
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Mark and Recapture &#8212; Think Bayes</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Logistic Regression" href="chap16.html" />
    <link rel="prev" title="Survival Analysis" href="chap14.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  
  <h1 class="site-logo" id="site-title">Think Bayes</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Think Bayes 2
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap01.html">
   Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap02.html">
   Bayes’s Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap03.html">
   Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap04.html">
   Estimating Proportions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap05.html">
   Estimating counts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap06.html">
   Odds and Addends
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap07.html">
   Minimum, maximum, and mixture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap08.html">
   Poisson Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap09.html">
   Decision Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap10.html">
   Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap11.html">
   Comparison
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap12.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap13.html">
   Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap14.html">
   Survival Analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Mark and Recapture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap16.html">
   Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap17.html">
   Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap18.html">
   Conjugate Priors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap19.html">
   MCMC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap20.html">
   Approximate Bayesian Computation
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chap15.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/AllenDowney/ThinkBayes2"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/AllenDowney/ThinkBayes2/master?urlpath=tree/chap15.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-grizzly-bear-problem">
   The Grizzly Bear Problem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-update">
   The Update
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#two-parameter-model">
   Two Parameter Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-prior">
   The Prior
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   The Update
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#joint-and-marginal-distributions">
   Joint and marginal distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-lincoln-index-problem">
   The Lincoln Index Problem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#three-parameter-model">
   Three-Parameter Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="mark-and-recapture">
<h1>Mark and Recapture<a class="headerlink" href="#mark-and-recapture" title="Permalink to this headline">¶</a></h1>
<p>This chapter introduces “mark and recapture” experiments, in which we sample individuals from a population, mark them somehow, and then take a second sample from the same population.  Seeing how many individuals in the second sample are marked, we can estimate the size of the population.</p>
<p>Experiments like this were originally used in ecology, but turn out to be useful in many other fields.  Examples in this chapter include software engineering and epidemiology.</p>
<p>Also, in this chapter we’ll work with models that have three parameters, so we’ll extend the joint distributions we’ve been using to three dimensions.</p>
<p>But first, grizzly bears.</p>
<div class="section" id="the-grizzly-bear-problem">
<h2>The Grizzly Bear Problem<a class="headerlink" href="#the-grizzly-bear-problem" title="Permalink to this headline">¶</a></h2>
<p>In 1996 and 1997 researchers deployed bear traps in locations in British Columbia and Alberta, Canada, in an effort to estimate the population of grizzly bears.  They describe the experiment in <a class="reference external" href="https://www.researchgate.net/publication/229195465_Estimating_Population_Size_of_Grizzly_Bears_Using_Hair_Capture_DNA_Profiling_and_Mark-Recapture_Analysis">this article</a>.</p>
<p>The “trap” consists of  a lure and several strands of barbed wire intended to capture samples of hair from bears that visit the lure.  Using the hair samples, the researchers use DNA analysis to identify individual bears.</p>
<p>During the first session, the researchers deployed traps at 76 sites.  Returning 10 days later, they obtained 1043 hair samples and identified 23 different bears.  During a second 10-day session they obtained 1191 samples from 19 different bears, where 4 of the 19 were from bears they had identified in the first batch.</p>
<p>To estimate the population of bears from this data, we need a model for the probability that each bear will be observed during each session.  As a starting place, we’ll make the simplest assumption, that every bear in the population has the same (unknown) probability of being sampled during each session.</p>
<p>With these assumptions we can compute the probability of the data for a range of possible populations.</p>
<p>As an example, let’s suppose that the actual population of bears is 100.</p>
<p>After the first session, 23 of the 100 bears have been identified.
During the second session, if we choose 19 bears at random, what is the probability that 4 of them were previously identified?</p>
<p>I’ll define</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N\)</span>: actual population size, 100.</p></li>
<li><p><span class="math notranslate nohighlight">\(K\)</span>: number of bears identified in the first session, 23.</p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span>: number of bears observed in the second session, 19 in the example.</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span>: number of bears in the second session that were previously identified, 4.</p></li>
</ul>
<p>For given values of <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(K\)</span>, and <span class="math notranslate nohighlight">\(n\)</span>, the probability of finding <span class="math notranslate nohighlight">\(k\)</span> previously-identified bears is given by the <a class="reference external" href="https://en.wikipedia.org/wiki/Hypergeometric_distribution">hypergeometric distribution</a>:</p>
<div class="math notranslate nohighlight">
\[\binom{K}{k} \binom{N-K}{n-k}/ \binom{N}{n}\]</div>
<p>where the <a class="reference external" href="https://en.wikipedia.org/wiki/Binomial_coefficient">binomial coefficient</a>, <span class="math notranslate nohighlight">\(\binom{K}{k}\)</span>, is the number of subsets of size <span class="math notranslate nohighlight">\(k\)</span> we can choose from a population of size <span class="math notranslate nohighlight">\(K\)</span>.</p>
<p>To understand why, consider:</p>
<ul class="simple">
<li><p>The denominator, <span class="math notranslate nohighlight">\(\binom{N}{n}\)</span>, is the number of subsets of <span class="math notranslate nohighlight">\(n\)</span> we could choose from a population of <span class="math notranslate nohighlight">\(N\)</span> bears.</p></li>
<li><p>The numerator is the number of subsets that contain <span class="math notranslate nohighlight">\(k\)</span> bears from the previously identified <span class="math notranslate nohighlight">\(K\)</span> and <span class="math notranslate nohighlight">\(n-k\)</span> from the previously unseen <span class="math notranslate nohighlight">\(N-K\)</span>.</p></li>
</ul>
<p>SciPy provides <code class="docutils literal notranslate"><span class="pre">hypergeom</span></code>, which we can use to compute this probability for a range of values of <span class="math notranslate nohighlight">\(k\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">hypergeom</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">23</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">19</span>

<span class="n">ks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">ks</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The result is the distribution of <span class="math notranslate nohighlight">\(k\)</span> with given parameters <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(K\)</span>, and <span class="math notranslate nohighlight">\(n\)</span>.
Here’s what it looks like.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">decorate</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">ps</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Number of bears observed twice&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PMF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Hypergeometric distribution of k (known population 100)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_12_0.png" src="_images/chap15_12_0.png" />
</div>
</div>
<p>The most likely value of <span class="math notranslate nohighlight">\(k\)</span> is 4, which is the value actually observed in the experiment.<br />
That suggests that <span class="math notranslate nohighlight">\(N=100\)</span> is a reasonable estimate of the population, given this data.</p>
<p>We’ve computed the distribution of <span class="math notranslate nohighlight">\(k\)</span> given <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(K\)</span>, and <span class="math notranslate nohighlight">\(n\)</span>.
Now let’s go the other way: given <span class="math notranslate nohighlight">\(K\)</span>, <span class="math notranslate nohighlight">\(n\)</span>, and <span class="math notranslate nohighlight">\(k\)</span>, how can we estimate the total population, <span class="math notranslate nohighlight">\(N\)</span>?</p>
</div>
<div class="section" id="the-update">
<h2>The Update<a class="headerlink" href="#the-update" title="Permalink to this headline">¶</a></h2>
<p>As a starting place, let’s suppose that, prior to this study, an expert estimates that the local bear population is between 50 and 500, and equally likely to be any value in that range.</p>
<p>I’ll use <code class="docutils literal notranslate"><span class="pre">make_uniform</span></code> to make a uniform distribution of integers in this range.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">make_uniform</span>

<span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">501</span><span class="p">)</span>
<span class="n">prior_N</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">)</span>
<span class="n">prior_N</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(451,)
</pre></div>
</div>
</div>
</div>
<p>So that’s our prior.</p>
<p>To compute the likelihood of the data, we can use <code class="docutils literal notranslate"><span class="pre">hypergeom</span></code> with constants <code class="docutils literal notranslate"><span class="pre">K</span></code> and <code class="docutils literal notranslate"><span class="pre">n</span></code>, and a range of values of <code class="docutils literal notranslate"><span class="pre">N</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Ns</span> <span class="o">=</span> <span class="n">prior_N</span><span class="o">.</span><span class="n">qs</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">23</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">19</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">likelihood</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="p">(</span><span class="n">Ns</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can compute the posterior in the usual way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span> <span class="o">=</span> <span class="n">prior_N</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior_N</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.07755224277106727
</pre></div>
</div>
</div>
</div>
<p>And here’s what it looks like.</p>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Population of bears (N)&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distribution of N&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_21_0.png" src="_images/chap15_21_0.png" />
</div>
</div>
<p>The most likely value is 109.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span><span class="o">.</span><span class="n">max_prob</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>109
</pre></div>
</div>
</div>
</div>
<p>But the distribution is skewed to the right, so the posterior mean is substantially higher.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>173.79880627085637
</pre></div>
</div>
</div>
</div>
<p>And the credible interval is quite wide.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 77., 363.])
</pre></div>
</div>
</div>
</div>
<p>This solution is relatively simple, but it turns out we can do a little better if we model the unknown probability of observing a bear explicitly.</p>
</div>
<div class="section" id="two-parameter-model">
<h2>Two Parameter Model<a class="headerlink" href="#two-parameter-model" title="Permalink to this headline">¶</a></h2>
<p>Next we’ll try a model with two parameters: the number of bears, <code class="docutils literal notranslate"><span class="pre">N</span></code>, and the probability of observing a bear, <code class="docutils literal notranslate"><span class="pre">p</span></code>.</p>
<p>We’ll assume that the probability is the same in both rounds, which is probably reasonable in this case because it is the same kind of trap in the same place.</p>
<p>We’ll also assume that the probabilities are independent; that is, the probability a bear is observed in the second round does not depend on whether it was observed in the first round.  This assumption might be less reasonable, but for now it is a necessary simplification.</p>
<p>Here are the counts again:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="mi">23</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">19</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
</div>
</div>
<p>For this model, I’ll express the data in a notation that will make it easier to generalize to more than two rounds:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">k10</span></code> is the number of bears observed in the first round but not the second,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">k01</span></code> is the number of bears observed in the second round but not the first, and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">k11</span></code> is the number of bears observed in both rounds.</p></li>
</ul>
<p>Here are their values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k10</span> <span class="o">=</span> <span class="mi">23</span> <span class="o">-</span> <span class="mi">4</span>
<span class="n">k01</span> <span class="o">=</span> <span class="mi">19</span> <span class="o">-</span> <span class="mi">4</span>
<span class="n">k11</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
</div>
</div>
<p>Suppose we know the actual values of <code class="docutils literal notranslate"><span class="pre">N</span></code> and <code class="docutils literal notranslate"><span class="pre">p</span></code>.  We can use them to compute the likelihood of this data.</p>
<p>For example, suppose we know that <code class="docutils literal notranslate"><span class="pre">N=100</span></code> and <code class="docutils literal notranslate"><span class="pre">p=0.2</span></code>.
We can use <code class="docutils literal notranslate"><span class="pre">N</span></code> to compute <code class="docutils literal notranslate"><span class="pre">k00</span></code>, which is the number of unobserved bears.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">observed</span> <span class="o">=</span> <span class="n">k01</span> <span class="o">+</span> <span class="n">k10</span> <span class="o">+</span> <span class="n">k11</span>
<span class="n">k00</span> <span class="o">=</span> <span class="n">N</span> <span class="o">-</span> <span class="n">observed</span>
<span class="n">k00</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>62
</pre></div>
</div>
</div>
</div>
<p>For the update, it will be convenient to store the data as a list that represents the number of bears in each category.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">k00</span><span class="p">,</span> <span class="n">k01</span><span class="p">,</span> <span class="n">k10</span><span class="p">,</span> <span class="n">k11</span><span class="p">]</span>
<span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[62, 15, 19, 4]
</pre></div>
</div>
</div>
</div>
<p>Now, if we know <code class="docutils literal notranslate"><span class="pre">p=0.2</span></code>, we can compute the probability a bear falls in each category.  For example, the probability of being observed in both rounds is <code class="docutils literal notranslate"><span class="pre">p*p</span></code>, and the probability of being unobserved in both rounds is <code class="docutils literal notranslate"><span class="pre">q*q</span></code> (where <code class="docutils literal notranslate"><span class="pre">q=1-p</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">q</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">p</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span><span class="o">*</span><span class="n">q</span><span class="p">,</span> <span class="n">q</span><span class="o">*</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="o">*</span><span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="o">*</span><span class="n">p</span><span class="p">]</span>
<span class="n">y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.6400000000000001,
 0.16000000000000003,
 0.16000000000000003,
 0.04000000000000001]
</pre></div>
</div>
</div>
</div>
<p>Now the probability of the data is given by the <a class="reference external" href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial distribution</a>:</p>
<div class="math notranslate nohighlight">
\[\frac{N!}{\prod x_i!} \prod y_i^{x_i}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is actual population, <span class="math notranslate nohighlight">\(x\)</span> is a sequence with the counts in each category, and <span class="math notranslate nohighlight">\(y\)</span> is a sequence of probabilities for each category.</p>
<p>SciPy provides <code class="docutils literal notranslate"><span class="pre">multinomial</span></code>, which provides <code class="docutils literal notranslate"><span class="pre">pmf</span></code>, which computes this probability.
Here is the probability of the data for these values of <code class="docutils literal notranslate"><span class="pre">N</span></code> and <code class="docutils literal notranslate"><span class="pre">p</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multinomial</span>

<span class="n">likelihood</span> <span class="o">=</span> <span class="n">multinomial</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">likelihood</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0016664011988507257
</pre></div>
</div>
</div>
</div>
<p>That’s the likelihood if we know <code class="docutils literal notranslate"><span class="pre">N</span></code> and <code class="docutils literal notranslate"><span class="pre">p</span></code>, but of course we don’t.  So we’ll choose prior distributions for <code class="docutils literal notranslate"><span class="pre">N</span></code> and <code class="docutils literal notranslate"><span class="pre">p</span></code>, and use the likelihoods to update it.</p>
</div>
<div class="section" id="the-prior">
<h2>The Prior<a class="headerlink" href="#the-prior" title="Permalink to this headline">¶</a></h2>
<p>We’ll use <code class="docutils literal notranslate"><span class="pre">prior_N</span></code> again for the prior distribution of <code class="docutils literal notranslate"><span class="pre">N</span></code>, and a uniform prior for the probability of observing a bear, <code class="docutils literal notranslate"><span class="pre">p</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">prior_p</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can make a joint distribution in the usual way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">make_joint</span>

<span class="n">joint_prior</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">prior_p</span><span class="p">,</span> <span class="n">prior_N</span><span class="p">)</span>
<span class="n">joint_prior</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(451, 100)
</pre></div>
</div>
</div>
</div>
<p>The result is a Pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> with values of <code class="docutils literal notranslate"><span class="pre">N</span></code> down the rows and values of <code class="docutils literal notranslate"><span class="pre">p</span></code> across the columns.
However, for this problem it will be convenient to represent the prior distribution as a 1-D <code class="docutils literal notranslate"><span class="pre">Series</span></code> rather than a 2-D <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.
We can convert from one format to the other using <code class="docutils literal notranslate"><span class="pre">stack</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">empiricaldist</span> <span class="kn">import</span> <span class="n">Pmf</span>

<span class="n">joint_pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">joint_prior</span><span class="o">.</span><span class="n">stack</span><span class="p">())</span>
<span class="n">joint_pmf</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>N</th>
      <th>p</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">50</th>
      <th>0.00</th>
      <td>0.000022</td>
    </tr>
    <tr>
      <th>0.01</th>
      <td>0.000022</td>
    </tr>
    <tr>
      <th>0.02</th>
      <td>0.000022</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">joint_pmf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>empiricaldist.empiricaldist.Pmf
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">joint_pmf</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>pandas.core.indexes.multi.MultiIndex
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joint_pmf</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(45100,)
</pre></div>
</div>
</div>
</div>
<p>The result is a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> whose index is a <code class="docutils literal notranslate"><span class="pre">MultiIndex</span></code>.
A <code class="docutils literal notranslate"><span class="pre">MultiIndex</span></code> can have more than one column; in this example, the first column contains values of <code class="docutils literal notranslate"><span class="pre">N</span></code> and the second column contains values of <code class="docutils literal notranslate"><span class="pre">p</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> has one row (and one prior probability) for each possible pair of parameters <code class="docutils literal notranslate"><span class="pre">N</span></code> and <code class="docutils literal notranslate"><span class="pre">p</span></code>.
So the total number of rows is the product of the lengths of <code class="docutils literal notranslate"><span class="pre">prior_N</span></code> and <code class="docutils literal notranslate"><span class="pre">prior_p</span></code>.</p>
<p>Now we have to compute the likelihood of the data for each pair of parameters.</p>
</div>
<div class="section" id="id1">
<h2>The Update<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>To allocate space for the likelihoods, it is convenient to make a copy of <code class="docutils literal notranslate"><span class="pre">joint_pmf</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">joint_pmf</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>As we loop through the pairs of parameters, we compute the likelihood of the data as in the previous section, and then store the result as an element of <code class="docutils literal notranslate"><span class="pre">likelihood</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">observed</span> <span class="o">=</span> <span class="n">k01</span> <span class="o">+</span> <span class="n">k10</span> <span class="o">+</span> <span class="n">k11</span>

<span class="k">for</span> <span class="n">N</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">joint_pmf</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">k00</span> <span class="o">=</span> <span class="n">N</span> <span class="o">-</span> <span class="n">observed</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">k00</span><span class="p">,</span> <span class="n">k01</span><span class="p">,</span> <span class="n">k10</span><span class="p">,</span> <span class="n">k11</span><span class="p">]</span>
    <span class="n">q</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">p</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span><span class="o">*</span><span class="n">q</span><span class="p">,</span> <span class="n">q</span><span class="o">*</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="o">*</span><span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="o">*</span><span class="n">p</span><span class="p">]</span>
    <span class="n">likelihood</span><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">multinomial</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can compute the posterior in the usual way.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_pmf</span> <span class="o">=</span> <span class="n">joint_pmf</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior_pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.9678796190279657e-05
</pre></div>
</div>
</div>
</div>
<p>We’ll use <code class="docutils literal notranslate"><span class="pre">plot_contour</span></code> again to visualize the joint posterior distribution.
But remember that the posterior distribution we just computed is represented as a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code>, which is a <code class="docutils literal notranslate"><span class="pre">Series</span></code>, and <code class="docutils literal notranslate"><span class="pre">plot_contour</span></code> expects a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<p>Since we used <code class="docutils literal notranslate"><span class="pre">stack</span></code> to convert from a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> to a <code class="docutils literal notranslate"><span class="pre">Series</span></code>, we can use <code class="docutils literal notranslate"><span class="pre">unstack</span></code> to go the other way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joint_posterior</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>And here’s what the result looks like.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">plot_contour</span>

<span class="n">plot_contour</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Joint posterior distribution of N and p&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_61_0.png" src="_images/chap15_61_0.png" />
</div>
</div>
<p>The most likely values of <code class="docutils literal notranslate"><span class="pre">N</span></code> are near 100, as in the previous model. The most likely values of <code class="docutils literal notranslate"><span class="pre">p</span></code> are near 0.2.</p>
<p>The shape of this contour indicates that these parameters are correlated.  If <code class="docutils literal notranslate"><span class="pre">p</span></code> is near the low end of the range, the most likely values of <code class="docutils literal notranslate"><span class="pre">N</span></code> are higher; if <code class="docutils literal notranslate"><span class="pre">p</span></code> is near the high end of the range, <code class="docutils literal notranslate"><span class="pre">N</span></code> is lower.</p>
<p>Now that we have a posterior <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>, we can extract the marginal distributions in the usual way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">marginal</span>

<span class="n">posterior2_p</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">posterior2_N</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s the posterior distribution for <code class="docutils literal notranslate"><span class="pre">p</span></code>:</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior2_p</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Probability of observing a bear&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of p&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_65_0.png" src="_images/chap15_65_0.png" />
</div>
</div>
<p>The most likely values are near 0.2.</p>
<p>Here’s the posterior distribution for <code class="docutils literal notranslate"><span class="pre">N</span></code> based on the two-parameter model, along with the posterior we got using the one-parameter (hypergeometric) model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;one-parameter model&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">)</span>
<span class="n">posterior2_N</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;two-parameter model&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Population of bears (N)&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of N&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_68_0.png" src="_images/chap15_68_0.png" />
</div>
</div>
<p>With the two-parameter model, the mean is a little lower and the 90% credible interval is a little narrower.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">posterior_N</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> 
      <span class="n">posterior_N</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>173.79880627085637 [ 77. 363.]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">posterior2_N</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> 
      <span class="n">posterior2_N</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>138.750521364726 [ 68. 277.]
</pre></div>
</div>
</div>
</div>
<p>The two-parameter model yields a narrower posterior distribution for <code class="docutils literal notranslate"><span class="pre">N</span></code>, compared to the one-parameter model, because it takes advantage of an additional source of information: the consistency of the two observations.</p>
<p>To see how this helps, consider a scenario where <code class="docutils literal notranslate"><span class="pre">N</span></code> is relatively low, like 138 (the posterior mean of the two-parameter model).</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N1</span> <span class="o">=</span> <span class="mi">138</span>
</pre></div>
</div>
</div>
</div>
<p>Given that we saw 23 bears during the first trial and 19 during the second, we can estimate the corresponding value of <code class="docutils literal notranslate"><span class="pre">p</span></code>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="mi">23</span> <span class="o">+</span> <span class="mi">19</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">mean</span><span class="o">/</span><span class="n">N1</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.15217391304347827
</pre></div>
</div>
</div>
</div>
<p>With these parameters, how much variability do you expect in the number of bears from one trial to the next?  We can quantify that by computing the standard deviation of the binomial distribution with these parameters.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>

<span class="n">binom</span><span class="p">(</span><span class="n">N1</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4.219519857292647
</pre></div>
</div>
</div>
</div>
<p>Now let’s consider a second scenario where <code class="docutils literal notranslate"><span class="pre">N</span></code> is 173, the posterior mean of the one-parameter model.  The corresponding value of <code class="docutils literal notranslate"><span class="pre">p</span></code> is lower.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N2</span> <span class="o">=</span> <span class="mi">173</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">mean</span><span class="o">/</span><span class="n">N2</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.12138728323699421
</pre></div>
</div>
</div>
</div>
<p>In this scenario, the variation we expect to see from one trial to the next is higher.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">binom</span><span class="p">(</span><span class="n">N2</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4.2954472470306415
</pre></div>
</div>
</div>
</div>
<p>So if the number of bears we observe is the same in both trials, that would be evidence for lower values of <code class="docutils literal notranslate"><span class="pre">N</span></code>, where we expect more consistency.
If the number of bears is substantially different between the two trials, that would be evidence for higher values of <code class="docutils literal notranslate"><span class="pre">N</span></code>.</p>
<p>In the actual data, the difference between the two trials is low, which is why the posterior mean of the two-parameter model is lower.
The two-parameter model takes advantage of additional information, which is why the credible interval is narrower.</p>
</div>
<div class="section" id="joint-and-marginal-distributions">
<h2>Joint and marginal distributions<a class="headerlink" href="#joint-and-marginal-distributions" title="Permalink to this headline">¶</a></h2>
<p>Marginal distributions are called “marginal” because in a common visualization they appear in the margins of the plot.</p>
<p>Seaborn provides a class called <code class="docutils literal notranslate"><span class="pre">JointGrid</span></code> that creates this visualization.
The following function uses it to show the joint and marginal distributions in a single plot.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">seaborn</span> <span class="kn">import</span> <span class="n">JointGrid</span>

<span class="k">def</span> <span class="nf">joint_plot</span><span class="p">(</span><span class="n">joint</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Show joint and marginal distributions.</span>
<span class="sd">    </span>
<span class="sd">    joint: DataFrame that represents a joint distribution</span>
<span class="sd">    options: passed to JointGrid</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># get the names of the parameters</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">joint</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">name</span>
    <span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;x&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">x</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">joint</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span>
    <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;y&#39;</span> <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">y</span>

    <span class="c1"># make a JointGrid with minimal data</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">x</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">:[</span><span class="mi">0</span><span class="p">]})</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">JointGrid</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>

    <span class="c1"># replace the contour plot</span>
    <span class="n">g</span><span class="o">.</span><span class="n">ax_joint</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">joint</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> 
                       <span class="n">joint</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> 
                       <span class="n">joint</span><span class="p">,</span> 
                       <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
    
    <span class="c1"># replace the marginals</span>
    <span class="n">marginal_x</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">g</span><span class="o">.</span><span class="n">ax_marg_x</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">marginal_x</span><span class="o">.</span><span class="n">qs</span><span class="p">,</span> <span class="n">marginal_x</span><span class="o">.</span><span class="n">ps</span><span class="p">)</span>
    
    <span class="n">marginal_y</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">g</span><span class="o">.</span><span class="n">ax_marg_y</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">marginal_y</span><span class="o">.</span><span class="n">ps</span><span class="p">,</span> <span class="n">marginal_y</span><span class="o">.</span><span class="n">qs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joint_plot</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_85_0.png" src="_images/chap15_85_0.png" />
</div>
</div>
<p>A <code class="docutils literal notranslate"><span class="pre">JointGrid</span></code> is a concise way to represent the joint and marginal distributions visually.</p>
</div>
<div class="section" id="the-lincoln-index-problem">
<h2>The Lincoln Index Problem<a class="headerlink" href="#the-lincoln-index-problem" title="Permalink to this headline">¶</a></h2>
<p>In <a class="reference external" href="http://www.johndcook.com/blog/2010/07/13/lincoln-index/">an excellent blog post</a>, John D. Cook wrote about the Lincoln index, which is a way to estimate the
number of errors in a document (or program) by comparing results from
two independent testers.
Here’s his presentation of the problem:</p>
<blockquote>
<div><p>“Suppose you have a tester who finds 20 bugs in your program. You
want to estimate how many bugs are really in the program. You know
there are at least 20 bugs, and if you have supreme confidence in your
tester, you may suppose there are around 20 bugs. But maybe your
tester isn’t very good. Maybe there are hundreds of bugs. How can you
have any idea how many bugs there are? There’s no way to know with one
tester. But if you have two testers, you can get a good idea, even if
you don’t know how skilled the testers are.”</p>
</div></blockquote>
<p>Suppose the first tester finds 20 bugs, the second finds 15, and they
find 3 in common; how can we estimate the number of bugs?</p>
<p>This problem is similar to the Grizzly Bear problem, so I’ll represent the data in the same way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k10</span> <span class="o">=</span> <span class="mi">20</span> <span class="o">-</span> <span class="mi">3</span>
<span class="n">k01</span> <span class="o">=</span> <span class="mi">15</span> <span class="o">-</span> <span class="mi">3</span>
<span class="n">k11</span> <span class="o">=</span> <span class="mi">3</span>
</pre></div>
</div>
</div>
</div>
<p>But in this case it is probably not reasonable to assume that the testers have the same probability of finding a bug.
So I’ll define two parameters, <code class="docutils literal notranslate"><span class="pre">p0</span></code> for the probability that the first tester finds a bug, and <code class="docutils literal notranslate"><span class="pre">p1</span></code> for the probability that the second tester finds a bug.</p>
<p>I will continue to assume that the probabilities are independent, which is like assuming that all bugs are equally easy to find.  That might not be a good assumption, but let’s stick with it for now.</p>
<p>As an example, suppose we know that the probabilities are 0.2 and 0.15.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p0</span><span class="p">,</span> <span class="n">p1</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.15</span>
</pre></div>
</div>
</div>
</div>
<p>We can compute the array of probabilities, <code class="docutils literal notranslate"><span class="pre">y</span></code>, like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_probs</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">p1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the probability for each of 4 categories.&quot;&quot;&quot;</span>
    <span class="n">q0</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">p0</span>
    <span class="n">q1</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">p1</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">q0</span><span class="o">*</span><span class="n">q1</span><span class="p">,</span> <span class="n">q0</span><span class="o">*</span><span class="n">p1</span><span class="p">,</span> <span class="n">p0</span><span class="o">*</span><span class="n">q1</span><span class="p">,</span> <span class="n">p0</span><span class="o">*</span><span class="n">p1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">compute_probs</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">p1</span><span class="p">)</span>
<span class="n">y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.68, 0.12, 0.17, 0.03]
</pre></div>
</div>
</div>
</div>
<p>With these probabilities, there is a
68% chance that neither tester finds the bug and a
3% chance that both do.</p>
<p>Pretending that these probabilities are known, we can compute the posterior distribution for <code class="docutils literal notranslate"><span class="pre">N</span></code>.
Here’s a prior distribution that’s uniform from 32 to 350 bugs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">350</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> 
<span class="n">prior_N</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">)</span>
<span class="n">prior_N</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>N</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>32</th>
      <td>0.015625</td>
    </tr>
    <tr>
      <th>37</th>
      <td>0.015625</td>
    </tr>
    <tr>
      <th>42</th>
      <td>0.015625</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>I’ll put the data in an array, with 0 as a place-keeper for the unknown value <code class="docutils literal notranslate"><span class="pre">k00</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">k01</span><span class="p">,</span> <span class="n">k10</span><span class="p">,</span> <span class="n">k11</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>And here are the likelihoods for each value of <code class="docutils literal notranslate"><span class="pre">N</span></code>, with <code class="docutils literal notranslate"><span class="pre">ps</span></code> as a constant.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">prior_N</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">observed</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="n">prior_N</span><span class="o">.</span><span class="n">qs</span><span class="p">:</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">N</span> <span class="o">-</span> <span class="n">observed</span>
    <span class="n">likelihood</span><span class="p">[</span><span class="n">N</span><span class="p">]</span> <span class="o">=</span> <span class="n">multinomial</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can compute the posterior in the usual way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span> <span class="o">=</span> <span class="n">prior_N</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior_N</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0003425201572557094
</pre></div>
</div>
</div>
</div>
<p>And here’s what it looks like.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Number of bugs (N)&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PMF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of n with known p1, p2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_103_0.png" src="_images/chap15_103_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">posterior_N</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> 
      <span class="n">posterior_N</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>102.1249999999998 [ 77. 127.]
</pre></div>
</div>
</div>
</div>
<p>With the assumption that <code class="docutils literal notranslate"><span class="pre">p0</span></code> and <code class="docutils literal notranslate"><span class="pre">p1</span></code> are known to be <code class="docutils literal notranslate"><span class="pre">0.2</span></code> and <code class="docutils literal notranslate"><span class="pre">0.15</span></code>, the posterior mean is 102 with 90% credible interval (77, 127).
But this result is based on the assumption that we know the probabilities, and we don’t.</p>
</div>
<div class="section" id="three-parameter-model">
<h2>Three-Parameter Model<a class="headerlink" href="#three-parameter-model" title="Permalink to this headline">¶</a></h2>
<p>What we need is a model with three parameters: <code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">p0</span></code>, and <code class="docutils literal notranslate"><span class="pre">p1</span></code>.
We’ll use <code class="docutils literal notranslate"><span class="pre">prior_N</span></code> again for the prior distribution of <code class="docutils literal notranslate"><span class="pre">N</span></code>, and here are the priors for <code class="docutils literal notranslate"><span class="pre">p0</span></code> and <code class="docutils literal notranslate"><span class="pre">p1</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">51</span><span class="p">)</span>
<span class="n">prior_p0</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p0&#39;</span><span class="p">)</span>
<span class="n">prior_p1</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we have to assemble them into a joint prior with three dimensions.
I’ll start by putting the first two into a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joint2</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">prior_p0</span><span class="p">,</span> <span class="n">prior_N</span><span class="p">)</span>
<span class="n">joint2</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(64, 51)
</pre></div>
</div>
</div>
</div>
<p>Now I’ll stack them, as in the previous example, and put the result in a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joint2_pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">joint2</span><span class="o">.</span><span class="n">stack</span><span class="p">())</span>
<span class="n">joint2_pmf</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>N</th>
      <th>p0</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">32</th>
      <th>0.00</th>
      <td>0.000306</td>
    </tr>
    <tr>
      <th>0.02</th>
      <td>0.000306</td>
    </tr>
    <tr>
      <th>0.04</th>
      <td>0.000306</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can use <code class="docutils literal notranslate"><span class="pre">make_joint</span></code> again to add in the third parameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joint3</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">prior_p1</span><span class="p">,</span> <span class="n">joint2_pmf</span><span class="p">)</span>
<span class="n">joint3</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3264, 51)
</pre></div>
</div>
</div>
</div>
<p>The result is a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> with values of <code class="docutils literal notranslate"><span class="pre">N</span></code> and <code class="docutils literal notranslate"><span class="pre">p0</span></code> in a <code class="docutils literal notranslate"><span class="pre">MultiIndex</span></code> that goes down the rows and values of <code class="docutils literal notranslate"><span class="pre">p1</span></code> in an index that goes across the columns.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joint3</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>p1</th>
      <th>0.00</th>
      <th>0.02</th>
      <th>0.04</th>
      <th>0.06</th>
      <th>0.08</th>
      <th>0.10</th>
      <th>0.12</th>
      <th>0.14</th>
      <th>0.16</th>
      <th>0.18</th>
      <th>...</th>
      <th>0.82</th>
      <th>0.84</th>
      <th>0.86</th>
      <th>0.88</th>
      <th>0.90</th>
      <th>0.92</th>
      <th>0.94</th>
      <th>0.96</th>
      <th>0.98</th>
      <th>1.00</th>
    </tr>
    <tr>
      <th>N</th>
      <th>p0</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">32</th>
      <th>0.00</th>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>...</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
    </tr>
    <tr>
      <th>0.02</th>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>...</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
    </tr>
    <tr>
      <th>0.04</th>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>...</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
      <td>0.000006</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 51 columns</p>
</div></div></div>
</div>
<p>Now I’ll apply <code class="docutils literal notranslate"><span class="pre">stack</span></code> again:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joint3_pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">joint3</span><span class="o">.</span><span class="n">stack</span><span class="p">())</span>
<span class="n">joint3_pmf</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>N</th>
      <th>p0</th>
      <th>p1</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">32</th>
      <th rowspan="3" valign="top">0.0</th>
      <th>0.00</th>
      <td>0.000006</td>
    </tr>
    <tr>
      <th>0.02</th>
      <td>0.000006</td>
    </tr>
    <tr>
      <th>0.04</th>
      <td>0.000006</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The result is a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> with a three-column <code class="docutils literal notranslate"><span class="pre">MultiIndex</span></code> containing all possible triplets of parameters.</p>
<p>The number of rows is the product of the number of values in all three priors, which is almost 170,000.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joint3_pmf</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(166464,)
</pre></div>
</div>
</div>
</div>
<p>That’s still small enough to be practical, but it will take longer to compute the likelihoods than in the previous examples.</p>
<p>Here’s the loop that computes the likelihoods; it’s similar to the one in the previous section:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">joint3_pmf</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">observed</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="k">for</span> <span class="n">N</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">p1</span> <span class="ow">in</span> <span class="n">joint3_pmf</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">N</span> <span class="o">-</span> <span class="n">observed</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">compute_probs</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">p1</span><span class="p">)</span>
    <span class="n">likelihood</span><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">p1</span><span class="p">]</span> <span class="o">=</span> <span class="n">multinomial</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can compute the posterior in the usual way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_pmf</span> <span class="o">=</span> <span class="n">joint3_pmf</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior_pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8.941088283758206e-06
</pre></div>
</div>
</div>
</div>
<p>Now, to extract the marginal distributions, we could unstack the joint posterior as we did in the previous section.
But <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> provides a version of <code class="docutils literal notranslate"><span class="pre">marginal</span></code> that works with a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> rather than a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.
Here’s how we use it to get the posterior distribution for <code class="docutils literal notranslate"><span class="pre">N</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">marginal</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And here’s what it looks look.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Number of bugs (N)&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distributions of N&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_127_0.png" src="_images/chap15_127_0.png" />
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_N</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>105.7656173219623
</pre></div>
</div>
</div>
</div>
<p>The posterior mean is 105 bugs, which suggests that there are still many bugs the testers have not found.</p>
<p>Here are the posteriors for <code class="docutils literal notranslate"><span class="pre">p0</span></code> and <code class="docutils literal notranslate"><span class="pre">p1</span></code>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_p1</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">marginal</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">posterior_p2</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">marginal</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">posterior_p1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;p1&#39;</span><span class="p">)</span>
<span class="n">posterior_p2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;p2&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Probability of finding a bug&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distributions of p1 and p2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_130_0.png" src="_images/chap15_130_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_p1</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">posterior_p1</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.2297065971677732, array([0.1, 0.4]))
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_p2</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">posterior_p2</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.17501172155925757, array([0.06, 0.32]))
</pre></div>
</div>
</div>
</div>
<p>Comparing the posterior distributions, the tester who found more bugs probably has a higher probability of finding bugs.  The posterior means are about 23% and 18%.  But the distributions overlap, so we should not be too sure.</p>
<p>This is the first example we’ve seen with three parameters.
As the number of parameters increases, the number of combinations increases quickly.
The method we’ve been using so far, enumerating all possible combinations, becomes impractical if the number of parameters is more than 3 or 4.</p>
<p>However there are other methods that can handle models with many more parameters, as we’ll see in &lt;&lt;_MCMC&gt;&gt;.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>The problems in this chapter are examples of <a class="reference external" href="https://en.wikipedia.org/wiki/Mark_and_recapture">mark and recapture</a> experiments, which are used in ecology to estimate animal populations.  They also have applications in engineering, as in the Lincoln index problem.  And in the exercises you’ll see that they are used in epidemiology, too.</p>
<p>This chapter introduces two new probability distributions:</p>
<ul class="simple">
<li><p>The hypergeometric distribution is a variation of the binomial distribution in which samples are drawn from the population without replacement.</p></li>
<li><p>The multinomial distribution is a generalization of the binomial distribution where there are more than two possible outcomes.</p></li>
</ul>
<p>Also in this chapter, we saw the first example of a model with three parameters.  We’ll see more in subsequent chapters.</p>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p><strong>Exercise:</strong> <a class="reference external" href="http://chao.stat.nthu.edu.tw/wordpress/paper/110.pdf">In an excellent paper</a>, Anne Chao explains how mark and recapture experiments are used in epidemiology to estimate the prevalence of a disease in a human population based on multiple incomplete lists of cases.</p>
<p>One of the examples in that paper is a study “to estimate the number of people who were infected by hepatitis in an outbreak that occurred in and around a college in northern Taiwan from April to July 1995.”</p>
<p>Three lists of cases were available:</p>
<ol class="simple">
<li><p>135 cases identified using a serum test.</p></li>
<li><p>122 cases reported by local hospitals.</p></li>
<li><p>126 cases reported on questionnaires collected by epidemiologists.</p></li>
</ol>
<p>In this exercise, we’ll use only the first two lists; in the next exercise we’ll bring in the third list.</p>
<p>Make a joint prior and update it using this data, then compute the posterior mean of <code class="docutils literal notranslate"><span class="pre">N</span></code> and a 90% credible interval.</p>
<p>The following array contains 0 as a place-holder for the unknown value of <code class="docutils literal notranslate"><span class="pre">k00</span></code>, followed by known values of <code class="docutils literal notranslate"><span class="pre">k01</span></code>, <code class="docutils literal notranslate"><span class="pre">k10</span></code>, and <code class="docutils literal notranslate"><span class="pre">k11</span></code>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">73</span><span class="p">,</span> <span class="mi">86</span><span class="p">,</span> <span class="mi">49</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>These data indicate that there are 73 cases on the second list that are not on the first, 86 cases on the first list that are not on the second, and 49 cases on both lists.</p>
<p>To keep things simple, we’ll assume that each case has the same probability of appearing on each list.  So we’ll use a two-parameter model where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the total number of cases and <code class="docutils literal notranslate"><span class="pre">p</span></code> is the probability that any case appears on any list.</p>
<p>Here are priors you can start with (but feel free to modify them).</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">prior_N</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">)</span>
<span class="n">prior_N</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>N</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>200</th>
      <td>0.016667</td>
    </tr>
    <tr>
      <th>205</th>
      <td>0.016667</td>
    </tr>
    <tr>
      <th>210</th>
      <td>0.016667</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">prior_p</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
<span class="n">prior_p</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>p</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0.00</th>
      <td>0.02</td>
    </tr>
    <tr>
      <th>0.02</th>
      <td>0.02</td>
    </tr>
    <tr>
      <th>0.04</th>
      <td>0.02</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">joint_prior</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">prior_p</span><span class="p">,</span> <span class="n">prior_N</span><span class="p">)</span>
<span class="n">joint_prior</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>p</th>
      <th>0.00</th>
      <th>0.02</th>
      <th>0.04</th>
      <th>0.06</th>
      <th>0.08</th>
      <th>0.10</th>
      <th>0.12</th>
      <th>0.14</th>
      <th>0.16</th>
      <th>0.18</th>
      <th>...</th>
      <th>0.80</th>
      <th>0.82</th>
      <th>0.84</th>
      <th>0.86</th>
      <th>0.88</th>
      <th>0.90</th>
      <th>0.92</th>
      <th>0.94</th>
      <th>0.96</th>
      <th>0.98</th>
    </tr>
    <tr>
      <th>N</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>200</th>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>...</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
    </tr>
    <tr>
      <th>205</th>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>...</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
    </tr>
    <tr>
      <th>210</th>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>...</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
      <td>0.000333</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 50 columns</p>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">prior_pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">joint_prior</span><span class="o">.</span><span class="n">stack</span><span class="p">())</span>
<span class="n">prior_pmf</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>N</th>
      <th>p</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">200</th>
      <th>0.00</th>
      <td>0.000333</td>
    </tr>
    <tr>
      <th>0.02</th>
      <td>0.000333</td>
    </tr>
    <tr>
      <th>0.04</th>
      <td>0.000333</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">observed</span> <span class="o">=</span> <span class="n">data2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">prior_pmf</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="k">for</span> <span class="n">N</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">prior_pmf</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">N</span> <span class="o">-</span> <span class="n">observed</span>
    <span class="n">q</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">p</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span><span class="o">*</span><span class="n">q</span><span class="p">,</span> <span class="n">q</span><span class="o">*</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="o">*</span><span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="o">*</span><span class="n">p</span><span class="p">]</span>
    <span class="n">likelihood</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">multinomial</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior_pmf</span> <span class="o">=</span> <span class="n">prior_pmf</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior_pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.266226682238907e-06
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">joint_posterior</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">plot_contour</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Joint posterior distribution of N and p&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_148_0.png" src="_images/chap15_148_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal_N</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">marginal_N</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Number of cases (N)&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of N&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_149_0.png" src="_images/chap15_149_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal_N</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">marginal_N</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(342.1317040018937, array([295., 400.]))
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise:</strong> Now let’s do the version of the problem with all three lists.  Here’s the data from Chou’s paper:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Hepatitis A virus list
P    Q    E    Data
1    1    1    k111 =28
1    1    0    k110 =21
1    0    1    k101 =17
1    0    0    k100 =69
0    1    1    k011 =18
0    1    0    k010 =55
0    0    1    k001 =63
0    0    0    k000 =??
</pre></div>
</div>
<p>Write a loop that computes the likelihood of the data for each pair of parameters, then update the prior and compute the posterior mean of <code class="docutils literal notranslate"><span class="pre">N</span></code>.  How does it compare to the results using only the first two lists?</p>
<p>Here’s the data in a NumPy array (in reverse order).</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">69</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Again, the first value is a place-keeper for the unknown <code class="docutils literal notranslate"><span class="pre">k000</span></code>.  The second value is <code class="docutils literal notranslate"><span class="pre">k001</span></code>, which means there are 63 cases that appear on the third list but not the first two.  And the last value is <code class="docutils literal notranslate"><span class="pre">k111</span></code>, which means there are 28 cases that appear on all three lists.</p>
<p>In the two-list version of the problem we computed <code class="docutils literal notranslate"><span class="pre">ps</span></code> by enumerating the combinations of <code class="docutils literal notranslate"><span class="pre">p</span></code> and <code class="docutils literal notranslate"><span class="pre">q</span></code>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">q</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">p</span>
<span class="n">ps</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span><span class="o">*</span><span class="n">q</span><span class="p">,</span> <span class="n">q</span><span class="o">*</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="o">*</span><span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="o">*</span><span class="n">p</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We could do the same thing for the three-list version, computing the probability for each of the eight categories.  But we can generalize it by recognizing that we are computing the cartesian product of <code class="docutils literal notranslate"><span class="pre">p</span></code> and <code class="docutils literal notranslate"><span class="pre">q</span></code>, repeated once for each list.</p>
<p>And we can use the following function (based on <a class="reference external" href="https://stackoverflow.com/questions/58242078/cartesian-product-of-arbitrary-lists-in-pandas/58242079#58242079">this StackOverflow answer</a>) to compute Cartesian products:</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cartesian_product</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Cartesian product of sequences.</span>
<span class="sd">    </span>
<span class="sd">    args: any number of sequences</span>
<span class="sd">    options: passes to `MultiIndex.from_product`</span>
<span class="sd">    </span>
<span class="sd">    returns: DataFrame with one column per sequence</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_product</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s an example with <code class="docutils literal notranslate"><span class="pre">p=0.2</span></code>:</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">cartesian_product</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>level_0</th>
      <th>level_1</th>
      <th>level_2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.8</td>
      <td>0.8</td>
      <td>0.8</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.8</td>
      <td>0.8</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.8</td>
      <td>0.2</td>
      <td>0.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.8</td>
      <td>0.2</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.2</td>
      <td>0.8</td>
      <td>0.8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.2</td>
      <td>0.8</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.2</td>
      <td>0.2</td>
      <td>0.8</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.2</td>
      <td>0.2</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>To compute the probability for each category, we take the product across the columns:</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    0.512
1    0.128
2    0.128
3    0.032
4    0.128
5    0.032
6    0.032
7    0.008
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Now you finish it off from there.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">observed</span> <span class="o">=</span> <span class="n">data3</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data3</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">prior_pmf</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="k">for</span> <span class="n">N</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">prior_pmf</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">N</span> <span class="o">-</span> <span class="n">observed</span>
    <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">cartesian_product</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">likelihood</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">multinomial</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior_pmf</span> <span class="o">=</span> <span class="n">prior_pmf</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior_pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.6359517829553705e-16
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">joint_posterior</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">plot_contour</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Joint posterior distribution of N and p&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_166_0.png" src="_images/chap15_166_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal3_N</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal_N</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;After two lists&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">)</span>
<span class="n">marginal3_N</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;After three lists&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Number of cases (N)&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of N&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap15_168_0.png" src="_images/chap15_168_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal_N</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">marginal_N</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(342.1317040018937, array([295., 400.]))
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal3_N</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">marginal3_N</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(391.0050140750373, array([360., 430.]))
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="chap14.html" title="previous page">Survival Analysis</a>
    <a class='right-next' id="next-link" href="chap16.html" title="next page">Logistic Regression</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Allen B. Downey<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>