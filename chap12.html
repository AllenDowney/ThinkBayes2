
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Classification &#8212; Think Bayes</title>
    
  <link rel="stylesheet" href="_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.c441f2ba0852f4cabcb80105e3a46ae6.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Inference" href="chap13.html" />
    <link rel="prev" title="Comparison" href="chap11.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  
  <h1 class="site-logo" id="site-title">Think Bayes</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Think Bayes 2
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap01.html">
   Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap02.html">
   Bayes’s Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap03.html">
   Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap04.html">
   Estimating Proportions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap05.html">
   Estimating Counts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap06.html">
   Odds and Addends
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap07.html">
   Minimum, Maximum, and Mixture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap08.html">
   Poisson Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap09.html">
   Decision Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap10.html">
   Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap11.html">
   Comparison
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap13.html">
   Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap14.html">
   Survival Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap15.html">
   Mark and Recapture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap16.html">
   Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap17.html">
   Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap18.html">
   Conjugate Priors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap19.html">
   MCMC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap20.html">
   Approximate Bayesian Computation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="redline.html">
   The Red Line Problem
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chap12.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/AllenDowney/ThinkBayes2"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/AllenDowney/ThinkBayes2/master?urlpath=tree/chap12.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#penguin-data">
   Penguin Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normal-models">
   Normal Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-update">
   The Update
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naive-bayesian-classification">
   Naive Bayesian Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#joint-distributions">
   Joint Distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multivariate-normal-distribution">
   Multivariate Normal Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizing-a-multivariate-normal-distribution">
   Visualizing a Multivariate Normal Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-less-naive-classifier">
   A Less Naive Classifier
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="classification">
<h1>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¶</a></h1>
<p>Classification might be the most well-known application of Bayesian methods, made famous in the 1990s as the basis of the first generation of <a class="reference external" href="https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering">spam filters</a>.</p>
<p>In this chapter, I’ll demonstrate Bayesian classification using data collected and made available by Dr. Kristen Gorman at the Palmer Long-Term Ecological Research Station in Antarctica (see Gorman, Williams, and Fraser, <a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081">“Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus <em>Pygoscelis</em>)”</a>, March 2014).
We’ll use this data to classify penguins by species.</p>
<div class="section" id="penguin-data">
<h2>Penguin Data<a class="headerlink" href="#penguin-data" title="Permalink to this headline">¶</a></h2>
<p>I’ll use Pandas to load the data into a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;penguins_raw.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(344, 17)
</pre></div>
</div>
</div>
</div>
<p>The dataset contains one row for each penguin and one column for each variable.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>studyName</th>
      <th>Sample Number</th>
      <th>Species</th>
      <th>Region</th>
      <th>Island</th>
      <th>Stage</th>
      <th>Individual ID</th>
      <th>Clutch Completion</th>
      <th>Date Egg</th>
      <th>Culmen Length (mm)</th>
      <th>Culmen Depth (mm)</th>
      <th>Flipper Length (mm)</th>
      <th>Body Mass (g)</th>
      <th>Sex</th>
      <th>Delta 15 N (o/oo)</th>
      <th>Delta 13 C (o/oo)</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>PAL0708</td>
      <td>1</td>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>Anvers</td>
      <td>Torgersen</td>
      <td>Adult, 1 Egg Stage</td>
      <td>N1A1</td>
      <td>Yes</td>
      <td>2007-11-11</td>
      <td>39.1</td>
      <td>18.7</td>
      <td>181.0</td>
      <td>3750.0</td>
      <td>MALE</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Not enough blood for isotopes.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>PAL0708</td>
      <td>2</td>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>Anvers</td>
      <td>Torgersen</td>
      <td>Adult, 1 Egg Stage</td>
      <td>N1A2</td>
      <td>Yes</td>
      <td>2007-11-11</td>
      <td>39.5</td>
      <td>17.4</td>
      <td>186.0</td>
      <td>3800.0</td>
      <td>FEMALE</td>
      <td>8.94956</td>
      <td>-24.69454</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>PAL0708</td>
      <td>3</td>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>Anvers</td>
      <td>Torgersen</td>
      <td>Adult, 1 Egg Stage</td>
      <td>N2A1</td>
      <td>Yes</td>
      <td>2007-11-16</td>
      <td>40.3</td>
      <td>18.0</td>
      <td>195.0</td>
      <td>3250.0</td>
      <td>FEMALE</td>
      <td>8.36821</td>
      <td>-25.33302</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>PAL0708</td>
      <td>4</td>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>Anvers</td>
      <td>Torgersen</td>
      <td>Adult, 1 Egg Stage</td>
      <td>N2A2</td>
      <td>Yes</td>
      <td>2007-11-16</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Adult not sampled.</td>
    </tr>
    <tr>
      <th>4</th>
      <td>PAL0708</td>
      <td>5</td>
      <td>Adelie Penguin (Pygoscelis adeliae)</td>
      <td>Anvers</td>
      <td>Torgersen</td>
      <td>Adult, 1 Egg Stage</td>
      <td>N3A1</td>
      <td>Yes</td>
      <td>2007-11-16</td>
      <td>36.7</td>
      <td>19.3</td>
      <td>193.0</td>
      <td>3450.0</td>
      <td>FEMALE</td>
      <td>8.76651</td>
      <td>-25.32426</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Three species of penguins are represented in the dataset:  Adélie, Chinstrap and Gentoo.</p>
<p>The measurements we’ll use are:</p>
<ul class="simple">
<li><p>Body Mass in grams (g).</p></li>
<li><p>Flipper Length in millimeters (mm).</p></li>
<li><p>Culmen Length in millimeters.</p></li>
<li><p>Culmen Depth in millimeters.</p></li>
</ul>
<p>If you are not familiar with the word “culmen”, it refers to the <a class="reference external" href="https://en.wikipedia.org/wiki/Bird_measurement#Culmen">top margin of the beak</a>.</p>
<p>These measurements will be most useful for classification if there are substantial differences between species and small variation within species.  To see whether that is true, and to what degree, I’ll plot cumulative distribution functions (CDFs) of each measurement for each species.</p>
<p>The following function takes the <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> and a column name.
It returns a dictionary that maps from each species name to a <code class="docutils literal notranslate"><span class="pre">Cdf</span></code> of the values in the column named <code class="docutils literal notranslate"><span class="pre">colname</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_cdf_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">colname</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Species2&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a CDF for each species.&quot;&quot;&quot;</span>
    <span class="n">cdf_map</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">grouped</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="p">)[</span><span class="n">colname</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">species</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">grouped</span><span class="p">:</span>
        <span class="n">cdf_map</span><span class="p">[</span><span class="n">species</span><span class="p">]</span> <span class="o">=</span> <span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">group</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">species</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cdf_map</span>
</pre></div>
</div>
</div>
</div>
<p>The following function plots a <code class="docutils literal notranslate"><span class="pre">Cdf</span></code> of the values in the given column for each species:</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">empiricaldist</span> <span class="kn">import</span> <span class="n">Cdf</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">decorate</span>

<span class="k">def</span> <span class="nf">plot_cdfs</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">colname</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Species2&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a CDF for each species.</span>
<span class="sd">    </span>
<span class="sd">    df: DataFrame</span>
<span class="sd">    colname: string column name</span>
<span class="sd">    by: string column name</span>

<span class="sd">    returns: dictionary from species name to Cdf</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cdf_map</span> <span class="o">=</span> <span class="n">make_cdf_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">colname</span><span class="p">,</span> <span class="n">by</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">species</span><span class="p">,</span> <span class="n">cdf</span> <span class="ow">in</span> <span class="n">cdf_map</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">cdf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="n">species</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    
    <span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="n">colname</span><span class="p">,</span>
             <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;CDF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s what the distributions look like for culmen length.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colname</span> <span class="o">=</span> <span class="s1">&#39;Culmen Length (mm)&#39;</span>
<span class="n">plot_cdfs</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">colname</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_25_0.png" src="_images/chap12_25_0.png" />
</div>
</div>
<p>It looks like we can use culmen length to identify  Adélie penguins, but the distributions for the other two species almost entirely overlap.</p>
<p>Here are the distributions for flipper length.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colname</span> <span class="o">=</span> <span class="s1">&#39;Flipper Length (mm)&#39;</span>
<span class="n">plot_cdfs</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">colname</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_27_0.png" src="_images/chap12_27_0.png" />
</div>
</div>
<p>Using flipper length, we can distinguish Gentoo penguins from the other two species.  So with just these two features, it seems like we should be able to classify penguins with some accuracy.</p>
<p>All of these CDFs show the sigmoid shape characteristic of the normal distribution;  I will take advantage of that observation in the next section.</p>
<p>Here are the distributions for culmen depth.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colname</span> <span class="o">=</span> <span class="s1">&#39;Culmen Depth (mm)&#39;</span>
<span class="n">plot_cdfs</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">colname</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_30_0.png" src="_images/chap12_30_0.png" />
</div>
</div>
<p>And here are the distributions of body mass.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colname</span> <span class="o">=</span> <span class="s1">&#39;Body Mass (g)&#39;</span>
<span class="n">plot_cdfs</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">colname</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_32_0.png" src="_images/chap12_32_0.png" />
</div>
</div>
<p>Culmen depth and body mass distinguish Gentoo penguins from the other two species, but these features might not add a lot of additional information, beyond what we get from flipper length and culmen length.</p>
</div>
<div class="section" id="normal-models">
<h2>Normal Models<a class="headerlink" href="#normal-models" title="Permalink to this headline">¶</a></h2>
<p>Let’s use these features to classify penguins. We’ll proceed in the usual Bayesian way:</p>
<ol class="simple">
<li><p>Define a prior distribution with the three possible species and a prior probability for each,</p></li>
<li><p>Compute the likelihood of the data for each hypothetical species, and then</p></li>
<li><p>Compute the posterior probability of each hypothesis.</p></li>
</ol>
<p>To compute the likelihood of the data under each hypothesis, I’ll use the data to estimate the parameters of a normal distribution for each species.</p>
<p>The following function takes a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> and a column name; it returns a dictionary that maps from each species name to a <code class="docutils literal notranslate"><span class="pre">norm</span></code> object.</p>
<p><code class="docutils literal notranslate"><span class="pre">norm</span></code> is defined in SciPy; it represents a normal distribution with a given mean and standard deviation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="k">def</span> <span class="nf">make_norm_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">colname</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Species2&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a map from species to norm object.&quot;&quot;&quot;</span>
    <span class="n">norm_map</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">grouped</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="p">)[</span><span class="n">colname</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">species</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">grouped</span><span class="p">:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
        <span class="n">norm_map</span><span class="p">[</span><span class="n">species</span><span class="p">]</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">norm_map</span>
</pre></div>
</div>
</div>
</div>
<p>For example, here’s the dictionary of <code class="docutils literal notranslate"><span class="pre">norm</span></code> objects for flipper length:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">flipper_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">)</span>
<span class="n">flipper_map</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;Adelie&#39;, &#39;Chinstrap&#39;, &#39;Gentoo&#39;])
</pre></div>
</div>
</div>
</div>
<p>Now suppose we measure a penguin and find that its flipper is 193 cm.  What is the probability of that measurement under each hypothesis?</p>
<p>The <code class="docutils literal notranslate"><span class="pre">norm</span></code> object provides <code class="docutils literal notranslate"><span class="pre">pdf</span></code>, which computes the probability density function (PDF) of the normal distribution.  We can use it to compute the likelihood of the observed data in a given distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="mi">193</span>
<span class="n">flipper_map</span><span class="p">[</span><span class="s1">&#39;Adelie&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.054732511875530694
</pre></div>
</div>
</div>
</div>
<p>The result is a probability density, so we can’t interpret it as a probability.  But it is proportional to the likelihood of the data, so we can use it to update the prior.</p>
<p>Here’s how we compute the likelihood of the data in each distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hypos</span> <span class="o">=</span> <span class="n">flipper_map</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="p">[</span><span class="n">flipper_map</span><span class="p">[</span><span class="n">hypo</span><span class="p">]</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">hypo</span> <span class="ow">in</span> <span class="n">hypos</span><span class="p">]</span>
<span class="n">likelihood</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.054732511875530694, 0.05172135615888162, 5.8660453661990634e-05]
</pre></div>
</div>
</div>
</div>
<p>Now we’re ready to do the update.</p>
</div>
<div class="section" id="the-update">
<h2>The Update<a class="headerlink" href="#the-update" title="Permalink to this headline">¶</a></h2>
<p>As usual I’ll use a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> to represent the prior distribution.  For simplicity, let’s assume that the three species are equally likely.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">empiricaldist</span> <span class="kn">import</span> <span class="n">Pmf</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">hypos</span><span class="p">)</span>
<span class="n">prior</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>0.333333</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now we can do the update in the usual way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
<span class="n">posterior</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>0.513860</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>0.485589</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>0.000551</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>A penguin with a 193 mm flipper is unlikely to be a Gentoo, but might be either an Adélie or Chinstrap (assuming that the three species were equally likely before the measurement).</p>
<p>The following function encapsulates the steps we just ran.
It takes a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> representing the prior distribution, the observed data, and a map from each hypothesis to the distribution of the feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_penguin</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">norm_map</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update hypothetical species.&quot;&quot;&quot;</span>
    <span class="n">hypos</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">qs</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="p">[</span><span class="n">norm_map</span><span class="p">[</span><span class="n">hypo</span><span class="p">]</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">hypo</span> <span class="ow">in</span> <span class="n">hypos</span><span class="p">]</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span>
    <span class="n">posterior</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">posterior</span>
</pre></div>
</div>
</div>
</div>
<p>The return value is the posterior distribution.</p>
<p>Here’s the previous example again, using <code class="docutils literal notranslate"><span class="pre">update_penguin</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior1</span> <span class="o">=</span> <span class="n">update_penguin</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="mi">193</span><span class="p">,</span> <span class="n">flipper_map</span><span class="p">)</span>
<span class="n">posterior1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>0.513860</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>0.485589</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>0.000551</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>As we saw in the CDFs, flipper length does not distinguish strongly between Adélie and Chinstrap penguins.</p>
<p>But culmen length <em>can</em> make this distinction, so let’s use it to do a second round of classification.
First we estimate distributions of culmen length for each species like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">culmen_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now suppose we see a penguin with culmen length 48 mm.
We can use this data to update the prior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior2</span> <span class="o">=</span> <span class="n">update_penguin</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="n">culmen_map</span><span class="p">)</span>
<span class="n">posterior2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>0.001557</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>0.474658</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>0.523785</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>A penguin with culmen length 48 mm is about equally likely to be a Chinstrap or Gentoo.</p>
<p>Using one feature at a time, we can often rule out one species or another, but we generally can’t identify species with confidence.
We can do better using multiple features.</p>
</div>
<div class="section" id="naive-bayesian-classification">
<h2>Naive Bayesian Classification<a class="headerlink" href="#naive-bayesian-classification" title="Permalink to this headline">¶</a></h2>
<p>To make it easier to do multiple updates, I’ll use the following function, which takes a prior <code class="docutils literal notranslate"><span class="pre">Pmf</span></code>, a sequence of measurements and a corresponding sequence of dictionaries containing estimated distributions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_naive</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data_seq</span><span class="p">,</span> <span class="n">norm_maps</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Naive Bayesian classifier</span>
<span class="sd">    </span>
<span class="sd">    prior: Pmf</span>
<span class="sd">    data_seq: sequence of measurements</span>
<span class="sd">    norm_maps: sequence of maps from species to distribution</span>
<span class="sd">    </span>
<span class="sd">    returns: Pmf representing the posterior distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">norm_map</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data_seq</span><span class="p">,</span> <span class="n">norm_maps</span><span class="p">):</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">update_penguin</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">norm_map</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">posterior</span>
</pre></div>
</div>
</div>
</div>
<p>It performs a series of updates, using one variable at a time, and returns the posterior <code class="docutils literal notranslate"><span class="pre">Pmf</span></code>.</p>
<p>To test it, I’ll use the same features we looked at in the previous section: culmen length and flipper length.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">,</span> <span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">]</span>
<span class="n">norm_maps</span> <span class="o">=</span> <span class="p">[</span><span class="n">flipper_map</span><span class="p">,</span> <span class="n">culmen_map</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now suppose we find a penguin with flipper length 193 mm and culmen length 48.
Here’s the update:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_seq</span> <span class="o">=</span> <span class="mi">193</span><span class="p">,</span> <span class="mi">48</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">update_naive</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data_seq</span><span class="p">,</span> <span class="n">norm_maps</span><span class="p">)</span>
<span class="n">posterior</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>0.003455</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>0.995299</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>0.001246</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is almost certain to be a Chinstrap.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior</span><span class="o">.</span><span class="n">max_prob</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Chinstrap&#39;
</pre></div>
</div>
</div>
</div>
<p>We can loop through the dataset and classify each penguin with these two features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">data_seq</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">colnames</span><span class="p">]</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">update_naive</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data_seq</span><span class="p">,</span> <span class="n">norm_maps</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">max_prob</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This loop adds a column called <code class="docutils literal notranslate"><span class="pre">Classification</span></code> to the <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>; it contains the species with the maximum posterior probability for each penguin.</p>
<p>So let’s see how many we got right.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>344
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">valid</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()</span>
<span class="n">valid</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>342
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">same</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Species2&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span>
<span class="n">same</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>324
</pre></div>
</div>
</div>
</div>
<p>There are 344 penguins in the dataset, but two of them are missing measurements, so we have 342 valid cases.
Of those, 324 are classified correctly, which is almost 95%.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">same</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">valid</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9473684210526315
</pre></div>
</div>
</div>
</div>
<p>The following function encapsulates these steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the accuracy of classification.&quot;&quot;&quot;</span>
    <span class="n">valid</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()</span>
    <span class="n">same</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Species2&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">same</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">valid</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The classifier we used in this section is called “naive” because it ignores correlations between the features.  To see why that matters, I’ll make a less naive classifier: one that takes into account the joint distribution of the features.</p>
</div>
<div class="section" id="joint-distributions">
<h2>Joint Distributions<a class="headerlink" href="#joint-distributions" title="Permalink to this headline">¶</a></h2>
<p>I’ll start by making a scatter plot of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">var1</span><span class="p">,</span> <span class="n">var2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a scatter plot.&quot;&quot;&quot;</span>
    <span class="n">grouped</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Species2&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">species</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">grouped</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="n">var1</span><span class="p">],</span> <span class="n">group</span><span class="p">[</span><span class="n">var2</span><span class="p">],</span>
                 <span class="n">label</span><span class="o">=</span><span class="n">species</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    
    <span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="n">var1</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="n">var2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s a scatter plot of culmen length and flipper length for the three species.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">var1</span> <span class="o">=</span> <span class="s1">&#39;Flipper Length (mm)&#39;</span>
<span class="n">var2</span> <span class="o">=</span> <span class="s1">&#39;Culmen Length (mm)&#39;</span>
<span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">var1</span><span class="p">,</span> <span class="n">var2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_78_0.png" src="_images/chap12_78_0.png" />
</div>
</div>
<p>Within each species, the joint distribution of these measurements forms an oval shape, at least roughly.  The orientation of the ovals is along a diagonal, which indicates that there is a correlation between culmen length and flipper length.</p>
<p>If we ignore these correlations, we are assuming that the features are independent.  To see what that looks like, I’ll make a joint distribution for each species assuming independence.</p>
<p>The following function makes a discrete <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> that approximates a normal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_pmf_norm</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">sigmas</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">101</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a Pmf approximation to a normal distribution.&quot;&quot;&quot;</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">dist</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="n">low</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">-</span> <span class="n">sigmas</span> <span class="o">*</span> <span class="n">std</span>
    <span class="n">high</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">sigmas</span> <span class="o">*</span> <span class="n">std</span>
    <span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">qs</span><span class="p">)</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">qs</span><span class="p">)</span>
    <span class="n">pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pmf</span>
</pre></div>
</div>
</div>
</div>
<p>We can use it, along with <code class="docutils literal notranslate"><span class="pre">make_joint</span></code>, to make a joint distribution of culmen length and flipper length for each species.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">make_joint</span>

<span class="n">joint_map</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">species</span> <span class="ow">in</span> <span class="n">hypos</span><span class="p">:</span>
    <span class="n">pmf1</span> <span class="o">=</span> <span class="n">make_pmf_norm</span><span class="p">(</span><span class="n">flipper_map</span><span class="p">[</span><span class="n">species</span><span class="p">])</span>
    <span class="n">pmf2</span> <span class="o">=</span> <span class="n">make_pmf_norm</span><span class="p">(</span><span class="n">culmen_map</span><span class="p">[</span><span class="n">species</span><span class="p">])</span>
    <span class="n">joint_map</span><span class="p">[</span><span class="n">species</span><span class="p">]</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">pmf1</span><span class="p">,</span> <span class="n">pmf2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The following figure compares a scatter plot of the data to the contours of the joint distributions, assuming independence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">plot_contour</span>

<span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">var1</span><span class="p">,</span> <span class="n">var2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">species</span> <span class="ow">in</span> <span class="n">hypos</span><span class="p">:</span>
    <span class="n">plot_contour</span><span class="p">(</span><span class="n">joint_map</span><span class="p">[</span><span class="n">species</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_84_0.png" src="_images/chap12_84_0.png" />
</div>
</div>
<p>The contours of a joint normal distribution form ellipses.
In this example, because the features are uncorrelated, the ellipses are aligned with the axes.
But they are not well aligned with the data.</p>
<p>We can make a better model of the data, and use it to compute better likelihoods, with a multivariate normal distribution.</p>
</div>
<div class="section" id="multivariate-normal-distribution">
<h2>Multivariate Normal Distribution<a class="headerlink" href="#multivariate-normal-distribution" title="Permalink to this headline">¶</a></h2>
<p>As we have seen, a univariate normal distribution is characterized by its mean and standard deviation.</p>
<p>A multivariate normal distribution is characterized by the means of the features and the <strong>covariance matrix</strong>, which contains <strong>variances</strong>, which quantify the spread of the features, and the <strong>covariances</strong>, which quantify the relationships among them.</p>
<p>We can use the data to estimate the means and covariance matrix for the population of penguins.
First I’ll select the columns we want.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="n">var1</span><span class="p">,</span> <span class="n">var2</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<p>And compute the means.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">mean</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Flipper Length (mm)    200.915205
Culmen Length (mm)      43.921930
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can also compute the covariance matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cov</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">cov</span><span class="p">()</span>
<span class="n">cov</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Flipper Length (mm)</th>
      <th>Culmen Length (mm)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Flipper Length (mm)</th>
      <td>197.731792</td>
      <td>50.375765</td>
    </tr>
    <tr>
      <th>Culmen Length (mm)</th>
      <td>50.375765</td>
      <td>29.807054</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The result is a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> with one row and one column for each feature.  The elements on the diagonal are the variances; the elements off the diagonal are covariances.</p>
<p>By themselves, variances and covariances are hard to interpret.  We can use them to compute standard deviations and correlation coefficients, which are easier to interpret, but the details of that calculation are not important right now.</p>
<p>Instead, we’ll pass the covariance matrix to <code class="docutils literal notranslate"><span class="pre">multivariate_normal</span></code>, which is a SciPy function that creates an object that represents a multivariate normal distribution.</p>
<p>As arguments it takes a sequence of means and a covariance matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>

<span class="n">multinorm</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The following function makes a <code class="docutils literal notranslate"><span class="pre">multivariate_normal</span></code> object for each species.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_multinorm_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">colnames</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a map from each species to a multivariate normal.&quot;&quot;&quot;</span>
    <span class="n">multinorm_map</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">grouped</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Species2&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">species</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">grouped</span><span class="p">:</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="n">colnames</span><span class="p">]</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">cov</span><span class="p">()</span>
        <span class="n">multinorm_map</span><span class="p">[</span><span class="n">species</span><span class="p">]</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">multinorm_map</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s how we make this map for the first two features, flipper length and culmen length.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">multinorm_map</span> <span class="o">=</span> <span class="n">make_multinorm_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="p">[</span><span class="n">var1</span><span class="p">,</span> <span class="n">var2</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="visualizing-a-multivariate-normal-distribution">
<h2>Visualizing a Multivariate Normal Distribution<a class="headerlink" href="#visualizing-a-multivariate-normal-distribution" title="Permalink to this headline">¶</a></h2>
<p>This section uses some NumPy magic to generate contour plots for multivariate normal distributions.  If that’s interesting for you, great!  Otherwise, feel free to skip to the results.  In the next section we’ll do the actual classification, which turns out to be easier than the visualization.</p>
<p>I’ll start by making a contour map for the distribution of features among Adélie penguins.<br />
Here are the univariate distributions for the two features we’ll use and the multivariate distribution we just computed.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">norm1</span> <span class="o">=</span> <span class="n">flipper_map</span><span class="p">[</span><span class="s1">&#39;Adelie&#39;</span><span class="p">]</span>
<span class="n">norm2</span> <span class="o">=</span> <span class="n">culmen_map</span><span class="p">[</span><span class="s1">&#39;Adelie&#39;</span><span class="p">]</span>
<span class="n">multinorm</span> <span class="o">=</span> <span class="n">multinorm_map</span><span class="p">[</span><span class="s1">&#39;Adelie&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>I’ll make a discrete <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> approximation for each of the univariate distributions.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmf1</span> <span class="o">=</span> <span class="n">make_pmf_norm</span><span class="p">(</span><span class="n">norm1</span><span class="p">)</span>
<span class="n">pmf2</span> <span class="o">=</span> <span class="n">make_pmf_norm</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And use them to make a mesh grid that contains all pairs of values.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">pmf1</span><span class="o">.</span><span class="n">qs</span><span class="p">,</span> <span class="n">pmf2</span><span class="o">.</span><span class="n">qs</span><span class="p">)</span>
<span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101)
</pre></div>
</div>
</div>
</div>
<p>The mesh is represented by two arrays: the first contains the quantities from <code class="docutils literal notranslate"><span class="pre">pmf1</span></code> along the <code class="docutils literal notranslate"><span class="pre">x</span></code> axis; the second contains the quantities from <code class="docutils literal notranslate"><span class="pre">pmf2</span></code> along the <code class="docutils literal notranslate"><span class="pre">y</span></code> axis.</p>
<p>In order to evaluate the multivariate distribution for each pair of values, we have to “stack” the arrays.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">))</span>
<span class="n">pos</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101, 2)
</pre></div>
</div>
</div>
</div>
<p>The result is a 3-D array that you can think of as a 2-D array of pairs.  When we pass this array to <code class="docutils literal notranslate"><span class="pre">multinorm.pdf</span></code>, it evaluates the probability density function of the distribution for each pair of values.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">densities</span> <span class="o">=</span> <span class="n">multinorm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
<span class="n">densities</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101)
</pre></div>
</div>
</div>
</div>
<p>The result is an array of probability densities.  If we put them in a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> and normalize them, the result is a discrete approximation of the joint distribution of the two features.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">normalize</span>

<span class="n">joint</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">densities</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">pmf1</span><span class="o">.</span><span class="n">qs</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">pmf2</span><span class="o">.</span><span class="n">qs</span><span class="p">)</span>
<span class="n">normalize</span><span class="p">(</span><span class="n">joint</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>15.871343639913828
</pre></div>
</div>
</div>
</div>
<p>Here’s what the result looks like.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_contour</span><span class="p">(</span><span class="n">joint</span><span class="p">)</span>
<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="n">var1</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="n">var2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_111_0.png" src="_images/chap12_111_0.png" />
</div>
</div>
<p>The contours of a multivariate normal distribution are still ellipses, but now that we have taken into account the correlation between the features, the ellipses are no longer aligned with the axes.</p>
<p>The following function encapsulate the steps we just did.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_joint</span><span class="p">(</span><span class="n">norm1</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">multinorm</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a joint distribution.</span>
<span class="sd">    </span>
<span class="sd">    norm1: `norm` object representing the distribution of the first feature</span>
<span class="sd">    norm2: `norm` object representing the distribution of the second feature</span>
<span class="sd">    multinorm: `multivariate_normal` object representing the joint distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pmf1</span> <span class="o">=</span> <span class="n">make_pmf_norm</span><span class="p">(</span><span class="n">norm1</span><span class="p">)</span>
    <span class="n">pmf2</span> <span class="o">=</span> <span class="n">make_pmf_norm</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">pmf1</span><span class="o">.</span><span class="n">qs</span><span class="p">,</span> <span class="n">pmf2</span><span class="o">.</span><span class="n">qs</span><span class="p">)</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">))</span>
    <span class="n">densities</span> <span class="o">=</span> <span class="n">multinorm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
    <span class="n">joint</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">densities</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">pmf1</span><span class="o">.</span><span class="n">qs</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">pmf2</span><span class="o">.</span><span class="n">qs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">joint</span>
</pre></div>
</div>
</div>
</div>
<p>The following figure shows a scatter plot of the data along with the contours of the multivariate normal distribution for each species.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">var1</span><span class="p">,</span> <span class="n">var2</span><span class="p">)</span>

<span class="k">for</span> <span class="n">species</span> <span class="ow">in</span> <span class="n">hypos</span><span class="p">:</span>
    <span class="n">norm1</span> <span class="o">=</span> <span class="n">flipper_map</span><span class="p">[</span><span class="n">species</span><span class="p">]</span>
    <span class="n">norm2</span> <span class="o">=</span> <span class="n">culmen_map</span><span class="p">[</span><span class="n">species</span><span class="p">]</span>
    <span class="n">multinorm</span> <span class="o">=</span> <span class="n">multinorm_map</span><span class="p">[</span><span class="n">species</span><span class="p">]</span>
    <span class="n">joint</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">norm1</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">multinorm</span><span class="p">)</span>
    <span class="n">plot_contour</span><span class="p">(</span><span class="n">joint</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_115_0.png" src="_images/chap12_115_0.png" />
</div>
</div>
<p>Because the multivariate normal distribution takes into account the correlations between features, it is a better model for the data.  And there is less overlap in the contours of the three distributions, which suggests that they should yield better classifications.</p>
</div>
<div class="section" id="a-less-naive-classifier">
<h2>A Less Naive Classifier<a class="headerlink" href="#a-less-naive-classifier" title="Permalink to this headline">¶</a></h2>
<p>In a previous section we used <code class="docutils literal notranslate"><span class="pre">update_penguin</span></code> to update a prior <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> based on observed data and a collection of <code class="docutils literal notranslate"><span class="pre">norm</span></code> objects that model the distribution of observations under each hypothesis.  Here it is again:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_penguin</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">norm_map</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update hypothetical species.&quot;&quot;&quot;</span>
    <span class="n">hypos</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">qs</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="p">[</span><span class="n">norm_map</span><span class="p">[</span><span class="n">hypo</span><span class="p">]</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">hypo</span> <span class="ow">in</span> <span class="n">hypos</span><span class="p">]</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span>
    <span class="n">posterior</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">posterior</span>
</pre></div>
</div>
</div>
</div>
<p>Last time we used this function, the values in <code class="docutils literal notranslate"><span class="pre">norm_map</span></code> were <code class="docutils literal notranslate"><span class="pre">norm</span></code> objects, but it also works if they are <code class="docutils literal notranslate"><span class="pre">multivariate_normal</span></code> objects.</p>
<p>We can use it to classify a penguin with flipper length 193 and culmen length 48:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="mi">193</span><span class="p">,</span> <span class="mi">48</span>
<span class="n">update_penguin</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">multinorm_map</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>0.002740</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>0.997257</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>0.000003</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>A penguin with those measurements is almost certainly a Chinstrap.</p>
<p>Now let’s see if this classifier does any better than the naive Bayesian classifier.
I’ll apply it to each penguin in the dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">colnames</span><span class="p">]</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">update_penguin</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">multinorm_map</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>And compute the accuracy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9532163742690059
</pre></div>
</div>
</div>
</div>
<p>It turns out to be only a little better: the accuracy is 95.3%, compared to 94.7% for the naive Bayesian classifier.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this chapter, we implemented a naive Bayesian classifier, which is “naive” in the sense that it assumes that the features it uses for classification are independent.</p>
<p>To see how bad that assumption is, we also implemented a classifier that uses a multivariate normal distribution to model the joint distribution of the features, which includes their dependencies.</p>
<p>In this example, the non-naive classifier is only marginally better.
In one way, that’s disappointing.  After all that work, it would have been nice to see a bigger improvement.
But in another way, it’s good news.  In general, a naive Bayesian classifier is easier to implement and requires less computation.  If it works nearly as well as a more complex algorithm, it might be a good choice for practical purposes.</p>
<p>Speaking of practical purposes, you might have noticed that this example isn’t very useful.  If we want to identify the species of a penguin, there are easier ways than measuring its flippers and beak.</p>
<p>But there <em>are</em> scientific uses for this type of classification.  One of them is the subject of the research paper we started with: <a class="reference external" href="https://en.wikipedia.org/wiki/Sexual_dimorphism">sexual dimorphism</a>, that is, differences in shape between male and female animals.</p>
<p>In some species, like angler fish, males and females look very different.  In other species, like mockingbirds, they are difficult to tell apart.
And dimorphism is worth studying because it provides insight into social behavior, sexual selection, and evolution.</p>
<p>One way to quantify the degree of sexual dimorphism in a species is to use a classification algorithm like the one in this chapter.  If you can find a set of features that makes it possible to classify individuals by sex with high accuracy, that’s evidence of high dimorphism.</p>
<p>As an exercise, you can use the dataset from this chapter to classify penguins by sex and see which of the three species is the most dimorphic.</p>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p><strong>Exercise:</strong>  In my example I used culmen length and flipper length because they seemed to provide the most power to distinguish the three species.  But maybe we can do better by using more features.</p>
<p>Make a naive Bayesian classifier that uses all four measurements in the dataset: culmen length and depth, flipper length, and body mass.
Is it more accurate than the model with two features?</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here are the norm maps for the other two features</span>

<span class="n">depth_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;Culmen Depth (mm)&#39;</span><span class="p">)</span>
<span class="n">mass_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;Body Mass (g)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># And here are sequences for the features and the norm maps</span>

<span class="n">colnames4</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">,</span> <span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">,</span> 
             <span class="s1">&#39;Culmen Depth (mm)&#39;</span><span class="p">,</span> <span class="s1">&#39;Body Mass (g)&#39;</span><span class="p">]</span>
<span class="n">norm_maps4</span> <span class="o">=</span> <span class="p">[</span><span class="n">culmen_map</span><span class="p">,</span> <span class="n">flipper_map</span><span class="p">,</span> 
              <span class="n">depth_map</span><span class="p">,</span> <span class="n">mass_map</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Now let&#39;s classify and compute accuracy.</span>

<span class="c1"># We can do a little better with all four features,</span>
<span class="c1"># almost 97% accuracy</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">data_seq</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">colnames4</span><span class="p">]</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">update_naive</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data_seq</span><span class="p">,</span> <span class="n">norm_maps4</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">max_prob</span><span class="p">()</span>

<span class="n">accuracy</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9678362573099415
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise:</strong>  One of the reasons the penguin dataset was collected was to quantify sexual dimorphism in different penguin species, that is, physical differences between male and female penguins.  One way to quantify dimorphism is to use measurements to classify penguins by sex.  If a species is more dimorphic, we expect to be able to classify them more accurately.</p>
<p>As an exercise, pick a species and use a Bayesian classifier (naive or not) to classify the penguins by sex.  Which features are most useful?  What accuracy can you achieve?</p>
<p>Note: One Gentoo penguin has an invalid value for <code class="docutils literal notranslate"><span class="pre">Sex</span></code>.  I used the following code to select one species and filter out invalid data.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gentoo</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Species2&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Gentoo&#39;</span><span class="p">)</span>
<span class="n">subset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">gentoo</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MALE      61
FEMALE    58
Name: Sex, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">valid</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;.&#39;</span>
<span class="n">valid</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>344
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">subset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">valid</span> <span class="o">&amp;</span> <span class="n">gentoo</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>OK, you can finish it off from here.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here are the feature distributions grouped by sex</span>

<span class="n">plot_cdfs</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_139_0.png" src="_images/chap12_139_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">plot_cdfs</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Culmen Depth (mm)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_140_0.png" src="_images/chap12_140_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">plot_cdfs</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_141_0.png" src="_images/chap12_141_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">plot_cdfs</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Body Mass (g)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap12_142_0.png" src="_images/chap12_142_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here are the norm maps for the features, grouped by sex</span>

<span class="n">culmen_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
<span class="n">flipper_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
<span class="n">depth_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Culmen Depth (mm)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
<span class="n">mass_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Body Mass (g)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># And here are the sequences we need for `update_naive`</span>

<span class="n">norm_maps4</span> <span class="o">=</span> <span class="p">[</span><span class="n">culmen_map</span><span class="p">,</span> <span class="n">flipper_map</span><span class="p">,</span> <span class="n">depth_map</span><span class="p">,</span> <span class="n">mass_map</span><span class="p">]</span>
<span class="n">colnames4</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">,</span> <span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">,</span> 
             <span class="s1">&#39;Culmen Depth (mm)&#39;</span><span class="p">,</span> <span class="s1">&#39;Body Mass (g)&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here&#39;s the prior</span>

<span class="n">hypos</span> <span class="o">=</span> <span class="n">culmen_map</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">hypos</span><span class="p">)</span>
<span class="n">prior</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>FEMALE</th>
      <td>0.5</td>
    </tr>
    <tr>
      <th>MALE</th>
      <td>0.5</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># And the update</span>

<span class="n">subset</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">subset</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">data_seq</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">colnames4</span><span class="p">]</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">update_naive</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data_seq</span><span class="p">,</span> <span class="n">norm_maps4</span><span class="p">)</span>
    <span class="n">subset</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">max_prob</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># This function computes accuracy</span>

<span class="k">def</span> <span class="nf">accuracy_sex</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the accuracy of classification.</span>
<span class="sd">    </span>
<span class="sd">    Compares columns Classification and Sex</span>
<span class="sd">    </span>
<span class="sd">    df: DataFrame</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">valid</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()</span>
    <span class="n">same</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">same</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">valid</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Using these features we can classify Gentoo penguins by</span>
<span class="c1"># sex with almost 92% accuracy</span>

<span class="n">accuracy_sex</span><span class="p">(</span><span class="n">subset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9186991869918699
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here&#39;s the whole process in a function so we can</span>
<span class="c1"># classify the other species</span>

<span class="k">def</span> <span class="nf">classify_by_sex</span><span class="p">(</span><span class="n">subset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Run the whole classification process.</span>
<span class="sd">    </span>
<span class="sd">    subset: DataFrame</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">culmen_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
    <span class="n">flipper_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
    <span class="n">depth_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Culmen Depth (mm)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
    <span class="n">mass_map</span> <span class="o">=</span> <span class="n">make_norm_map</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="s1">&#39;Body Mass (g)&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>

    <span class="n">norm_maps4</span> <span class="o">=</span> <span class="p">[</span><span class="n">culmen_map</span><span class="p">,</span> <span class="n">flipper_map</span><span class="p">,</span> <span class="n">depth_map</span><span class="p">,</span> <span class="n">mass_map</span><span class="p">]</span>

    <span class="n">hypos</span> <span class="o">=</span> <span class="n">culmen_map</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">hypos</span><span class="p">)</span>

    <span class="n">subset</span><span class="p">[</span><span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">subset</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
        <span class="n">data_seq</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">colnames4</span><span class="p">]</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">update_naive</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data_seq</span><span class="p">,</span> <span class="n">norm_maps4</span><span class="p">)</span>
        <span class="n">subset</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Classification&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">max_prob</span><span class="p">()</span>
        
    <span class="k">return</span> <span class="n">accuracy_sex</span><span class="p">(</span><span class="n">subset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here&#39;s the subset of Adelie penguins</span>

<span class="c1"># The accuracy is about 88%</span>

<span class="n">adelie</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Species2&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;Adelie&#39;</span>
<span class="n">subset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">adelie</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">classify_by_sex</span><span class="p">(</span><span class="n">subset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8807947019867549
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># And for Chinstrap, accuracy is about 92%</span>

<span class="n">chinstrap</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Species2&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;Chinstrap&#39;</span>
<span class="n">subset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">chinstrap</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">classify_by_sex</span><span class="p">(</span><span class="n">subset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9264705882352942
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># It looks like Gentoo and Chinstrap penguins are about equally</span>
<span class="c1"># dimorphic, Adelie penguins a little less so.</span>

<span class="c1"># All of these results are consistent with what&#39;s in the paper.</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="chap11.html" title="previous page">Comparison</a>
    <a class='right-next' id="next-link" href="chap13.html" title="next page">Inference</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Allen B. Downey<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>