
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Logistic Regression &#8212; Think Bayes</title>
    
  <link rel="stylesheet" href="_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.c441f2ba0852f4cabcb80105e3a46ae6.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Regression" href="chap17.html" />
    <link rel="prev" title="Mark and Recapture" href="chap15.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  
  <h1 class="site-logo" id="site-title">Think Bayes</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Think Bayes 2
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap01.html">
   Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap02.html">
   Bayes’s Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap03.html">
   Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap04.html">
   Estimating Proportions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap05.html">
   Estimating Counts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap06.html">
   Odds and Addends
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap07.html">
   Minimum, Maximum, and Mixture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap08.html">
   Poisson Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap09.html">
   Decision Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap10.html">
   Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap11.html">
   Comparison
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap12.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap13.html">
   Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap14.html">
   Survival Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap15.html">
   Mark and Recapture
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap17.html">
   Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap18.html">
   Conjugate Priors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap19.html">
   MCMC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap20.html">
   Approximate Bayesian Computation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Examples
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="redline.html">
   The Red Line Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="vaccine2.html">
   Estimating vaccine efficacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="usb.html">
   Flipping USB Connectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="sister.html">
   The Left Handed Sister Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bayes_dice.html">
   Bayesian Dice
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chap16.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/AllenDowney/ThinkBayes2"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/AllenDowney/ThinkBayes2/master?urlpath=tree/chap16.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#log-odds">
   Log Odds
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-space-shuttle-problem">
   The Space Shuttle Problem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prior-distribution">
   Prior Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#likelihood">
   Likelihood
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-update">
   The Update
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#marginal-distributions">
   Marginal Distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transforming-distributions">
   Transforming Distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#predictive-distributions">
   Predictive Distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#empirical-bayes">
   Empirical Bayes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="logistic-regression">
<h1>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h1>
<p>This chapter introduces two related topics: log odds and logistic regression.</p>
<p>In &lt;&lt;_BayessRule&gt;&gt;, we rewrote Bayes’s Theorem in terms of odds and derived Bayes’s Rule, which can be a convenient way to do a Bayesian update on paper or in your head.
In this chapter, we’ll look at Bayes’s Rule on a logarithmic scale, which provides insight into how we accumulate evidence through successive updates.</p>
<p>That leads directly to logistic regression, which is based on a linear model of the relationship between evidence and the log odds of a hypothesis.
As an example, we’ll use data from the Space Shuttle to explore the relationship between temperature and the probability of damage to the O-rings.</p>
<p>As an exercise, you’ll have a chance to model the relationship between a child’s age when they start school and their probability of being diagnosed with Attention Deficit Hyperactivity Disorder (ADHD).</p>
<div class="section" id="log-odds">
<h2>Log Odds<a class="headerlink" href="#log-odds" title="Permalink to this headline">¶</a></h2>
<p>When I was in grad school, I signed up for a class on the Theory of Computation.
On the first day of class, I was the first to arrive.
A few minutes later, another student arrived.</p>
<p>At the time, about 83% of the students in the computer science program <a class="reference external" href="https://www.aps.org/programs/education/statistics/fraction-phd.cfm">were male</a>, so I was mildly surprised to note that the other student was female.</p>
<p>When another female student arrived a few minutes later, I started to think I was in the wrong room.
When third female student arrived, I was confident I was in the wrong room.
And as it turned out, I was.</p>
<p>I’ll use this anecdote to demonstrate Bayes’s Rule on a logarithmic scale and show how it relates to logistic regression.</p>
<p>Using <span class="math notranslate nohighlight">\(H\)</span> to represent the hypothesis that I was in the right room, and <span class="math notranslate nohighlight">\(F\)</span> to represent the observation that the first other student was female, we can write Bayes’s Rule like this:</p>
<div class="math notranslate nohighlight">
\[O(H|F) = O(H) \frac{P(F|H)}{P(F|not H)}\]</div>
<p>Before I saw the other students, I was confident I was in the right room, so I might assign prior odds of 10:1 in favor:</p>
<div class="math notranslate nohighlight">
\[O(H) = 10\]</div>
<p>If I was in the right room, the likelihood of the first female student was about 17%.
If I was not in the right room, the likelihood of the first female student was more like 50%,</p>
<div class="math notranslate nohighlight">
\[\frac{P(F|H)}{P(F|not H)} = 17 / 50\]</div>
<p>So the likelihood ratio is close to 1/3.  Applying Bayes’s Rule, the posterior odds were</p>
<div class="math notranslate nohighlight">
\[O(H|F) = 10 / 3\]</div>
<p>After two students, the posterior odds were</p>
<div class="math notranslate nohighlight">
\[O(H|FF) = 10 / 9\]</div>
<p>And after three students:</p>
<div class="math notranslate nohighlight">
\[O(H|FFF) = 10 / 27\]</div>
<p>At that point, I was right to suspect I was in the wrong room.</p>
<p>The following table shows the odds after each update, the corresponding probabilities, and the change in probability after each step, expressed in percentage points.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prob</span><span class="p">(</span><span class="n">o</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">o</span> <span class="o">/</span> <span class="p">(</span><span class="n">o</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">,</span> <span class="s1">&#39;1 student&#39;</span><span class="p">,</span> <span class="s1">&#39;2 students&#39;</span><span class="p">,</span> <span class="s1">&#39;3 students&#39;</span><span class="p">]</span>

<span class="n">table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
<span class="n">table</span><span class="p">[</span><span class="s1">&#39;odds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="o">/</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="o">/</span><span class="mi">27</span><span class="p">]</span>
<span class="n">table</span><span class="p">[</span><span class="s1">&#39;prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prob</span><span class="p">(</span><span class="n">table</span><span class="p">[</span><span class="s1">&#39;odds&#39;</span><span class="p">])</span>
<span class="n">table</span><span class="p">[</span><span class="s1">&#39;prob diff&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;prob&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">table</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>odds</th>
      <th>prob</th>
      <th>prob diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>prior</th>
      <td>10.000000</td>
      <td>0.909091</td>
      <td>--</td>
    </tr>
    <tr>
      <th>1 student</th>
      <td>3.333333</td>
      <td>0.769231</td>
      <td>-13.986014</td>
    </tr>
    <tr>
      <th>2 students</th>
      <td>1.111111</td>
      <td>0.526316</td>
      <td>-24.291498</td>
    </tr>
    <tr>
      <th>3 students</th>
      <td>0.370370</td>
      <td>0.270270</td>
      <td>-25.604552</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Each update uses the same likelihood, but the changes in probability are not the same.  The first update decreases the probability by about 14 percentage points, the second by 24, and the third by 26.
That’s normal for this kind of update, and in fact it’s necessary; if the changes were the same size, we would quickly get into negative probabilities.</p>
<p>The odds follow a more obvious pattern.  Because each update multiplies the odds by the same likelihood ratio, the odds form a geometric sequence.
And that brings us to consider another way to represent uncertainty: <strong>log odds</strong>, which is the logarithm of odds, usually expressed using the natural log (base <span class="math notranslate nohighlight">\(e\)</span>).</p>
<p>Adding log odds to the table:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">table</span><span class="p">[</span><span class="s1">&#39;log odds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">table</span><span class="p">[</span><span class="s1">&#39;odds&#39;</span><span class="p">])</span>
<span class="n">table</span><span class="p">[</span><span class="s1">&#39;log odds diff&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;log odds&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span>
<span class="n">table</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>odds</th>
      <th>prob</th>
      <th>prob diff</th>
      <th>log odds</th>
      <th>log odds diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>prior</th>
      <td>10.000000</td>
      <td>0.909091</td>
      <td>--</td>
      <td>2.302585</td>
      <td>--</td>
    </tr>
    <tr>
      <th>1 student</th>
      <td>3.333333</td>
      <td>0.769231</td>
      <td>-13.986014</td>
      <td>1.203973</td>
      <td>-1.098612</td>
    </tr>
    <tr>
      <th>2 students</th>
      <td>1.111111</td>
      <td>0.526316</td>
      <td>-24.291498</td>
      <td>0.105361</td>
      <td>-1.098612</td>
    </tr>
    <tr>
      <th>3 students</th>
      <td>0.370370</td>
      <td>0.270270</td>
      <td>-25.604552</td>
      <td>-0.993252</td>
      <td>-1.098612</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>You might notice:</p>
<ul class="simple">
<li><p>When probability is greater than 0.5, odds are greater than 1, and log odds are positive.</p></li>
<li><p>When probability is less than 0.5, odds are less than 1, and log odds are negative.</p></li>
</ul>
<p>You might also notice that the log odds are equally spaced.
The change in log odds after each update is the logarithm of the likelihood ratio.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-1.0986122886681098
</pre></div>
</div>
</div>
</div>
<p>That’s true in this example, and we can show that it’s true in general by taking the log of both sides of Bayes’s Rule.</p>
<div class="math notranslate nohighlight">
\[\log O(H|F) = \log O(H) + \log \frac{P(F|H)}{P(F|not H)}\]</div>
<p>On a log odds scale, a Bayesian update is additive.  So if <span class="math notranslate nohighlight">\(F^x\)</span> means that <span class="math notranslate nohighlight">\(x\)</span> female students arrive while I am waiting, the posterior log odds that I am in the right room are:</p>
<div class="math notranslate nohighlight">
\[\log O(H|F^x) = \log O(H) + x \log \frac{P(F|H)}{P(F|not H)}\]</div>
<p>This equation represents a linear relationship between the log likelihood ratio and the posterior log odds.</p>
<p>In this example the linear equation is exact, but even when it’s not, it is common to use a linear function to model the relationship between an explanatory variable, <span class="math notranslate nohighlight">\(x\)</span>, and a dependent variable expressed in log odds, like this:</p>
<div class="math notranslate nohighlight">
\[\log O(H | x) = \beta_0 + \beta_1 x\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> are unknown parameters:</p>
<ul class="simple">
<li><p>The intercept, <span class="math notranslate nohighlight">\(\beta_0\)</span>, is the log odds of the hypothesis when <span class="math notranslate nohighlight">\(x\)</span> is 0.</p></li>
<li><p>The slope, <span class="math notranslate nohighlight">\(\beta_1\)</span>, is the log of the likelihood ratio.</p></li>
</ul>
<p>This equation is the basis of logistic regression.</p>
</div>
<div class="section" id="the-space-shuttle-problem">
<h2>The Space Shuttle Problem<a class="headerlink" href="#the-space-shuttle-problem" title="Permalink to this headline">¶</a></h2>
<p>As an example of logistic regression, I’ll solve a problem from Cameron Davidson-Pilon’s book, <a class="reference external" href="http://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC2.ipynb"><em>Bayesian Methods for Hackers</em></a>.  He writes:</p>
<blockquote>
<div><p>“On January 28, 1986, the twenty-fifth flight of the U.S. space shuttle program ended in disaster when one of the rocket boosters of the Shuttle Challenger exploded shortly after lift-off, killing all seven crew members. The presidential commission on the accident concluded that it was caused by the failure of an O-ring in a field joint on the rocket booster, and that this failure was due to a faulty design that made the O-ring unacceptably sensitive to a number of factors including outside temperature. Of the previous 24 flights, data were available on failures of O-rings on 23 (one was lost at sea), and these data were discussed on the evening preceding the Challenger launch, but unfortunately only the data corresponding to the 7 flights on which there was a damage incident were considered important and these were thought to show no obvious trend.”</p>
</div></blockquote>
<p>The dataset is originally from <a class="reference external" href="https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1989.10478858">this paper</a>, but also available from <a class="reference external" href="https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/data/challenger_data.csv">Davidson-Pilon</a>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/data/challenger_data.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>I’ll read the data and do some cleaning.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;challenger_data.csv&#39;</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># avoiding column names with spaces</span>
<span class="n">data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Damage Incident&#39;</span><span class="p">:</span> <span class="s1">&#39;Damage&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># dropping row 3, in which Damage Incident is NaN,</span>
<span class="c1"># and row 24, which is the record for the Challenger</span>
<span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># convert the Damage column to integer</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;Damage&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Damage&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Temperature</th>
      <th>Damage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1981-04-12</td>
      <td>66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1981-11-12</td>
      <td>70</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1982-03-22</td>
      <td>69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1982-01-11</td>
      <td>68</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1983-04-04</td>
      <td>67</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1983-06-18</td>
      <td>72</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1983-08-30</td>
      <td>73</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1983-11-28</td>
      <td>70</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1984-02-03</td>
      <td>57</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1984-04-06</td>
      <td>63</td>
      <td>1</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1984-08-30</td>
      <td>70</td>
      <td>1</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1984-10-05</td>
      <td>78</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>1984-11-08</td>
      <td>67</td>
      <td>0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>1985-01-24</td>
      <td>53</td>
      <td>1</td>
    </tr>
    <tr>
      <th>15</th>
      <td>1985-04-12</td>
      <td>67</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1985-04-29</td>
      <td>75</td>
      <td>0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>1985-06-17</td>
      <td>70</td>
      <td>0</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1985-07-29</td>
      <td>81</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1985-08-27</td>
      <td>76</td>
      <td>0</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1985-10-03</td>
      <td>79</td>
      <td>0</td>
    </tr>
    <tr>
      <th>21</th>
      <td>1985-10-30</td>
      <td>75</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22</th>
      <td>1985-11-26</td>
      <td>76</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23</th>
      <td>1986-01-12</td>
      <td>58</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here are the first few rows:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Temperature</th>
      <th>Damage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1981-04-12</td>
      <td>66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1981-11-12</td>
      <td>70</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1982-03-22</td>
      <td>69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1982-01-11</td>
      <td>68</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1983-04-04</td>
      <td>67</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The columns are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Date</span></code>: The date of launch,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Temperature</span></code>: Outside temperature in Fahrenheit, and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Damage</span></code>: <code class="docutils literal notranslate"><span class="pre">1</span></code> if there was a damage incident and <code class="docutils literal notranslate"><span class="pre">0</span></code> otherwise.</p></li>
</ul>
<p>There are 23 launches in the dataset, 7 with damage incidents.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Damage&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(23, 7)
</pre></div>
</div>
</div>
</div>
<p>The following figure shows the relationship between damage and temperature.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">decorate</span>

<span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot damage as a function of temperature.</span>
<span class="sd">    </span>
<span class="sd">    data: DataFrame</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Temperature&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Damage&#39;</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> 
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>

    <span class="n">decorate</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Probability of damage&quot;</span><span class="p">,</span>
         <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Outside temperature (deg F)&quot;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Damage to O-Rings vs Temperature&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_28_0.png" src="_images/chap16_28_0.png" />
</div>
</div>
<p>When the outside temperature was below 65 degrees, there was always damage to the O-rings.  When the temperature was above 65 degrees, there was usually no damage.</p>
<p>Based on this figure, it seems plausible that the probability of damage is related to temperature.  If we assume this probability follows a logistic model, we can write:</p>
<div class="math notranslate nohighlight">
\[\log O(H | x) = \beta_0 + \beta_1 x\]</div>
<p>where <span class="math notranslate nohighlight">\(H\)</span> is the hypothesis that the O-rings will be damaged, <span class="math notranslate nohighlight">\(x\)</span> is temperature, and <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> are the parameters we will estimate.
For reasons I’ll explain soon, I’ll define <span class="math notranslate nohighlight">\(x\)</span> to be temperature shifted by an offset so its mean is 0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">offset</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Temperature&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Temperature&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">offset</span>
<span class="n">offset</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>70.0
</pre></div>
</div>
</div>
</div>
<p>And for consistency I’ll create a copy of the <code class="docutils literal notranslate"><span class="pre">Damage</span></code> columns called <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Damage&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Before doing a Bayesian update, I’ll use <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> to run a conventional (non-Bayesian) logistic regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;y ~ x&#39;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">disp</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">results</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   -1.208490
x           -0.232163
dtype: float64
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">results</span></code> contains a “point estimate” for each parameter, that is, a single value rather than a posterior distribution.</p>
<p>The intercept is about -1.2, and the estimated slope is about -0.23.
To see what these parameters mean, I’ll use them to compute probabilities for a range of temperatures.
Here’s the range:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inter</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">]</span>
<span class="n">slope</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">53</span><span class="p">,</span> <span class="mi">83</span><span class="p">)</span> <span class="o">-</span> <span class="n">offset</span>
</pre></div>
</div>
</div>
</div>
<p>We can use the logistic regression equation to compute log odds:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_odds</span> <span class="o">=</span> <span class="n">inter</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xs</span>
</pre></div>
</div>
</div>
</div>
<p>And then convert to probabilities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">odds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_odds</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">odds</span> <span class="o">/</span> <span class="p">(</span><span class="n">odds</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ps</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.4155141126966854
</pre></div>
</div>
</div>
</div>
<p>Converting log odds to probabilities is a common enough operation that it has a name, <code class="docutils literal notranslate"><span class="pre">expit</span></code>, and SciPy provides a function that computes it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">expit</span>

<span class="n">ps</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">inter</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ps</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.4155141126966854
</pre></div>
</div>
</div>
</div>
<p>Here’s what the logistic model looks like with these estimated parameters.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="o">+</span><span class="n">offset</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_46_0.png" src="_images/chap16_46_0.png" />
</div>
</div>
<p>At low temperatures, the probability of damage is high; at high temperatures, it drops off to near 0.</p>
<p>But that’s based on conventional logistic regression.
Now we’ll do the Bayesian version.</p>
</div>
<div class="section" id="prior-distribution">
<h2>Prior Distribution<a class="headerlink" href="#prior-distribution" title="Permalink to this headline">¶</a></h2>
<p>I’ll use uniform distributions for both parameters, using the point estimates from the previous section to help me choose the upper and lower bounds.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">make_uniform</span>

<span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
<span class="n">prior_inter</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="s1">&#39;Intercept&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
<span class="n">prior_slope</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="s1">&#39;Slope&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can use <code class="docutils literal notranslate"><span class="pre">make_joint</span></code> to construct the joint prior distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">make_joint</span>

<span class="n">joint</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">prior_inter</span><span class="p">,</span> <span class="n">prior_slope</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The values of <code class="docutils literal notranslate"><span class="pre">intercept</span></code> run across the columns, the values of <code class="docutils literal notranslate"><span class="pre">slope</span></code> run down the rows.</p>
<p>For this problem, it will be convenient to “stack” the prior so the parameters are levels in a <code class="docutils literal notranslate"><span class="pre">MultiIndex</span></code>, and put the result in a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">empiricaldist</span> <span class="kn">import</span> <span class="n">Pmf</span>

<span class="n">joint_pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">joint</span><span class="o">.</span><span class="n">stack</span><span class="p">())</span>
<span class="n">joint_pmf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>Slope</th>
      <th>Intercept</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">-0.8</th>
      <th>-5.00</th>
      <td>0.000098</td>
    </tr>
    <tr>
      <th>-4.94</th>
      <td>0.000098</td>
    </tr>
    <tr>
      <th>-4.88</th>
      <td>0.000098</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">joint_pmf</span></code> is a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> with two levels in the index, one for each parameter.  That makes it easy to loop through possible pairs of parameters, as we’ll see in the next section.</p>
</div>
<div class="section" id="likelihood">
<h2>Likelihood<a class="headerlink" href="#likelihood" title="Permalink to this headline">¶</a></h2>
<p>To do the update, we have to compute the likelihood of the data for each possible pair of parameters.</p>
<p>To make that easier, I’m going to group the data by temperature, <code class="docutils literal notranslate"><span class="pre">x</span></code>, and count the number of launches and damage incidents at each temperature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grouped</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">])</span>
<span class="n">grouped</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>sum</th>
    </tr>
    <tr>
      <th>x</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>-17.0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>-13.0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>-12.0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>-7.0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>-4.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The result is a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> with two columns: <code class="docutils literal notranslate"><span class="pre">count</span></code> is the number of launches at each temperature; <code class="docutils literal notranslate"><span class="pre">sum</span></code> is the number of damage incidents.
To be consistent with the parameters of the binomial distributions, I’ll assign them to variables named <code class="docutils literal notranslate"><span class="pre">ns</span></code> and <code class="docutils literal notranslate"><span class="pre">ks</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ns</span> <span class="o">=</span> <span class="n">grouped</span><span class="p">[</span><span class="s1">&#39;count&#39;</span><span class="p">]</span>
<span class="n">ks</span> <span class="o">=</span> <span class="n">grouped</span><span class="p">[</span><span class="s1">&#39;sum&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>To compute the likelihood of the data, let’s assume temporarily that the parameters we just estimated, <code class="docutils literal notranslate"><span class="pre">slope</span></code> and <code class="docutils literal notranslate"><span class="pre">inter</span></code>,  are correct.</p>
<p>We can use them to compute the probability of damage at each launch temperature, like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">grouped</span><span class="o">.</span><span class="n">index</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">inter</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ps</span></code> contains the probability of damage for each launch temperature, according to the model.</p>
<p>Now, for each temperature we have <code class="docutils literal notranslate"><span class="pre">ns</span></code>, <code class="docutils literal notranslate"><span class="pre">ps</span></code>, and <code class="docutils literal notranslate"><span class="pre">ks</span></code>;
we can use the binomial distribution to compute the likelihood of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>

<span class="n">likes</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">ps</span><span class="p">)</span>
<span class="n">likes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.93924781, 0.85931657, 0.82884484, 0.60268105, 0.56950687,
       0.24446388, 0.67790595, 0.72637895, 0.18815003, 0.8419509 ,
       0.87045398, 0.15645171, 0.86667894, 0.95545945, 0.96435859,
       0.97729671])
</pre></div>
</div>
</div>
</div>
<p>Each element of <code class="docutils literal notranslate"><span class="pre">likes</span></code> is the probability of seeing <code class="docutils literal notranslate"><span class="pre">k</span></code> damage incidents in <code class="docutils literal notranslate"><span class="pre">n</span></code> launches if the probability of damage is <code class="docutils literal notranslate"><span class="pre">p</span></code>.
The likelihood of the whole dataset is the product of this array.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likes</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0004653644508250066
</pre></div>
</div>
</div>
</div>
<p>That’s how we compute the likelihood of the data for a particular pair of parameters.
Now we can compute the likelihood of the data for all possible pairs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">joint_pmf</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">slope</span><span class="p">,</span> <span class="n">inter</span> <span class="ow">in</span> <span class="n">joint_pmf</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">inter</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xs</span><span class="p">)</span>
    <span class="n">likes</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">ps</span><span class="p">)</span>
    <span class="n">likelihood</span><span class="p">[</span><span class="n">slope</span><span class="p">,</span> <span class="n">inter</span><span class="p">]</span> <span class="o">=</span> <span class="n">likes</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
<p>To initialize <code class="docutils literal notranslate"><span class="pre">likelihood</span></code>, we make a copy of <code class="docutils literal notranslate"><span class="pre">joint_pmf</span></code>, which is a convenient way to make sure that <code class="docutils literal notranslate"><span class="pre">likelihood</span></code> has the same type, index, and data type as <code class="docutils literal notranslate"><span class="pre">joint_pmf</span></code>.</p>
<p>The loop iterates through the parameters.  For each possible pair, it uses the logistic model to compute <code class="docutils literal notranslate"><span class="pre">ps</span></code>, computes the likelihood of the data, and assigns the result to a row in <code class="docutils literal notranslate"><span class="pre">likelihood</span></code>.</p>
</div>
<div class="section" id="the-update">
<h2>The Update<a class="headerlink" href="#the-update" title="Permalink to this headline">¶</a></h2>
<p>Now we can compute the posterior distribution in the usual way.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_pmf</span> <span class="o">=</span> <span class="n">joint_pmf</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior_pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Because we used a uniform prior, the parameter pair with the highest likelihood is also the pair with maximum posterior probability:</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">posterior_pmf</span><span class="o">.</span><span class="n">max_prob</span><span class="p">(),</span>
          <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;slope&#39;</span><span class="p">,</span> <span class="s1">&#39;inter&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>slope   -0.233
inter   -1.220
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>So we can confirm that the results of the Bayesian update are consistent with the maximum likelihood estimate computed by StatsModels:</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   -1.208490
x           -0.232163
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>They are approximately the same, within the precision of the grid we’re using.</p>
<p>If we unstack the posterior <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> we can make a contour plot of the joint posterior distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">plot_contour</span>

<span class="n">joint_posterior</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>
<span class="n">plot_contour</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">)</span>
<span class="n">decorate</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Joint posterior distribution&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_77_0.png" src="_images/chap16_77_0.png" />
</div>
</div>
<p>The ovals in the contour plot are aligned along a diagonal, which indicates that there is some correlation between <code class="docutils literal notranslate"><span class="pre">slope</span></code> and <code class="docutils literal notranslate"><span class="pre">inter</span></code> in the posterior distribution.</p>
<p>But the correlation is weak, which is one of the reasons we subtracted off the mean launch temperature when we computed <code class="docutils literal notranslate"><span class="pre">x</span></code>; centering the data minimizes the correlation between the parameters.</p>
<p><strong>Exercise:</strong> To see why this matters, go back and set <code class="docutils literal notranslate"><span class="pre">offset=60</span></code> and run the analysis again.
The slope should be the same, but the intercept will be different.  And if you plot the joint distribution, the contours you get will be elongated, indicating stronger correlation between the estimated parameters.</p>
<p>In theory, this correlation is not a problem, but in practice it is.  With uncentered data, the posterior distribution is more spread out, so it’s harder to cover with the joint prior distribution.
Centering the data maximizes the precision of the estimates; with uncentered data, we have to do more computation to get the same precision.</p>
</div>
<div class="section" id="marginal-distributions">
<h2>Marginal Distributions<a class="headerlink" href="#marginal-distributions" title="Permalink to this headline">¶</a></h2>
<p>Finally, we can extract the marginal distributions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">marginal</span>

<span class="n">marginal_inter</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">marginal_slope</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s the posterior distribution of <code class="docutils literal notranslate"><span class="pre">inter</span></code>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">marginal_inter</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;intercept&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of intercept&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_83_0.png" src="_images/chap16_83_0.png" />
</div>
</div>
<p>And here’s the posterior distribution of <code class="docutils literal notranslate"><span class="pre">slope</span></code>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">marginal_slope</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;slope&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C2&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Slope&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of slope&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_85_0.png" src="_images/chap16_85_0.png" />
</div>
</div>
<p>Here are the posterior means.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">marginal_inter</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">marginal_slope</span><span class="o">.</span><span class="n">mean</span><span class="p">()],</span>
          <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;inter&#39;</span><span class="p">,</span> <span class="s1">&#39;slope&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>inter   -1.376107
slope   -0.289795
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Both marginal distributions are moderately skewed, so the posterior means are somewhat different from the point estimates.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   -1.208490
x           -0.232163
dtype: float64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="transforming-distributions">
<h2>Transforming Distributions<a class="headerlink" href="#transforming-distributions" title="Permalink to this headline">¶</a></h2>
<p>Let’s interpret these parameters.  Recall that the intercept is the log odds of the hypothesis when <span class="math notranslate nohighlight">\(x\)</span> is 0, which is when temperature is about 70 degrees F (the value of <code class="docutils literal notranslate"><span class="pre">offset</span></code>).
So we can interpret the quantities in <code class="docutils literal notranslate"><span class="pre">marginal_inter</span></code> as log odds.</p>
<p>To convert them to probabilities, I’ll use the following function, which transforms the quantities in a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> by applying a given function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Transform the quantities in a Pmf.&quot;&quot;&quot;</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">pmf</span><span class="o">.</span><span class="n">ps</span>
    <span class="n">qs</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">pmf</span><span class="o">.</span><span class="n">qs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">qs</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If we call <code class="docutils literal notranslate"><span class="pre">transform</span></code> and pass <code class="docutils literal notranslate"><span class="pre">expit</span></code> as a parameter, it transforms the log odds in <code class="docutils literal notranslate"><span class="pre">marginal_inter</span></code> into probabilities and returns the posterior distribution of <code class="docutils literal notranslate"><span class="pre">inter</span></code> expressed in terms of probabilities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">marginal_probs</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">marginal_inter</span><span class="p">,</span> <span class="n">expit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Pmf</span></code> provides a <code class="docutils literal notranslate"><span class="pre">transform</span></code> method that does the same thing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">marginal_probs</span> <span class="o">=</span> <span class="n">marginal_inter</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">expit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s the posterior distribution for the probability of damage at 70 degrees F.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">marginal_probs</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Probability of damage at 70 deg F&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of probabilities&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_97_0.png" src="_images/chap16_97_0.png" />
</div>
</div>
<p>The mean of this distribution is about 22%, which is the probability of damage at 70 degrees F, according to the model.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_prob</span> <span class="o">=</span> <span class="n">marginal_probs</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">mean_prob</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2201937884647988
</pre></div>
</div>
</div>
</div>
<p>This result shows the second reason I defined <code class="docutils literal notranslate"><span class="pre">x</span></code> to be zero when temperature is 70 degrees F; this way, the intercept corresponds to the probability of damage at a relevant temperature, rather than 0 degrees F.</p>
<p>Now let’s look more closely at the estimated slope.  In the logistic model, the parameter <span class="math notranslate nohighlight">\(\beta_1\)</span> is the log of the likelihood ratio.</p>
<p>So we can interpret the quantities in <code class="docutils literal notranslate"><span class="pre">marginal_slope</span></code> as log likelihood ratios, and we can use <code class="docutils literal notranslate"><span class="pre">exp</span></code> to transform them to likelihood ratios (also known as Bayes factors).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">marginal_lr</span> <span class="o">=</span> <span class="n">marginal_slope</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The result is the posterior distribution of likelihood ratios; here’s what it looks like.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">marginal_lr</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C3&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Likelihood ratio of 1 deg F&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of likelihood ratios&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_104_0.png" src="_images/chap16_104_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_lr</span> <span class="o">=</span> <span class="n">marginal_lr</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">mean_lr</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7542914170110268
</pre></div>
</div>
</div>
</div>
<p>The mean of this distribution is about 0.75, which means that each additional degree Fahrenheit provides evidence against the possibility of damage, with a likelihood ratio (Bayes factor) of 0.75.</p>
<p>Notice:</p>
<ul class="simple">
<li><p>I computed the posterior mean of the probability of damage at 70 deg F by transforming the marginal distribution of the intercept to the marginal distribution of probability, and then computing the mean.</p></li>
<li><p>I computed the posterior mean of the likelihood ratio by transforming the marginal distribution of slope to the marginal distribution of likelihood ratios, and then computing the mean.</p></li>
</ul>
<p>This is the correct order of operations, as opposed to computing the posterior means first and then transforming them.</p>
<p>To see the difference, let’s compute both values the other way around.
Here’s the posterior mean of <code class="docutils literal notranslate"><span class="pre">marginal_inter</span></code>, transformed to a probability, compared to the mean of <code class="docutils literal notranslate"><span class="pre">marginal_probs</span></code>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">expit</span><span class="p">(</span><span class="n">marginal_inter</span><span class="o">.</span><span class="n">mean</span><span class="p">()),</span> <span class="n">marginal_probs</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.2016349762400815, 0.2201937884647988)
</pre></div>
</div>
</div>
</div>
<p>And here’s the posterior mean of <code class="docutils literal notranslate"><span class="pre">marginal_slope</span></code>, transformed to a likelihood ratio, compared to the mean <code class="docutils literal notranslate"><span class="pre">marginal_lr</span></code>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">marginal_slope</span><span class="o">.</span><span class="n">mean</span><span class="p">()),</span> <span class="n">marginal_lr</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.7484167954660071, 0.7542914170110268)
</pre></div>
</div>
</div>
</div>
<p>In this example, the differences are not huge, but they can be.
As a general rule, transform first, then compute summary statistics.</p>
</div>
<div class="section" id="predictive-distributions">
<h2>Predictive Distributions<a class="headerlink" href="#predictive-distributions" title="Permalink to this headline">¶</a></h2>
<p>In the logistic model, the parameters are interpretable, at least after transformation.  But often what we care about are predictions, not parameters.  In the Space Shuttle problem, the most important prediction is, “What is the probability of O-ring damage if the outside temperature is 31 degrees F?”</p>
<p>To make that prediction, I’ll draw a sample of parameter pairs from the posterior distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">101</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The result is an array of 101 tuples, each representing a possible pair of parameters.
I chose this sample size to make the computation fast.
Increasing it would not change the results much, but they would be a little more precise.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101,)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span><span class="o">.</span><span class="n">dtype</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dtype(&#39;O&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tuple
</pre></div>
</div>
</div>
</div>
<p>To generate predictions, I’ll use a range of temperatures from 31 degrees F (the temperature when the Challenger launched) to 82 degrees F (the highest observed temperature).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">temps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">31</span><span class="p">,</span> <span class="mi">83</span><span class="p">)</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">temps</span> <span class="o">-</span> <span class="n">offset</span>
</pre></div>
</div>
</div>
</div>
<p>The following loop uses <code class="docutils literal notranslate"><span class="pre">xs</span></code> and the sample of parameters to construct an array of predicted probabilities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">inter</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
    <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">inter</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The result has one column for each value in <code class="docutils literal notranslate"><span class="pre">xs</span></code> and one row for each element of <code class="docutils literal notranslate"><span class="pre">sample</span></code>.</p>
<p>To get a quick sense of what the predictions look like, we can loop through the rows and plot them.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">ps</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">temps</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
    
<span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_126_0.png" src="_images/chap16_126_0.png" />
</div>
</div>
<p>The overlapping lines in this figure give a sense of the most likely value at each temperature and the degree of uncertainty.</p>
<p>In each column, I’ll compute the median to quantify the central tendency and a 90% credible interval to quantify the uncertainty.</p>
<p><code class="docutils literal notranslate"><span class="pre">np.percentile</span></code> computes the given percentiles; with the argument <code class="docutils literal notranslate"><span class="pre">axis=0</span></code>, it computes them for each column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">low</span><span class="p">,</span> <span class="n">median</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">95</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The results are arrays containing predicted probabilities for the lower bound of the 90% CI, the median, and the upper bound of the CI.</p>
<p>Here’s what they look like:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">temps</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">temps</span><span class="p">,</span> <span class="n">median</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;logistic model&#39;</span><span class="p">)</span>

<span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_131_0.png" src="_images/chap16_131_0.png" />
</div>
</div>
<p>According to these results, the probability of damage to the O-rings at 80 degrees F is near 2%, but there is some uncertainty about that prediction; the upper bound of the CI is around 10%.</p>
<p>At 60 degrees, the probability of damage is near 80%, but the CI is even wider, from 48% to 97%.</p>
<p>But the primary goal of the model is to predict the probability of damage at 31 degrees F, and the answer is at least 97%, and more likely to be more than 99.9%.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">low</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">temps</span><span class="p">)</span>
<span class="n">median</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">median</span><span class="p">,</span> <span class="n">temps</span><span class="p">)</span>
<span class="n">high</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">temps</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="mi">80</span>
<span class="nb">print</span><span class="p">(</span><span class="n">median</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="p">(</span><span class="n">low</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">high</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.016956535510200765 (0.000563939208692237, 0.1335417225332125)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="mi">60</span>
<span class="nb">print</span><span class="p">(</span><span class="n">median</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="p">(</span><span class="n">low</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">high</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7738185742694538 (0.45512110762641983, 0.9654437697137236)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="mi">31</span>
<span class="nb">print</span><span class="p">(</span><span class="n">median</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="p">(</span><span class="n">low</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">high</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9998129598124814 (0.97280101769455, 0.999999987740933)
</pre></div>
</div>
</div>
</div>
<p>One conclusion we might draw is this:  If the people responsible for the Challenger launch had taken into account all of the data, and not just the seven damage incidents, they could have predicted that the probability of damage at 31 degrees F was nearly certain.  If they had, it seems likely they would have postponed the launch.</p>
<p>At the same time, if they considered the previous figure, they might have realized that the model makes predictions that extend far beyond the data.  When we extrapolate like that, we have to remember not just the uncertainty quantified by the model, which we expressed as a credible interval; we also have to consider the possibility that the model itself is unreliable.</p>
<p>This example is based on a logistic model, which assumes that each additional degree of temperature contributes the same amount of evidence in favor of (or against) the possibility of damage.  Within a narrow range of temperatures, that might be a reasonable assumption, especially if it is supported by data.  But over a wider range, and beyond the bounds of the data, reality has no obligation to stick to the model.</p>
</div>
<div class="section" id="empirical-bayes">
<h2>Empirical Bayes<a class="headerlink" href="#empirical-bayes" title="Permalink to this headline">¶</a></h2>
<p>In this chapter I used StatsModels to compute the parameters that maximize the probability of the data, and then used those estimates to choose the bounds of the uniform prior distributions.
It might have occurred to you that this process uses the data twice, once to choose the priors and again to do the update.  If that bothers you, you are not alone.
The process I used is an example of what’s called the <a class="reference external" href="https://en.wikipedia.org/wiki/Empirical_Bayes_method">Empirical Bayes method</a>, although I don’t think that’s a particularly good name for it.</p>
<p>Although it might seem problematic to use the data twice, in these examples, it is not.  To see why, consider an alternative: instead of using the estimated parameters to choose the bounds of the prior distribution, I could have used uniform distributions with much wider ranges.
In that case, the results would be the same; the only difference is that I would spend more time computing likelihoods for parameters where the posterior probabilities are negligibly small.</p>
<p>So you can think of this version of Empirical Bayes as an optimization that minimizes computation by putting the prior distributions where the likelihood of the data is worth computing.
This optimization doesn’t affect the results, so it doesn’t “double-count” the data.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>So far we have seen three ways to represent degrees of confidence in a hypothesis: probability, odds, and log odds.
When we write Bayes’s Rule in terms of log odds, a Bayesian update is the sum of the prior and the likelihood; in this sense, Bayesian statistics is the arithmetic of hypotheses and evidence.</p>
<p>This form of Bayes’s Theorem is also the foundation of logistic regression, which we used to infer parameters and make predictions.  In the Space Shuttle problem, we modeled the relationship between temperature and the probability of damage, and showed that the Challenger disaster might have been predictable.  But this example is also a warning about the hazards of using a model to extrapolate far beyond the data.</p>
<p>In the exercises below you’ll have a chance to practice the material in this chapter, using log odds to evaluate a political pundit and using logistic regression to model diagnosis rates for Attention Deficit Hyperactivity Disorder (ADHD).</p>
<p>In the next chapter we’ll move from logistic regression to linear regression, which we will use to model changes over time in temperature, snowfall, and the marathon world record.</p>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p><strong>Exercise:</strong> Suppose a political pundit claims to be able to predict the outcome of elections, but instead of picking a winner, they give each candidate a probability of winning.
With that kind of prediction, it can be hard to say whether it is right or wrong.</p>
<p>For example, suppose the pundit says that Alice has a 70% chance of beating Bob, and then Bob wins the election.  Does that mean the pundit was wrong?</p>
<p>One way to answer this question is to consider two hypotheses:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">H</span></code>: The pundit’s algorithm is legitimate; the probabilities it produces are correct in the sense that they accurately reflect the candidates’ probabilities of winning.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">not</span> <span class="pre">H</span></code>: The pundit’s algorithm is bogus; the probabilities it produces are random values with a mean of 50%.</p></li>
</ul>
<p>If the pundit says Alice has a 70% chance of winning, and she does, that provides evidence in favor of <code class="docutils literal notranslate"><span class="pre">H</span></code> with likelihood ratio 70/50.</p>
<p>If the pundit says Alice has a 70% chance of winning, and she loses, that’s evidence against <code class="docutils literal notranslate"><span class="pre">H</span></code> with a likelihood ratio of 50/30.</p>
<p>Suppose we start with some confidence in the algorithm, so the prior odds are 4 to 1.  And suppose the pundit generates predictions for three elections:</p>
<ul class="simple">
<li><p>In the first election, the pundit says Alice has a 70% chance of winning and she does.</p></li>
<li><p>In the second election, the pundit says Bob has a 30% chance of winning and he does.</p></li>
<li><p>In the third election, the pundit says Carol has an 90% chance of winning and she does.</p></li>
</ul>
<p>What is the log likelihood ratio for each of these outcomes?  Use the log-odds form of Bayes’s Rule to compute the posterior log odds for <code class="docutils literal notranslate"><span class="pre">H</span></code> after these outcomes.  In total, do these outcomes increase or decrease your confidence in the pundit?</p>
<p>If you are interested in this topic, you can <a class="reference external" href="http://allendowney.blogspot.com/2016/11/why-are-we-so-surprised.html">read more about it in this blog post</a>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">prior_log_odds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">prior_log_odds</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.3862943611198906
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">lr1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">7</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span>
<span class="n">lr2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span>
<span class="n">lr3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">9</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span>

<span class="n">lr1</span><span class="p">,</span> <span class="n">lr2</span><span class="p">,</span> <span class="n">lr3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.3364722366212129, -0.5108256237659907, 0.5877866649021191)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># In total, these three outcomes provide evidence that the</span>
<span class="c1"># pundit&#39;s algorithm is legitmate, although with K=1.8,</span>
<span class="c1"># it is weak evidence.</span>

<span class="n">posterior_log_odds</span> <span class="o">=</span> <span class="n">prior_log_odds</span> <span class="o">+</span> <span class="n">lr1</span> <span class="o">+</span> <span class="n">lr2</span> <span class="o">+</span> <span class="n">lr3</span>
<span class="n">posterior_log_odds</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.7997276388772319
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise:</strong>  An article in the <em>New England Journal of Medicine</em> reports results from a study that looked at the diagnosis rate of Attention Deficit Hyperactivity Disorder (ADHD) as a function of birth month: <a class="reference external" href="https://www.nejm.org/doi/10.1056/NEJMoa1806828">“Attention Deficit–Hyperactivity Disorder and Month of School Enrollment”</a>.</p>
<p>They found that children born in June, July, and August were substantially more likely to be diagnosed with ADHD, compared to children born in September, but only in states that use a September cutoff for children to enter kindergarten.  In these states, children born in August start school almost a year younger than children born in September.  The authors of the study suggest that the cause is “age-based variation in behavior that may be attributed to ADHD rather than to the younger age of the children”.</p>
<p>Use the methods in this chapter to estimate the probability of diagnosis as a function of birth month.
The notebook for this chapter provides the data and some suggestions for getting started.</p>
<p>The paper includes this figure:</p>
<img width="500" src="https://www.nejm.org/na101/home/literatum/publisher/mms/journals/content/nejm/2018/nejm_2018.379.issue-22/nejmoa1806828/20190131/images/img_xlarge/nejmoa1806828_f1.jpeg">
<p>In my opinion, this representation of the data does not show the effect as clearly as it could.</p>
<p>But the figure includes the raw data, so we can analyze it ourselves.</p>
<p>Note: there is an error in the figure, confirmed by personal correspondence:</p>
<blockquote>
<div><p>The May and June [diagnoses] are reversed. May should be 317 (not 287) and June should be 287 (not 317).</p>
</div></blockquote>
<p>So here is the corrected data, where <code class="docutils literal notranslate"><span class="pre">n</span></code> is the number of children born in each month, starting with January, and <code class="docutils literal notranslate"><span class="pre">k</span></code> is the number of children diagnosed with ADHD.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">32690</span><span class="p">,</span> <span class="mi">31238</span><span class="p">,</span> <span class="mi">34405</span><span class="p">,</span> <span class="mi">34565</span><span class="p">,</span> <span class="mi">34977</span><span class="p">,</span> <span class="mi">34415</span><span class="p">,</span> 
                   <span class="mi">36577</span><span class="p">,</span> <span class="mi">36319</span><span class="p">,</span> <span class="mi">35353</span><span class="p">,</span> <span class="mi">34405</span><span class="p">,</span> <span class="mi">31285</span><span class="p">,</span> <span class="mi">31617</span><span class="p">])</span>

<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">265</span><span class="p">,</span> <span class="mi">280</span><span class="p">,</span> <span class="mi">307</span><span class="p">,</span> <span class="mi">312</span><span class="p">,</span> <span class="mi">317</span><span class="p">,</span> <span class="mi">287</span><span class="p">,</span> 
                      <span class="mi">320</span><span class="p">,</span> <span class="mi">309</span><span class="p">,</span> <span class="mi">225</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">232</span><span class="p">,</span> <span class="mi">243</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>First, I’m going to “roll” the data so it starts in September rather than January.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And I’ll put it in a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> with one row for each month and the diagnosis rate per 10,000.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adhd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">))</span>
<span class="n">adhd</span><span class="p">[</span><span class="s1">&#39;rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adhd</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">adhd</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10000</span>
<span class="n">adhd</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>k</th>
      <th>n</th>
      <th>rate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>225</td>
      <td>35353</td>
      <td>63.643821</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>240</td>
      <td>34405</td>
      <td>69.757303</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>232</td>
      <td>31285</td>
      <td>74.156944</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>243</td>
      <td>31617</td>
      <td>76.857387</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>265</td>
      <td>32690</td>
      <td>81.064546</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>280</td>
      <td>31238</td>
      <td>89.634420</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>307</td>
      <td>34405</td>
      <td>89.231216</td>
    </tr>
    <tr>
      <th>7</th>
      <td>7</td>
      <td>312</td>
      <td>34565</td>
      <td>90.264719</td>
    </tr>
    <tr>
      <th>8</th>
      <td>8</td>
      <td>317</td>
      <td>34977</td>
      <td>90.630986</td>
    </tr>
    <tr>
      <th>9</th>
      <td>9</td>
      <td>287</td>
      <td>34415</td>
      <td>83.393869</td>
    </tr>
    <tr>
      <th>10</th>
      <td>10</td>
      <td>320</td>
      <td>36577</td>
      <td>87.486672</td>
    </tr>
    <tr>
      <th>11</th>
      <td>11</td>
      <td>309</td>
      <td>36319</td>
      <td>85.079435</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here’s what the diagnosis rates look like.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_adhd</span><span class="p">(</span><span class="n">adhd</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">adhd</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">adhd</span><span class="p">[</span><span class="s1">&#39;rate&#39;</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> 
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">5.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;Younger than average&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;Older than average&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>

    <span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Birth date, months after cutoff&#39;</span><span class="p">,</span>
             <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Diagnosis rate per 10,000&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_adhd</span><span class="p">(</span><span class="n">adhd</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_156_0.png" src="_images/chap16_156_0.png" />
</div>
</div>
<p>For the first 9 months, from September to May, we see what we would expect if some of the excess diagnoses are due to “age-based variation in behavior”.  For each month of difference in age, we see an increase in the number of diagnoses.</p>
<p>This pattern breaks down for the last three months, June, July, and August.  This might be explained by random variation, but it also might be due to parental manipulation; if some parents hold back children born near the deadline, the observations for these month would include a mixture of children who are relatively old for their grade and therefore less likely to be diagnosed.</p>
<p>Unfortunately, the dataset includes only month of birth, not year, so we don’t know the actual ages of these students when they started school.  However, we can use the first nine months to estimate the effect of age on diagnosis rate; then we can think about what to do with the other three months.</p>
<p>Use the methods in this chapter to estimate the probability of diagnosis as a function of birth month.
Start with the following prior distributions.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">5.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.6</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">51</span><span class="p">)</span>
<span class="n">prior_inter</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="s1">&#39;Intercept&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">51</span><span class="p">)</span>
<span class="n">prior_slope</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="s1">&#39;Slope&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Make a joint prior distribution and update it using the data for the first nine months.</p></li>
<li><p>Then draw a sample from the posterior distribution and use it to compute the median probability of diagnosis for each month and a 90% credible interval.</p></li>
<li><p>As a bonus exercise, do a second update using the data from the last three months, but treating the observed number of diagnoses as a lower bound on the number of diagnoses there would be if no children were kept back.</p></li>
</ol>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">joint</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">prior_inter</span><span class="p">,</span> <span class="n">prior_slope</span><span class="p">)</span>
<span class="n">joint</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Intercept</th>
      <th>-5.200</th>
      <th>-5.188</th>
      <th>-5.176</th>
      <th>-5.164</th>
      <th>-5.152</th>
      <th>-5.140</th>
      <th>-5.128</th>
      <th>-5.116</th>
      <th>-5.104</th>
      <th>-5.092</th>
      <th>...</th>
      <th>-4.708</th>
      <th>-4.696</th>
      <th>-4.684</th>
      <th>-4.672</th>
      <th>-4.660</th>
      <th>-4.648</th>
      <th>-4.636</th>
      <th>-4.624</th>
      <th>-4.612</th>
      <th>-4.600</th>
    </tr>
    <tr>
      <th>Slope</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0.0000</th>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>...</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
    </tr>
    <tr>
      <th>0.0016</th>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>...</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
    </tr>
    <tr>
      <th>0.0032</th>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>...</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
    </tr>
    <tr>
      <th>0.0048</th>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>...</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
    </tr>
    <tr>
      <th>0.0064</th>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>...</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
      <td>0.000384</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 51 columns</p>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">joint_pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">joint</span><span class="o">.</span><span class="n">stack</span><span class="p">())</span>
<span class="n">joint_pmf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>Slope</th>
      <th>Intercept</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">0.0</th>
      <th>-5.200</th>
      <td>0.000384</td>
    </tr>
    <tr>
      <th>-5.188</th>
      <td>0.000384</td>
    </tr>
    <tr>
      <th>-5.176</th>
      <td>0.000384</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">num_legit</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">adhd1</span> <span class="o">=</span> <span class="n">adhd</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">num_legit</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">adhd2</span> <span class="o">=</span> <span class="n">adhd</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">num_legit</span><span class="p">:]</span>
<span class="n">adhd1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>k</th>
      <th>n</th>
      <th>rate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>225</td>
      <td>35353</td>
      <td>63.643821</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>240</td>
      <td>34405</td>
      <td>69.757303</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>232</td>
      <td>31285</td>
      <td>74.156944</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>243</td>
      <td>31617</td>
      <td>76.857387</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>265</td>
      <td>32690</td>
      <td>81.064546</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>280</td>
      <td>31238</td>
      <td>89.634420</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>307</td>
      <td>34405</td>
      <td>89.231216</td>
    </tr>
    <tr>
      <th>7</th>
      <td>7</td>
      <td>312</td>
      <td>34565</td>
      <td>90.264719</td>
    </tr>
    <tr>
      <th>8</th>
      <td>8</td>
      <td>317</td>
      <td>34977</td>
      <td>90.630986</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">adhd2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>k</th>
      <th>n</th>
      <th>rate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>9</td>
      <td>287</td>
      <td>34415</td>
      <td>83.393869</td>
    </tr>
    <tr>
      <th>10</th>
      <td>10</td>
      <td>320</td>
      <td>36577</td>
      <td>87.486672</td>
    </tr>
    <tr>
      <th>11</th>
      <td>11</td>
      <td>309</td>
      <td>36319</td>
      <td>85.079435</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>

<span class="n">likelihood1</span> <span class="o">=</span> <span class="n">joint_pmf</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">adhd1</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">ks</span> <span class="o">=</span> <span class="n">adhd1</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">]</span>
<span class="n">ns</span> <span class="o">=</span> <span class="n">adhd1</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">slope</span><span class="p">,</span> <span class="n">inter</span> <span class="ow">in</span> <span class="n">joint_pmf</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">inter</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xs</span><span class="p">)</span>
    <span class="n">likes</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">ps</span><span class="p">)</span>
    <span class="n">likelihood1</span><span class="p">[</span><span class="n">slope</span><span class="p">,</span> <span class="n">inter</span><span class="p">]</span> <span class="o">=</span> <span class="n">likes</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>

<span class="n">likelihood1</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.5436858189129196e-14
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># This update uses the binomial survival function to compute</span>
<span class="c1"># the probability that the number of cases *exceeds* `ks`.</span>

<span class="n">likelihood2</span> <span class="o">=</span> <span class="n">joint_pmf</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">adhd2</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">ks</span> <span class="o">=</span> <span class="n">adhd2</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">]</span>
<span class="n">ns</span> <span class="o">=</span> <span class="n">adhd2</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">slope</span><span class="p">,</span> <span class="n">inter</span> <span class="ow">in</span> <span class="n">joint_pmf</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">inter</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xs</span><span class="p">)</span>
    <span class="n">likes</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">ps</span><span class="p">)</span>
    <span class="n">likelihood2</span><span class="p">[</span><span class="n">slope</span><span class="p">,</span> <span class="n">inter</span><span class="p">]</span> <span class="o">=</span> <span class="n">likes</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>

<span class="n">likelihood2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1905.3511925068485
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior_pmf</span> <span class="o">=</span> <span class="n">joint_pmf</span> <span class="o">*</span> <span class="n">likelihood1</span>
<span class="n">posterior_pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.3624320718619453e-17
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior_pmf</span><span class="o">.</span><span class="n">max_prob</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.0448, -4.996)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior_pmf</span> <span class="o">=</span> <span class="n">joint_pmf</span> <span class="o">*</span> <span class="n">likelihood1</span> <span class="o">*</span> <span class="n">likelihood2</span>
<span class="n">posterior_pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.3403142133315614e-17
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior_pmf</span><span class="o">.</span><span class="n">max_prob</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.0448, -4.996)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">joint_posterior</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>

<span class="n">plot_contour</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">)</span>
<span class="n">decorate</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Joint posterior distribution&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_171_0.png" src="_images/chap16_171_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal_inter</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">marginal_slope</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint_posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">marginal_inter</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">marginal_slope</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(-4.999322906782624, 0.044607616771986124)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal_inter</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">)</span>
<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of intercept&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_173_0.png" src="_images/chap16_173_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal_slope</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C2&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Slope&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior marginal distribution of slope&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_174_0.png" src="_images/chap16_174_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">posterior_pmf</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">101</span><span class="p">)</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">adhd</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">inter</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
    <span class="n">ps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">inter</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xs</span><span class="p">)</span>
    
<span class="n">ps</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 12)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">low</span><span class="p">,</span> <span class="n">median</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mf">97.5</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">median</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.00663988, 0.00695303, 0.00728085, 0.00762401, 0.00798321,
       0.00835919, 0.00875272, 0.00915734, 0.00955774, 0.00997548,
       0.01043603, 0.01094356])
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">low</span><span class="o">*</span><span class="mi">10000</span><span class="p">,</span> <span class="n">high</span><span class="o">*</span><span class="mi">10000</span><span class="p">,</span> 
                 <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">median</span><span class="o">*</span><span class="mi">10000</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">,</span>
         <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plot_adhd</span><span class="p">(</span><span class="n">adhd</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap16_177_0.png" src="_images/chap16_177_0.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="chap15.html" title="previous page">Mark and Recapture</a>
    <a class='right-next' id="next-link" href="chap17.html" title="next page">Regression</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Allen B. Downey<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>