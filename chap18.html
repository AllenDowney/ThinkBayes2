
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Conjugate Priors &#8212; Think Bayes</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MCMC" href="chap19.html" />
    <link rel="prev" title="Regression" href="chap17.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Think Bayes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Think Bayes 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap01.html">
   Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap02.html">
   Bayes’s Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap03.html">
   Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap04.html">
   Estimating Proportions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap05.html">
   Estimating Counts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap06.html">
   Odds and Addends
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap07.html">
   Minimum, Maximum, and Mixture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap08.html">
   Poisson Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap09.html">
   Decision Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap10.html">
   Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap11.html">
   Comparison
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap12.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap13.html">
   Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap14.html">
   Survival Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap15.html">
   Mark and Recapture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap16.html">
   Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap17.html">
   Regression
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Conjugate Priors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap19.html">
   MCMC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap20.html">
   Approximate Bayesian Computation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Examples
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="redline.html">
   The Red Line Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="vaccine2.html">
   Estimating vaccine efficacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="usb.html">
   Flipping USB Connectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="sister.html">
   The Left Handed Sister Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bayes_dice.html">
   Bayesian Dice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="radiation.html">
   The Emitter-Detector Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hospital.html">
   Grid algorithms for hierarchical models
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chap18.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/AllenDowney/ThinkBayes2"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/AllenDowney/ThinkBayes2/master?urlpath=tree/chap18.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-world-cup-problem-revisited">
   The World Cup Problem Revisited
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-conjugate-prior">
   The Conjugate Prior
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-the-actual">
   What the Actual?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binomial-likelihood">
   Binomial Likelihood
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lions-and-tigers-and-bears">
   Lions and Tigers and Bears
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-dirichlet-distribution">
   The Dirichlet Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Conjugate Priors</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-world-cup-problem-revisited">
   The World Cup Problem Revisited
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-conjugate-prior">
   The Conjugate Prior
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-the-actual">
   What the Actual?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binomial-likelihood">
   Binomial Likelihood
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lions-and-tigers-and-bears">
   Lions and Tigers and Bears
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-dirichlet-distribution">
   The Dirichlet Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="conjugate-priors">
<h1>Conjugate Priors<a class="headerlink" href="#conjugate-priors" title="Permalink to this headline">¶</a></h1>
<p>In the previous chapters we have used grid approximations to solve a variety of problems.
One of my goals has been to show that this approach is sufficient to solve many real-world problems.
And I think it’s a good place to start because it shows clearly how the methods work.</p>
<p>However, as we saw in the previous chapter, grid methods will only get you so far.
As we increase the number of parameters, the number of points in the grid grows (literally) exponentially.
With more than 3-4 parameters, grid methods become impractical.</p>
<p>So, in the remaining three chapters, I will present three alternatives:</p>
<ol class="simple">
<li><p>In this chapter we’ll use <strong>conjugate priors</strong> to speed up some of the computations we’ve already done.</p></li>
<li><p>In the next chapter, I’ll present Markov chain Monte Carlo (MCMC) methods, which can solve problems with tens of parameters, or even hundreds, in a reasonable amount of time.</p></li>
<li><p>And in the last chapter we’ll use Approximate Bayesian Computation (ABC) for problems that are hard to model with simple distributions.</p></li>
</ol>
<p>We’ll start with the World Cup problem.</p>
<div class="section" id="the-world-cup-problem-revisited">
<h2>The World Cup Problem Revisited<a class="headerlink" href="#the-world-cup-problem-revisited" title="Permalink to this headline">¶</a></h2>
<p>In &lt;&lt;_PoissonProcesses&gt;&gt;, we solved the World Cup problem using a Poisson process to model goals in a soccer game as random events that are equally likely to occur at any point during a game.</p>
<p>We used a gamma distribution to represent the prior distribution of <span class="math notranslate nohighlight">\(\lambda\)</span>, the goal-scoring rate.  And we used a Poisson distribution to compute the probability of <span class="math notranslate nohighlight">\(k\)</span>, the number of goals scored.</p>
<p>Here’s a gamma object that represents the prior distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">gamma</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.4</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And here’s a grid approximation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">pmf_from_dist</span>

<span class="n">lams</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">lams</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s the likelihood of scoring 4 goals for each possible value of <code class="docutils literal notranslate"><span class="pre">lam</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">poisson</span>

<span class="n">k</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">poisson</span><span class="p">(</span><span class="n">lams</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And here’s the update.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.05015532557804499
</pre></div>
</div>
</div>
</div>
<p>So far, this should be familiar.
Now we’ll solve the same problem using the conjugate prior.</p>
</div>
<div class="section" id="the-conjugate-prior">
<h2>The Conjugate Prior<a class="headerlink" href="#the-conjugate-prior" title="Permalink to this headline">¶</a></h2>
<p>In &lt;&lt;_TheGammaDistribution&gt;&gt;, I presented three reasons to use a gamma distribution for the prior and said there was a fourth reason I would reveal later.
Well, now is the time.</p>
<p>The other reason I chose the gamma distribution is that it is the “conjugate prior” of the Poisson distribution, so-called because the two distributions are connected or coupled, which is what “conjugate” means.</p>
<p>In the next section I’ll explain <em>how</em> they are connected, but first I’ll show you the consequence of this connection, which is that there is a remarkably simple way to compute the posterior distribution.</p>
<p>However, in order to demonstrate it, we have to switch from the one-parameter version of the gamma distribution to the two-parameter version.  Since the first parameter is called <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, you might guess that the second parameter is called <code class="docutils literal notranslate"><span class="pre">beta</span></code>.</p>
<p>The following function takes <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">beta</span></code> and makes an object that represents a gamma distribution with those parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_gamma_dist</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Makes a gamma object.&quot;&quot;&quot;</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">beta</span><span class="p">)</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
    <span class="k">return</span> <span class="n">dist</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s the prior distribution with <code class="docutils literal notranslate"><span class="pre">alpha=1.4</span></code> again and <code class="docutils literal notranslate"><span class="pre">beta=1</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.4</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">prior_gamma</span> <span class="o">=</span> <span class="n">make_gamma_dist</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">prior_gamma</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.4
</pre></div>
</div>
</div>
</div>
<p>Now I claim without proof that we can do a Bayesian update with <code class="docutils literal notranslate"><span class="pre">k</span></code> goals just by making a gamma distribution with parameters <code class="docutils literal notranslate"><span class="pre">alpha+k</span></code> and <code class="docutils literal notranslate"><span class="pre">beta+1</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_gamma</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update a gamma prior.&quot;&quot;&quot;</span>
    <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">k</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">beta</span> <span class="o">+</span> <span class="n">t</span>
    <span class="k">return</span> <span class="n">make_gamma_dist</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s how we update it with <code class="docutils literal notranslate"><span class="pre">k=4</span></code> goals in <code class="docutils literal notranslate"><span class="pre">t=1</span></code> game.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">posterior_gamma</span> <span class="o">=</span> <span class="n">update_gamma</span><span class="p">(</span><span class="n">prior_gamma</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>After all the work we did with the grid, it might seem absurd that we can do a Bayesian update by adding two pairs of numbers.
So let’s confirm that it works.</p>
<p>I’ll make a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> with a discrete approximation of the posterior distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_conjugate</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">posterior_gamma</span><span class="p">,</span> <span class="n">lams</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The following figure shows the result along with the posterior we computed using the grid algorithm.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">decorate</span>

<span class="k">def</span> <span class="nf">decorate_rate</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Goal scoring rate (lam)&#39;</span><span class="p">,</span>
             <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PMF&#39;</span><span class="p">,</span>
             <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;grid posterior&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>
<span class="n">posterior_conjugate</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;conjugate posterior&#39;</span><span class="p">,</span> 
                         <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>

<span class="n">decorate_rate</span><span class="p">(</span><span class="s1">&#39;Posterior distribution&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap18_27_0.png" src="_images/chap18_27_0.png" />
</div>
</div>
<p>They are the same other than small differences due to floating-point approximations.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">posterior_conjugate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="what-the-actual">
<h2>What the Actual?<a class="headerlink" href="#what-the-actual" title="Permalink to this headline">¶</a></h2>
<p>To understand how that works, we’ll write the PDF of the gamma prior and the PMF of the Poisson likelihood, then multiply them together, because that’s what the Bayesian update does.
We’ll see that the result is a gamma distribution, and we’ll derive its parameters.</p>
<p>Here’s the PDF of the gamma prior, which is the probability density for each value of <span class="math notranslate nohighlight">\(\lambda\)</span>, given parameters <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>:</p>
<div class="math notranslate nohighlight">
\[\lambda^{\alpha-1} e^{-\lambda \beta}\]</div>
<p>I have omitted the normalizing factor; since we are planning to normalize the posterior distribution anyway, we don’t really need it.</p>
<p>Now suppose a team scores <span class="math notranslate nohighlight">\(k\)</span> goals in <span class="math notranslate nohighlight">\(t\)</span> games.
The probability of this data is given by the PMF of the Poisson distribution, which is a function of <span class="math notranslate nohighlight">\(k\)</span> with <span class="math notranslate nohighlight">\(\lambda\)</span> and <span class="math notranslate nohighlight">\(t\)</span> as parameters.</p>
<div class="math notranslate nohighlight">
\[\lambda^k e^{-\lambda t}\]</div>
<p>Again, I have omitted the normalizing factor, which makes it clearer that the gamma and Poisson distributions have the same functional form.
When we multiply them together, we can pair up the factors and add up the exponents.
The result is the unnormalized posterior distribution,</p>
<div class="math notranslate nohighlight">
\[\lambda^{\alpha-1+k} e^{-\lambda(\beta + t)}\]</div>
<p>which we can recognize as an unnormalized gamma distribution with parameters <span class="math notranslate nohighlight">\(\alpha + k\)</span> and <span class="math notranslate nohighlight">\(\beta + t\)</span>.</p>
<p>This derivation provides insight into what the parameters of the posterior distribution mean: <span class="math notranslate nohighlight">\(\alpha\)</span> reflects the number of events that have occurred; <span class="math notranslate nohighlight">\(\beta\)</span> reflects the elapsed time.</p>
</div>
<div class="section" id="binomial-likelihood">
<h2>Binomial Likelihood<a class="headerlink" href="#binomial-likelihood" title="Permalink to this headline">¶</a></h2>
<p>As a second example, let’s look again at the Euro problem.
When we solved it with a grid algorithm, we started with a uniform prior:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">make_uniform</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
<span class="n">uniform</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="s1">&#39;uniform&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We used the binomial distribution to compute the likelihood of the data, which was 140 heads out of 250 attempts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>

<span class="n">k</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">140</span><span class="p">,</span> <span class="mi">250</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">uniform</span><span class="o">.</span><span class="n">qs</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then we computed the posterior distribution in the usual way.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior</span> <span class="o">=</span> <span class="n">uniform</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.003944617569326651
</pre></div>
</div>
</div>
</div>
<p>We can solve this problem more efficiently using the conjugate prior of the binomial distribution, which is the beta distribution.</p>
<p>The beta distribution is bounded between 0 and 1, so it works well for representing the distribution of a probability like <code class="docutils literal notranslate"><span class="pre">x</span></code>.
It has two parameters, called <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">beta</span></code>, that determine the shape of the distribution.</p>
<p>SciPy provides an object called <code class="docutils literal notranslate"><span class="pre">beta</span></code> that represents a beta distribution.
The following function takes <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">beta</span></code> and returns a new <code class="docutils literal notranslate"><span class="pre">beta</span></code> object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.stats</span>

<span class="k">def</span> <span class="nf">make_beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Makes a beta object.&quot;&quot;&quot;</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
    <span class="k">return</span> <span class="n">dist</span>
</pre></div>
</div>
</div>
</div>
<p>It turns out that the uniform distribution, which we used as a prior, is the beta distribution with parameters <code class="docutils literal notranslate"><span class="pre">alpha=1</span></code> and <code class="docutils literal notranslate"><span class="pre">beta=1</span></code>.
So we can make a <code class="docutils literal notranslate"><span class="pre">beta</span></code> object that represents a uniform distribution, like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">prior_beta</span> <span class="o">=</span> <span class="n">make_beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s figure out how to do the update.  As in the previous example, we’ll write the PDF of the prior distribution and the PMF of the likelihood function, and multiply them together.  We’ll see that the product has the same form as the prior, and we’ll derive its parameters.</p>
<p>Here is the PDF of the beta distribution, which is a function of <span class="math notranslate nohighlight">\(x\)</span> with <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> as parameters.</p>
<div class="math notranslate nohighlight">
\[x^{\alpha-1} (1-x)^{\beta-1}\]</div>
<p>Again, I have omitted the normalizing factor, which we don’t need because we are going to normalize the distribution after the update.</p>
<p>And here’s the PMF of the binomial distribution, which is a function of <span class="math notranslate nohighlight">\(k\)</span> with <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(x\)</span> as parameters.</p>
<div class="math notranslate nohighlight">
\[x^{k} (1-x)^{n-k}\]</div>
<p>Again, I have omitted the normalizing factor.
Now when we multiply the beta prior and the binomial likelihood, the result is</p>
<div class="math notranslate nohighlight">
\[x^{\alpha-1+k} (1-x)^{\beta-1+n-k}\]</div>
<p>which we recognize as an unnormalized beta distribution with parameters <span class="math notranslate nohighlight">\(\alpha+k\)</span> and <span class="math notranslate nohighlight">\(\beta+n-k\)</span>.</p>
<p>So if we observe <code class="docutils literal notranslate"><span class="pre">k</span></code> successes in <code class="docutils literal notranslate"><span class="pre">n</span></code> trials, we can do the update by making a beta distribution with parameters <code class="docutils literal notranslate"><span class="pre">alpha+k</span></code> and <code class="docutils literal notranslate"><span class="pre">beta+n-k</span></code>.
That’s what this function does:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_beta</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update a beta distribution.&quot;&quot;&quot;</span>
    <span class="n">k</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">k</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">beta</span> <span class="o">+</span> <span class="n">n</span> <span class="o">-</span> <span class="n">k</span>
    <span class="k">return</span> <span class="n">make_beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Again, the conjugate prior gives us insight into the meaning of the parameters; <span class="math notranslate nohighlight">\(\alpha\)</span> is related to the number of observed successes; <span class="math notranslate nohighlight">\(\beta\)</span> is related to the number of failures.</p>
<p>Here’s how we do the update with the observed data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="mi">140</span><span class="p">,</span> <span class="mi">250</span>
<span class="n">posterior_beta</span> <span class="o">=</span> <span class="n">update_beta</span><span class="p">(</span><span class="n">prior_beta</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To confirm that it works, I’ll evaluate the posterior distribution for the possible values of <code class="docutils literal notranslate"><span class="pre">xs</span></code> and put the results in a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_conjugate</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">posterior_beta</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And we can compare the posterior distribution we just computed with the results from the grid algorithm.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">decorate_euro</span><span class="p">(</span><span class="n">title</span><span class="p">):</span>
    <span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Proportion of heads (x)&#39;</span><span class="p">,</span>
             <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Probability&#39;</span><span class="p">,</span>
             <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;grid posterior&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>
<span class="n">posterior_conjugate</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;conjugate posterior&#39;</span><span class="p">,</span>
                        <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C4&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>

<span class="n">decorate_euro</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distribution of x&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap18_49_0.png" src="_images/chap18_49_0.png" />
</div>
</div>
<p>They are the same other than small differences due to floating-point approximations.</p>
<p>The examples so far are problems we have already solved, so let’s try something new.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">posterior_conjugate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="lions-and-tigers-and-bears">
<h2>Lions and Tigers and Bears<a class="headerlink" href="#lions-and-tigers-and-bears" title="Permalink to this headline">¶</a></h2>
<p>Suppose we visit a wild animal preserve where we know that the only animals are lions and tigers and bears, but we don’t know how many of each there are.
During the tour, we see 3 lions, 2 tigers, and one bear. Assuming that every animal had an equal chance to appear in our sample, what is the probability that the next animal we see is a bear?</p>
<p>To answer this question, we’ll use the data to estimate the prevalence of each species, that is, what fraction of the animals belong to each species.
If we know the prevalences, we can use the multinomial distribution to compute the probability of the data.
For example, suppose we know that the fraction of lions, tigers, and bears is 0.4, 0.3, and 0.3, respectively.</p>
<p>In that case the probability of the data is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multinomial</span>

<span class="n">data</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span>

<span class="n">multinomial</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.10368
</pre></div>
</div>
</div>
</div>
<p>Now, we could choose a prior for the prevalences and do a Bayesian update using the multinomial distribution to compute the probability of the data.</p>
<p>But there’s an easier way, because the multinomial distribution has a conjugate prior: the Dirichlet distribution.</p>
</div>
<div class="section" id="the-dirichlet-distribution">
<h2>The Dirichlet Distribution<a class="headerlink" href="#the-dirichlet-distribution" title="Permalink to this headline">¶</a></h2>
<p>The Dirichlet distribution is a multivariate distribution, like the multivariate normal distribution we used in &lt;&lt;_MultivariateNormalDistribution&gt;&gt; to describe the distribution of penguin measurements.</p>
<p>In that example, the quantities in the distribution are pairs of flipper length and culmen length, and the parameters of the distribution are a vector of means and a matrix of covariances.</p>
<p>In a Dirichlet distribution, the quantities are vectors of probabilities, <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, and the parameter is a vector, <span class="math notranslate nohighlight">\(\mathbf{\alpha}\)</span>.</p>
<p>An example will make that clearer.  SciPy provides a <code class="docutils literal notranslate"><span class="pre">dirichlet</span></code> object that represents a Dirichlet distribution.
Here’s an instance with <span class="math notranslate nohighlight">\(\mathbf{\alpha} = 1, 2, 3\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">dirichlet</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">dirichlet</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Since we provided three parameters, the result is a distribution of three variables.
If we draw a random value from this distribution, like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.53566485, 0.35129   , 0.11304515]])
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>The result is an array of three values.
They are bounded between 0 and 1, and they always add up to 1, so they can be interpreted as the probabilities of a set of outcomes that are mutually exclusive and collectively exhaustive.</p>
<p>Let’s see what the distributions of these values look like.  I’ll draw 1000 random vectors from this distribution, like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000, 3)
</pre></div>
</div>
</div>
</div>
<p>The result is an array with 1000 rows and three columns.  I’ll compute the <code class="docutils literal notranslate"><span class="pre">Cdf</span></code> of the values in each column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">empiricaldist</span> <span class="kn">import</span> <span class="n">Cdf</span>

<span class="n">cdfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">col</span><span class="p">)</span> 
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">transpose</span><span class="p">()]</span>
</pre></div>
</div>
</div>
</div>
<p>The result is a list of <code class="docutils literal notranslate"><span class="pre">Cdf</span></code> objects that represent the marginal distributions of the three variables.  Here’s what they look like.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cdf</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cdfs</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Column </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="n">cdf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    
<span class="n">decorate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap18_66_0.png" src="_images/chap18_66_0.png" />
</div>
</div>
<p>Column 0, which corresponds to the lowest parameter, contains the lowest probabilities.
Column 2, which corresponds to the highest parameter, contains the highest probabilities.</p>
<p>As it turns out, these marginal distributions are beta distributions.
The following function takes a sequence of parameters, <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, and computes the marginal distribution of variable <code class="docutils literal notranslate"><span class="pre">i</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">marginal_beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the ith marginal of a Dirichlet distribution.&quot;&quot;&quot;</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">make_beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">total</span><span class="o">-</span><span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>We can use it to compute the marginal distribution for the three variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">marginals</span> <span class="o">=</span> <span class="p">[</span><span class="n">marginal_beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
             <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alpha</span><span class="p">))]</span>
</pre></div>
</div>
</div>
</div>
<p>The following plot shows the CDF of these distributions as gray lines and compares them to the CDFs of the samples.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alpha</span><span class="p">)):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Column </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span>
    
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">marginals</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">xs</span><span class="p">)</span>
    <span class="n">pmf</span><span class="o">.</span><span class="n">make_cdf</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C5&#39;</span><span class="p">)</span>
    
    <span class="n">cdf</span> <span class="o">=</span> <span class="n">cdfs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">cdf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap18_72_0.png" src="_images/chap18_72_0.png" />
</div>
</div>
<p>This confirms that the marginals of the Dirichlet distribution are beta distributions.
And that’s useful because the Dirichlet distribution is the conjugate prior for the multinomial likelihood function.</p>
<p>If the prior distribution is Dirichlet with parameter vector <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and the data is a vector of observations, <code class="docutils literal notranslate"><span class="pre">data</span></code>, the posterior distribution is Dirichlet with parameter vector <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">+</span> <span class="pre">data</span></code>.</p>
<p>As an exercise at the end of this chapter, you can use this method to solve the Lions and Tigers and Bears problem.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>After reading this chapter, if you feel like you’ve been tricked, I understand.  It turns out that many of the problems in this book can be solved with just a few arithmetic operations.  So why did we go to all the trouble of using grid algorithms?</p>
<p>Sadly, there are only a few problems we can solve with conjugate priors; in fact, this chapter includes most of the ones that are useful in practice.</p>
<p>For the vast majority of problems, there is no conjugate prior and no shortcut to compute the posterior distribution.
That’s why we need grid algorithms and the methods in the next two chapters, Approximate Bayesian Computation (ABC) and Markov chain Monte Carlo methods (MCMC).</p>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p><strong>Exercise:</strong> In the second version of the World Cup problem, the data we use for the update is not the number of goals in a game, but the time until the first goal.
So the probability of the data is given by the exponential distribution rather than the Poisson distribution.</p>
<p>But it turns out that the gamma distribution is <em>also</em> the conjugate prior of the exponential distribution, so there is a simple way to compute this update, too.
The PDF of the exponential distribution is a function of <span class="math notranslate nohighlight">\(t\)</span> with <span class="math notranslate nohighlight">\(\lambda\)</span> as a parameter.</p>
<div class="math notranslate nohighlight">
\[\lambda e^{-\lambda t}\]</div>
<p>Multiply the PDF of the gamma prior by this likelihood, confirm that the result is an unnormalized gamma distribution, and see if you can derive its parameters.</p>
<p>Write a few lines of code to update <code class="docutils literal notranslate"><span class="pre">prior_gamma</span></code> with the data from this version of the problem, which was a first goal after 11 minutes and a second goal after an additional 12 minutes.</p>
<p>Remember to express these quantities in units of games, which are approximately 90 minutes.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The unnormalized posterior is</span>

<span class="sd">\lambda^{\alpha-1+1} e^{-(\beta + t) \lambda}</span>

<span class="sd">which is an unnormalized gamma distribution with parameters</span>
<span class="sd">`alpha+1` and `beta+t`, which means that we observed 1 goal</span>
<span class="sd">in elapsed time `t`.</span>

<span class="sd">So we can use the same update function and call it like this:</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">data</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="o">/</span><span class="mi">90</span>
<span class="n">posterior1</span> <span class="o">=</span> <span class="n">update_gamma</span><span class="p">(</span><span class="n">prior_gamma</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here&#39;s the second update</span>

<span class="n">data</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="o">/</span><span class="mi">90</span>
<span class="n">posterior2</span> <span class="o">=</span> <span class="n">update_gamma</span><span class="p">(</span><span class="n">posterior1</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">prior_gamma</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">posterior1</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">posterior2</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1.4, 2.1386138613861387, 2.7079646017699113)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># And here&#39;s what the posteriors look like</span>

<span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">prior_gamma</span><span class="p">,</span> <span class="n">lams</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C5&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;prior&#39;</span><span class="p">)</span>
<span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">posterior1</span><span class="p">,</span> <span class="n">lams</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;after 1 goal&#39;</span><span class="p">)</span>
<span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">posterior2</span><span class="p">,</span> <span class="n">lams</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;after 2 goals&#39;</span><span class="p">)</span>

<span class="n">decorate_rate</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;World Cup Problem, Germany v Brazil&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap18_80_0.png" src="_images/chap18_80_0.png" />
</div>
</div>
<p><strong>Exercise:</strong> For problems like the Euro problem where the likelihood function is binomial, we can do a Bayesian update with just a few arithmetic operations, but only if the prior is a beta distribution.</p>
<p>If we want a uniform prior, we can use a beta distribution with <code class="docutils literal notranslate"><span class="pre">alpha=1</span></code> and <code class="docutils literal notranslate"><span class="pre">beta=1</span></code>.
But what can we do if the prior distribution we want is not a beta distribution?
For example, in &lt;&lt;_TrianglePrior&gt;&gt; we also solved the Euro problem with a triangle prior, which is not a beta distribution.</p>
<p>In these cases, we can often find a beta distribution that is a good-enough approximation for the prior we want.
See if you can find a beta distribution that fits the triangle prior, then update it using <code class="docutils literal notranslate"><span class="pre">update_beta</span></code>.</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">pmf_from_dist</span></code> to make a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> that approximates the posterior distribution and compare it to the posterior we just computed using a grid algorithm.  How big is the largest difference between them?</p>
<p>Here’s the triangle prior again.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">empiricaldist</span> <span class="kn">import</span> <span class="n">Pmf</span>

<span class="n">ramp_up</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">ramp_down</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ramp_up</span><span class="p">,</span> <span class="n">ramp_down</span><span class="p">)</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">uniform</span><span class="o">.</span><span class="n">qs</span>

<span class="n">triangle</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;triangle&#39;</span><span class="p">)</span>
<span class="n">triangle</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2500
</pre></div>
</div>
</div>
</div>
<p>And here’s the update.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">140</span><span class="p">,</span> <span class="mi">250</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>

<span class="n">posterior</span> <span class="o">=</span> <span class="n">triangle</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">posterior</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.007008842590059086
</pre></div>
</div>
</div>
</div>
<p>To get you started, here’s the beta distribution that we used as a uniform prior.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">prior_beta</span> <span class="o">=</span> <span class="n">make_beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">prior_beta</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5
</pre></div>
</div>
</div>
</div>
<p>And here’s what it looks like compared to the triangle prior.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior_pmf</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">prior_beta</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>

<span class="n">triangle</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;triangle&#39;</span><span class="p">)</span>
<span class="n">prior_pmf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">)</span>

<span class="n">decorate_euro</span><span class="p">(</span><span class="s1">&#39;Prior distributions&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap18_89_0.png" src="_images/chap18_89_0.png" />
</div>
</div>
<p>Now you take it from there.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">data</span> <span class="o">=</span> <span class="mi">140</span><span class="p">,</span> <span class="mi">250</span>
<span class="n">posterior_beta</span> <span class="o">=</span> <span class="n">update_beta</span><span class="p">(</span><span class="n">prior_beta</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="n">posterior_beta</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5595238095238095
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior_conjugate</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">posterior_beta</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;grid posterior&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
<span class="n">posterior_conjugate</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;conjugate posterior&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Proportion of heads (x)&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Probability&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distribution of x&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap18_93_0.png" src="_images/chap18_93_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># The largest absolute difference is pretty small</span>

<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">posterior_conjugate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>False
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise:</strong>  <a class="reference external" href="https://en.wikipedia.org/wiki/3Blue1Brown">3Blue1Brown</a> is a YouTube channel about math; if you are not already aware of it, I recommend it highly.
In <a class="reference external" href="https://www.youtube.com/watch?v=8idr1WZ1A7Q">this video</a> the narrator presents this problem:</p>
<blockquote>
<div><p>You are buying a product online and you see three sellers offering the same product at the same price.  One of them has a 100% positive rating, but with only 10 reviews.  Another has a 96% positive rating with 50 total reviews.  And yet another has a 93% positive rating, but with 200 total reviews.</p>
<p>Which one should you buy from?</p>
</div></blockquote>
<p>Let’s think about how to model this scenario.  Suppose each seller has some unknown probability, <code class="docutils literal notranslate"><span class="pre">x</span></code>, of providing satisfactory service and getting a positive rating, and we want to choose the seller with the highest value of <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<p>This is not the only model for this scenario, and it is not necessarily the best.  An alternative would be something like item response theory, where sellers have varying ability to provide satisfactory service and customers have varying difficulty of being satisfied.</p>
<p>But the first model has the virtue of simplicity, so let’s see where it gets us.</p>
<ol class="simple">
<li><p>As a prior, I suggest a beta distribution with <code class="docutils literal notranslate"><span class="pre">alpha=8</span></code> and <code class="docutils literal notranslate"><span class="pre">beta=2</span></code>.  What does this prior look like and what does it imply about sellers?</p></li>
<li><p>Use the data to update the prior for the three sellers and plot the posterior distributions.  Which seller has the highest posterior mean?</p></li>
<li><p>How confident should we be about our choice?  That is, what is the probability that the seller with the highest posterior mean actually has the highest value of <code class="docutils literal notranslate"><span class="pre">x</span></code>?</p></li>
<li><p>Consider a beta prior with <code class="docutils literal notranslate"><span class="pre">alpha=0.7</span></code> and <code class="docutils literal notranslate"><span class="pre">beta=0.5</span></code>.  What does this prior look like and what does it imply about sellers?</p></li>
<li><p>Run the analysis again with this prior and see what effect it has on the results.</p></li>
</ol>
<p>Note: When you evaluate the beta distribution, you should restrict the range of <code class="docutils literal notranslate"><span class="pre">xs</span></code> so it does not include 0 and 1.  When the parameters of the beta distribution are less than 1, the probability density goes to infinity at 0 and 1.  From a mathematical point of view, that’s not a problem; it is still a proper probability distribution.  But from a computational point of view, it means we have to avoid evaluating the PDF at 0 and 1.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># The first prior implies that most sellers are </span>
<span class="c1"># satisfactory most of the time, but none are perfect.</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">make_beta</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.995</span><span class="p">,</span> <span class="mi">199</span><span class="p">)</span>
<span class="n">prior_pmf</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
<span class="n">prior_pmf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;C5&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;prior&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Probability of positive rating&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap18_97_0.png" src="_images/chap18_97_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">data1</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">data2</span> <span class="o">=</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">50</span>
<span class="n">data3</span> <span class="o">=</span> <span class="mi">186</span><span class="p">,</span> <span class="mi">200</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">seller1</span> <span class="o">=</span> <span class="n">update_beta</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data1</span><span class="p">)</span>
<span class="n">seller2</span> <span class="o">=</span> <span class="n">update_beta</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data2</span><span class="p">)</span>
<span class="n">seller3</span> <span class="o">=</span> <span class="n">update_beta</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">seller1_pmf</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">seller1</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
<span class="n">seller2_pmf</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">seller2</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
<span class="n">seller3_pmf</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">seller3</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">seller1_pmf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;seller 1&#39;</span><span class="p">)</span>
<span class="n">seller2_pmf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;seller 2&#39;</span><span class="p">)</span>
<span class="n">seller3_pmf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;seller 3&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Probability of positive rating&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mf">0.65</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap18_101_0.png" src="_images/chap18_101_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">seller1</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">seller2</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">seller3</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.9, 0.9333333333333333, 0.9238095238095239)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">iters</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">iters</span><span class="p">))</span>

<span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">seller1</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">iters</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">seller2</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">iters</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">seller3</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">iters</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="kn">from</span> <span class="nn">empiricaldist</span> <span class="kn">import</span> <span class="n">Pmf</span>

<span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Pmf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">best</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.2948</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.4750</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.2302</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>Exercise:</strong> Use a Dirichlet prior with parameter vector <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">[1,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> to solve the Lions and Tigers and Bears problem:</p>
<blockquote>
<div><p>Suppose we visit a wild animal preserve where we know that the only animals are lions and tigers and bears, but we don’t know how many of each there are.</p>
<p>During the tour, we see three lions, two tigers, and one bear. Assuming that every animal had an equal chance to appear in our sample, estimate the prevalence of each species.</p>
<p>What is the probability that the next animal we see is a bear?</p>
</div></blockquote>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">prior_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior_alpha</span> <span class="o">=</span> <span class="n">prior_alpha</span> <span class="o">+</span> <span class="n">data</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">marginal_bear</span> <span class="o">=</span> <span class="n">marginal_beta</span><span class="p">(</span><span class="n">posterior_alpha</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">marginal_bear</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2222222222222222
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">dist</span> <span class="o">=</span> <span class="n">dirichlet</span><span class="p">(</span><span class="n">posterior_alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lion&#39;</span><span class="p">,</span> <span class="s1">&#39;tiger&#39;</span><span class="p">,</span> <span class="s1">&#39;bear&#39;</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;prob&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prob</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lion</th>
      <td>0.444444</td>
    </tr>
    <tr>
      <th>tiger</th>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>bear</th>
      <td>0.222222</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="chap17.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Regression</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="chap19.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">MCMC</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Allen B. Downey<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>