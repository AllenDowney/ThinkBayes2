
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2. Bayes’s Theorem &#8212; Think Bayes</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap02';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. Distributions" href="chap03.html" />
    <link rel="prev" title="1. Probability" href="chap01.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">Think Bayes</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Think Bayes 2
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Front Matter</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="preface.html">Preface</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chap01.html">1. Probability</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. Bayes’s Theorem</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap03.html">3. Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap04.html">4. Estimating Proportions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap05.html">5. Estimating Counts</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap06.html">6. Odds and Addends</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap07.html">7. Minimum, Maximum, and Mixture</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap08.html">8. Poisson Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap09.html">9. Decision Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap10.html">10. Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap11.html">11. Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap12.html">12. Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap13.html">13. Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap14.html">14. Survival Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap15.html">15. Mark and Recapture</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap16.html">16. Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap17.html">17. Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap18.html">18. Conjugate Priors</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap19_v3.html">19. MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap20.html">20. Approximate Bayesian Computation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="redline.html">The Red Line Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="redline_pymc.html">The Red Line Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="vaccine2.html">Estimating vaccine efficacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="usb.html">Flipping USB Connectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="sister.html">The Left Handed Sister Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes_dice.html">Bayesian Dice</a></li>
<li class="toctree-l1"><a class="reference internal" href="radiation.html">The Emitter-Detector Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="hospital.html">Grid algorithms for hierarchical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="hospital_birth_rate.html">Comparing birth rates</a></li>
<li class="toctree-l1"><a class="reference internal" href="ok.html">How Many Typos?</a></li>
<li class="toctree-l1"><a class="reference internal" href="bookstore.html">How Many Books?</a></li>
<li class="toctree-l1"><a class="reference internal" href="beta_binomial.html">The All-Knowing Cube of Probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="zipf.html">What’s a chartist?</a></li>
<li class="toctree-l1"><a class="reference internal" href="bread.html">The Poincaré Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="cancer.html">Cancer Survival Rates Are Misleading</a></li>
<li class="toctree-l1"><a class="reference internal" href="raven.html">The Raven Paradox</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/AllenDowney/ThinkBayes2" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chap02.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bayes’s Theorem</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-cookie-problem">2.1. The Cookie Problem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diachronic-bayes">2.2. Diachronic Bayes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-tables">2.3. Bayes Tables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-dice-problem">2.4. The Dice Problem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-monty-hall-problem">2.5. The Monty Hall Problem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">2.6. Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">2.7. Exercises</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>You can order print and ebook versions of <em>Think Bayes 2e</em> from
<a class="reference external" href="https://bookshop.org/a/98697/9781492089469">Bookshop.org</a> and
<a class="reference external" href="https://amzn.to/334eqGo">Amazon</a>.</p>
<section id="bayess-theorem">
<h1><span class="section-number">2. </span>Bayes’s Theorem<a class="headerlink" href="#bayess-theorem" title="Link to this heading">#</a></h1>
<p>In the previous chapter, we derived Bayes’s Theorem:</p>
<div class="math notranslate nohighlight">
\[P(A|B) = \frac{P(A) P(B|A)}{P(B)}\]</div>
<p>As an example, we used data from the General Social Survey and Bayes’s Theorem  to compute conditional probabilities.
But since we had the complete dataset, we didn’t really need Bayes’s Theorem.
It was easy enough to compute the left side of the equation directly, and no easier to compute the right side.</p>
<p>But often we don’t have a complete dataset, and in that case Bayes’s Theorem is more useful.   In this chapter, we’ll use it to solve several more challenging problems related to conditional probability.</p>
<section id="the-cookie-problem">
<h2><span class="section-number">2.1. </span>The Cookie Problem<a class="headerlink" href="#the-cookie-problem" title="Link to this heading">#</a></h2>
<p>We’ll start with a thinly disguised version of an <a class="reference external" href="https://en.wikipedia.org/wiki/Urn_problem">urn problem</a>:</p>
<blockquote>
<div><p>Suppose there are two bowls of cookies.</p>
<ul class="simple">
<li><p>Bowl 1 contains 30 vanilla cookies and 10 chocolate cookies.</p></li>
<li><p>Bowl 2 contains 20 vanilla cookies and 20 chocolate cookies.</p></li>
</ul>
<p>Now suppose you choose one of the bowls at random and, without looking, choose a cookie at random. If the cookie is vanilla, what is the probability that it came from Bowl 1?</p>
</div></blockquote>
<p>What we want is the conditional probability that we chose from Bowl 1 given that we got a vanilla cookie, <span class="math notranslate nohighlight">\(P(B_1 | V)\)</span>.</p>
<p>But what we get from the statement of the problem is:</p>
<ul class="simple">
<li><p>The conditional probability of getting a vanilla cookie, given that we chose from Bowl 1, <span class="math notranslate nohighlight">\(P(V | B_1)\)</span> and</p></li>
<li><p>The conditional probability of getting a vanilla cookie, given that we chose from Bowl 2, <span class="math notranslate nohighlight">\(P(V | B_2)\)</span>.</p></li>
</ul>
<p>Bayes’s Theorem tells us how they are related:</p>
<div class="math notranslate nohighlight">
\[P(B_1|V) = \frac{P(B_1)~P(V|B_1)}{P(V)}\]</div>
<p>The term on the left is what we want. The terms on the right are:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(B_1)\)</span>, the probability that we chose Bowl 1,
unconditioned by what kind of cookie we got.
Since the problem says we chose a bowl at random,
we assume <span class="math notranslate nohighlight">\(P(B_1) = 1/2\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(V|B_1)\)</span>, the probability of getting a vanilla cookie
from Bowl 1, which is 3/4.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(V)\)</span>, the probability of drawing a vanilla cookie from
either bowl.</p></li>
</ul>
<p>To compute <span class="math notranslate nohighlight">\(P(V)\)</span>, we can use the law of total probability:</p>
<div class="math notranslate nohighlight">
\[P(V) = P(B_1)~P(V|B_1) ~+~ P(B_2)~P(V|B_2)\]</div>
<p>Plugging in the numbers from the statement of the problem, we have</p>
<div class="math notranslate nohighlight">
\[P(V) = (1/2)~(3/4) ~+~ (1/2)~(1/2) = 5/8\]</div>
<p>We can also compute this result directly, like this:</p>
<ul class="simple">
<li><p>Since we had an equal chance of choosing either bowl and the bowls contain the same number of cookies, we had the same chance of choosing any cookie.</p></li>
<li><p>Between the two bowls there are 50 vanilla and 30 chocolate cookies, so <span class="math notranslate nohighlight">\(P(V) = 5/8\)</span>.</p></li>
</ul>
<p>Finally, we can apply Bayes’s Theorem to compute the posterior probability of Bowl 1:</p>
<div class="math notranslate nohighlight">
\[P(B_1|V) = (1/2)~(3/4)~/~(5/8) = 3/5\]</div>
<p>This example demonstrates one use of Bayes’s theorem: it provides a
way to get from <span class="math notranslate nohighlight">\(P(B|A)\)</span> to <span class="math notranslate nohighlight">\(P(A|B)\)</span>.
This strategy is useful in cases like this where it is easier to compute the terms on the right side than the term on the left.</p>
</section>
<section id="diachronic-bayes">
<h2><span class="section-number">2.2. </span>Diachronic Bayes<a class="headerlink" href="#diachronic-bayes" title="Link to this heading">#</a></h2>
<p>There is another way to think of Bayes’s theorem: it gives us a way to
update the probability of a hypothesis, <span class="math notranslate nohighlight">\(H\)</span>, given some body of data, <span class="math notranslate nohighlight">\(D\)</span>.</p>
<p>This interpretation is “diachronic”, which means “related to change over time”; in this case, the probability of the hypotheses changes as we see new data.</p>
<p>Rewriting Bayes’s theorem with <span class="math notranslate nohighlight">\(H\)</span> and <span class="math notranslate nohighlight">\(D\)</span> yields:</p>
<div class="math notranslate nohighlight">
\[P(H|D) = \frac{P(H)~P(D|H)}{P(D)}\]</div>
<p>In this interpretation, each term has a name:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(H)\)</span> is the probability of the hypothesis before we see the data, called the prior probability, or just <strong>prior</strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(H|D)\)</span> is the probability of the hypothesis after we see the data, called the <strong>posterior</strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(D|H)\)</span> is the probability of the data under the hypothesis, called the <strong>likelihood</strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(D)\)</span> is the <strong>total probability of the data</strong>, under any hypothesis.</p></li>
</ul>
<p>Sometimes we can compute the prior based on background information. For example, the cookie problem specifies that we choose a bowl at random with equal probability.</p>
<p>In other cases the prior is subjective; that is, reasonable people might disagree, either because they use different background information or because they interpret the same information differently.</p>
<p>The likelihood is usually the easiest part to compute. In the cookie
problem, we are given the number of cookies in each bowl, so we can compute the probability of the data under each hypothesis.</p>
<p>Computing the total probability of the data can be tricky.
It is supposed to be the probability of seeing the data under any hypothesis at all, but it can be hard to nail down what that means.</p>
<p>Most often we simplify things by specifying a set of hypotheses that
are:</p>
<ul class="simple">
<li><p>Mutually exclusive, which means that only one of them can be true, and</p></li>
<li><p>Collectively exhaustive, which means one of them must be true.</p></li>
</ul>
<p>When these conditions apply, we can compute <span class="math notranslate nohighlight">\(P(D)\)</span> using the law of total probability.  For example, with two hypotheses, <span class="math notranslate nohighlight">\(H_1\)</span> and <span class="math notranslate nohighlight">\(H_2\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(D) = P(H_1)~P(D|H_1) + P(H_2)~P(D|H_2)\]</div>
<p>And more generally, with any number of hypotheses:</p>
<div class="math notranslate nohighlight">
\[P(D) = \sum_i P(H_i)~P(D|H_i)\]</div>
<p>The process in this section, using data and a prior probability to compute a posterior probability, is called a <strong>Bayesian update</strong>.</p>
</section>
<section id="bayes-tables">
<h2><span class="section-number">2.3. </span>Bayes Tables<a class="headerlink" href="#bayes-tables" title="Link to this heading">#</a></h2>
<p>A convenient tool for doing a Bayesian update is a Bayes table.
You can write a Bayes table on paper or use a spreadsheet, but in this section I’ll use a Pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<p>First I’ll make empty <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> with one row for each hypothesis:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Bowl 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Bowl 2&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Now I’ll add a column to represent the priors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span>
<span class="n">table</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bowl 1</th>
      <td>0.5</td>
    </tr>
    <tr>
      <th>Bowl 2</th>
      <td>0.5</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>And a column for the likelihoods:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span>
<span class="n">table</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bowl 1</th>
      <td>0.5</td>
      <td>0.75</td>
    </tr>
    <tr>
      <th>Bowl 2</th>
      <td>0.5</td>
      <td>0.50</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here we see a difference from the previous method: we compute likelihoods for both hypotheses, not just Bowl 1:</p>
<ul class="simple">
<li><p>The chance of getting a vanilla cookie from Bowl 1 is 3/4.</p></li>
<li><p>The chance of getting a vanilla cookie from Bowl 2 is 1/2.</p></li>
</ul>
<p>You might notice that the likelihoods don’t add up to 1.  That’s OK; each of them is a probability conditioned on a different hypothesis.
There’s no reason they should add up to 1 and no problem if they don’t.</p>
<p>The next step is similar to what we did with Bayes’s Theorem; we multiply the priors by the likelihoods:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="p">[</span><span class="s1">&#39;unnorm&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span>
<span class="n">table</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bowl 1</th>
      <td>0.5</td>
      <td>0.75</td>
      <td>0.375</td>
    </tr>
    <tr>
      <th>Bowl 2</th>
      <td>0.5</td>
      <td>0.50</td>
      <td>0.250</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>I call the result <code class="docutils literal notranslate"><span class="pre">unnorm</span></code> because these values are the “unnormalized posteriors”.  Each of them is the product of a prior and a likelihood:</p>
<div class="math notranslate nohighlight">
\[P(H_i)~P(D|H_i)\]</div>
<p>which is the numerator of Bayes’s Theorem.
If we add them up, we have</p>
<div class="math notranslate nohighlight">
\[P(H_1)~P(D|H_1) + P(H_2)~P(D|H_2)\]</div>
<p>which is the denominator of Bayes’s Theorem, <span class="math notranslate nohighlight">\(P(D)\)</span>.</p>
<p>So we can compute the total probability of the data like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prob_data</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;unnorm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">prob_data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.625
</pre></div>
</div>
</div>
</div>
<p>Notice that we get 5/8, which is what we got by computing <span class="math notranslate nohighlight">\(P(D)\)</span> directly.</p>
<p>And we can compute the posterior probabilities like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="p">[</span><span class="s1">&#39;posterior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;unnorm&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">prob_data</span>
<span class="n">table</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bowl 1</th>
      <td>0.5</td>
      <td>0.75</td>
      <td>0.375</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>Bowl 2</th>
      <td>0.5</td>
      <td>0.50</td>
      <td>0.250</td>
      <td>0.4</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The posterior probability for Bowl 1 is 0.6, which is what we got using Bayes’s Theorem explicitly.
As a bonus, we also get the posterior probability of Bowl 2, which is 0.4.</p>
<p>When we add up the unnormalized posteriors and divide through, we force the posteriors to add up to 1.  This process is called “normalization”, which is why the total probability of the data is also called the “normalizing constant”.</p>
</section>
<section id="the-dice-problem">
<h2><span class="section-number">2.4. </span>The Dice Problem<a class="headerlink" href="#the-dice-problem" title="Link to this heading">#</a></h2>
<p>A Bayes table can also solve problems with more than two hypotheses.  For example:</p>
<blockquote>
<div><p>Suppose I have a box with a 6-sided die, an 8-sided die, and a 12-sided die. I choose one of the dice at random, roll it, and report that the outcome is a 1. What is the probability that I chose the 6-sided die?</p>
</div></blockquote>
<p>In this example, there are three hypotheses with equal prior
probabilities. The data is my report that the outcome is a 1.</p>
<p>If I chose the 6-sided die, the probability of the data is
1/6. If I chose the 8-sided die, the probability is 1/8, and if I chose the 12-sided die, it’s 1/12.</p>
<p>Here’s a Bayes table that uses integers to represent the hypotheses:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>I’ll use fractions to represent the prior probabilities and the likelihoods.  That way they don’t get rounded off to floating-point numbers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">fractions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Fraction</span>

<span class="n">table2</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">table2</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">table2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>1/3</td>
      <td>1/6</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1/3</td>
      <td>1/8</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1/3</td>
      <td>1/12</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Once you have priors and likelhoods, the remaining steps are always the same, so I’ll put them in a function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="n">table</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the posterior probabilities.&quot;&quot;&quot;</span>
    <span class="n">table</span><span class="p">[</span><span class="s1">&#39;unnorm&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span>
    <span class="n">prob_data</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;unnorm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">table</span><span class="p">[</span><span class="s1">&#39;posterior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s1">&#39;unnorm&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">prob_data</span>
    <span class="k">return</span> <span class="n">prob_data</span>
</pre></div>
</div>
</div>
</div>
<p>And call it like this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prob_data</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">table2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here is the final Bayes table:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>1/3</td>
      <td>1/6</td>
      <td>1/18</td>
      <td>4/9</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1/3</td>
      <td>1/8</td>
      <td>1/24</td>
      <td>1/3</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1/3</td>
      <td>1/12</td>
      <td>1/36</td>
      <td>2/9</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The posterior probability of the 6-sided die is 4/9, which is a little more than the probabilities for the other dice, 3/9 and 2/9.
Intuitively, the 6-sided die is the most likely because it had the highest likelihood of producing the outcome we saw.</p>
</section>
<section id="the-monty-hall-problem">
<h2><span class="section-number">2.5. </span>The Monty Hall Problem<a class="headerlink" href="#the-monty-hall-problem" title="Link to this heading">#</a></h2>
<p>Next we’ll use a Bayes table to solve one of the most contentious problems in probability.</p>
<p>The Monty Hall problem is based on a game show called <em>Let’s Make a Deal</em>. If you are a contestant on the show, here’s how the game works:</p>
<ul class="simple">
<li><p>The host, Monty Hall, shows you three closed doors – numbered 1, 2, and 3 – and tells you that there is a prize behind each door.</p></li>
<li><p>One prize is valuable (traditionally a car), the other two are less valuable (traditionally goats).</p></li>
<li><p>The object of the game is to guess which door has the car. If you guess right, you get to keep the car.</p></li>
</ul>
<p>Suppose you pick Door 1. Before opening the door you chose, Monty opens Door 3 and reveals a goat. Then Monty offers you the option to stick with your original choice or switch to the remaining unopened door.</p>
<p>To maximize your chance of winning the car, should you stick with Door 1 or switch to Door 2?</p>
<p>To answer this question, we have to make some assumptions about the behavior of the host:</p>
<ol class="arabic simple">
<li><p>Monty always opens a door and offers you the option to switch.</p></li>
<li><p>He never opens the door you picked or the door with the car.</p></li>
<li><p>If you choose the door with the car, he chooses one of the other
doors at random.</p></li>
</ol>
<p>Under these assumptions, you are better off switching.
If you stick, you win <span class="math notranslate nohighlight">\(1/3\)</span> of the time. If you switch, you win <span class="math notranslate nohighlight">\(2/3\)</span> of the time.</p>
<p>If you have not encountered this problem before, you might find that
answer surprising. You would not be alone; many people have the strong
intuition that it doesn’t matter if you stick or switch. There are two
doors left, they reason, so the chance that the car is behind Door A is 50%. But that is wrong.</p>
<p>To see why, it can help to use a Bayes table. We start with three
hypotheses: the car might be behind Door 1, 2, or 3. According to the
statement of the problem, the prior probability for each door is 1/3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Door 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Door 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Door 3&#39;</span><span class="p">])</span>
<span class="n">table3</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">table3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Door 1</th>
      <td>1/3</td>
    </tr>
    <tr>
      <th>Door 2</th>
      <td>1/3</td>
    </tr>
    <tr>
      <th>Door 3</th>
      <td>1/3</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The data is that Monty opened Door 3 and revealed a goat. So let’s
consider the probability of the data under each hypothesis:</p>
<ul class="simple">
<li><p>If the car is behind Door 1, Monty chooses Door 2 or 3 at random, so the probability he opens Door 3 is <span class="math notranslate nohighlight">\(1/2\)</span>.</p></li>
<li><p>If the car is behind Door 2, Monty has to open Door 3, so the probability of the data under this hypothesis is 1.</p></li>
<li><p>If the car is behind Door 3, Monty does not open it, so the probability of the data under this hypothesis is 0.</p></li>
</ul>
<p>Here are the likelihoods.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table3</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>
<span class="n">table3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Door 1</th>
      <td>1/3</td>
      <td>1/2</td>
    </tr>
    <tr>
      <th>Door 2</th>
      <td>1/3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Door 3</th>
      <td>1/3</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now that we have priors and likelihoods, we can use <code class="docutils literal notranslate"><span class="pre">update</span></code> to compute the posterior probabilities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">update</span><span class="p">(</span><span class="n">table3</span><span class="p">)</span>
<span class="n">table3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Door 1</th>
      <td>1/3</td>
      <td>1/2</td>
      <td>1/6</td>
      <td>1/3</td>
    </tr>
    <tr>
      <th>Door 2</th>
      <td>1/3</td>
      <td>1</td>
      <td>1/3</td>
      <td>2/3</td>
    </tr>
    <tr>
      <th>Door 3</th>
      <td>1/3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>After Monty opens Door 3, the posterior probability of Door 1 is <span class="math notranslate nohighlight">\(1/3\)</span>;
the posterior probability of Door 2 is <span class="math notranslate nohighlight">\(2/3\)</span>.
So you are better off switching from Door 1 to Door 2.</p>
<p>As this example shows, our intuition for probability is not always
reliable.
Bayes’s Theorem can help by providing a divide-and-conquer strategy:</p>
<ol class="arabic simple">
<li><p>First, write down the hypotheses and the data.</p></li>
<li><p>Next, figure out the prior probabilities.</p></li>
<li><p>Finally, compute the likelihood of the data under each hypothesis.</p></li>
</ol>
<p>The Bayes table does the rest.</p>
</section>
<section id="summary">
<h2><span class="section-number">2.6. </span>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<p>In this chapter we solved the Cookie Problem using Bayes’s theorem explicitly and using a Bayes table.
There’s no real difference between these methods, but the Bayes table can make it easier to compute the total probability of the data, especially for problems with more than two hypotheses.</p>
<p>Then we solved the Dice Problem, which we will see again in the next chapter, and the Monty Hall problem, which you might hope you never see again.</p>
<p>If the Monty Hall problem makes your head hurt, you are not alone.  But I think it demonstrates the power of Bayes’s Theorem as a divide-and-conquer strategy for solving tricky problems.  And I hope it provides some insight into <em>why</em> the answer is what it is.</p>
<p>When Monty opens a door, he provides information we can use to update our belief about the location of the car.  Part of the information is obvious.  If he opens Door 3, we know the car is not behind Door 3.  But part of the information is more subtle.  Opening Door 3 is more likely if the car is behind Door 2, and less likely if it is behind Door 1.  So the data is evidence in favor of Door 2.  We will come back to this notion of evidence in future chapters.</p>
<p>In the next chapter we’ll extend the Cookie Problem and the Dice Problem, and take the next step from basic probability to Bayesian statistics.</p>
<p>But first, you might want to work on the exercises.</p>
</section>
<section id="exercises">
<h2><span class="section-number">2.7. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<p><strong>Exercise:</strong> Suppose you have two coins in a box.
One is a normal coin with heads on one side and tails on the other, and one is a trick coin with heads on both sides.  You choose a coin at random and see that one of the sides is heads.
What is the probability that you chose the trick coin?</p>
<div class="cell tag_hide-cell docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell content</p>
<p class="expanded admonition-title">Hide code cell content</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">table4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="s1">&#39;Trick&#39;</span><span class="p">])</span>
<span class="n">table4</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span>
<span class="n">table4</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span>

<span class="n">update</span><span class="p">(</span><span class="n">table4</span><span class="p">)</span>
<span class="n">table4</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Normal</th>
      <td>0.5</td>
      <td>0.5</td>
      <td>0.25</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>Trick</th>
      <td>0.5</td>
      <td>1.0</td>
      <td>0.50</td>
      <td>0.666667</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</details>
</div>
<p><strong>Exercise:</strong> Suppose you meet someone and learn that they have two children.
You ask if either child is a girl and they say yes.
What is the probability that both children are girls?</p>
<p>Hint: Start with four equally likely hypotheses.</p>
<div class="cell tag_hide-cell docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell content</p>
<p class="expanded admonition-title">Hide code cell content</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">table5</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;GG&#39;</span><span class="p">,</span> <span class="s1">&#39;GB&#39;</span><span class="p">,</span> <span class="s1">&#39;BG&#39;</span><span class="p">,</span> <span class="s1">&#39;BB&#39;</span><span class="p">])</span>
<span class="n">table5</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">4</span>
<span class="n">table5</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>

<span class="n">update</span><span class="p">(</span><span class="n">table5</span><span class="p">)</span>
<span class="n">table5</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GG</th>
      <td>0.25</td>
      <td>1</td>
      <td>0.25</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>GB</th>
      <td>0.25</td>
      <td>1</td>
      <td>0.25</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>BG</th>
      <td>0.25</td>
      <td>1</td>
      <td>0.25</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>BB</th>
      <td>0.25</td>
      <td>0</td>
      <td>0.00</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</details>
</div>
<p><strong>Exercise:</strong> There are many variations of the <a class="reference external" href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall problem</a>.<br />
For example, suppose Monty always chooses Door 2 if he can, and
only chooses Door 3 if he has to (because the car is behind Door 2).</p>
<p>If you choose Door 1 and Monty opens Door 2, what is the probability the car is behind Door 3?</p>
<p>If you choose Door 1 and Monty opens Door 3, what is the probability the car is behind Door 2?</p>
<div class="cell tag_hide-cell docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell content</p>
<p class="expanded admonition-title">Hide code cell content</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># If the car is behind Door 1, Monty would always open Door 2 </span>
<span class="c1"># If the car was behind Door 2, Monty would have opened Door 3</span>
<span class="c1"># If the car is behind Door 3, Monty would always open Door 2</span>

<span class="n">table6</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Door 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Door 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Door 3&#39;</span><span class="p">])</span>
<span class="n">table6</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
<span class="n">table6</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>

<span class="n">update</span><span class="p">(</span><span class="n">table6</span><span class="p">)</span>
<span class="n">table6</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Door 1</th>
      <td>0.333333</td>
      <td>1</td>
      <td>0.333333</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>Door 2</th>
      <td>0.333333</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Door 3</th>
      <td>0.333333</td>
      <td>1</td>
      <td>0.333333</td>
      <td>0.5</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</details>
</div>
<div class="cell tag_hide-cell docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell content</p>
<p class="expanded admonition-title">Hide code cell content</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># If the car is behind Door 1, Monty would have opened Door 2</span>
<span class="c1"># If the car is behind Door 2, Monty would always open Door 3</span>
<span class="c1"># If the car is behind Door 3, Monty would have opened Door 2</span>

<span class="n">table7</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Door 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Door 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Door 3&#39;</span><span class="p">])</span>
<span class="n">table7</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
<span class="n">table7</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>

<span class="n">update</span><span class="p">(</span><span class="n">table7</span><span class="p">)</span>
<span class="n">table7</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Door 1</th>
      <td>0.333333</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Door 2</th>
      <td>0.333333</td>
      <td>1</td>
      <td>0.333333</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Door 3</th>
      <td>0.333333</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</details>
</div>
<p><strong>Exercise:</strong> M&amp;M’s are small candy-coated chocolates that come in a variety of colors.<br />
Mars, Inc., which makes M&amp;M’s, changes the mixture of colors from time to time.
In 1995, they introduced blue M&amp;M’s.</p>
<ul class="simple">
<li><p>In 1994, the color mix in a bag of plain M&amp;M’s was 30% Brown, 20% Yellow, 20% Red, 10% Green, 10% Orange, 10% Tan.</p></li>
<li><p>In 1996, it was 24% Blue , 20% Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown.</p></li>
</ul>
<p>Suppose a friend of mine has two bags of M&amp;M’s, and he tells me
that one is from 1994 and one from 1996.  He won’t tell me which is
which, but he gives me one M&amp;M from each bag.  One is yellow and
one is green.  What is the probability that the yellow one came
from the 1994 bag?</p>
<p>Hint: The trick to this question is to define the hypotheses and the data carefully.</p>
<div class="cell tag_hide-cell docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell content</p>
<p class="expanded admonition-title">Hide code cell content</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Hypotheses:</span>
<span class="c1"># A: yellow from 94, green from 96</span>
<span class="c1"># B: yellow from 96, green from 94</span>

<span class="n">table8</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">])</span>
<span class="n">table8</span><span class="p">[</span><span class="s1">&#39;prior&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span>
<span class="n">table8</span><span class="p">[</span><span class="s1">&#39;likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.2</span><span class="o">*</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.14</span><span class="o">*</span><span class="mf">0.1</span>

<span class="n">update</span><span class="p">(</span><span class="n">table8</span><span class="p">)</span>
<span class="n">table8</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>A</th>
      <td>0.5</td>
      <td>0.040</td>
      <td>0.020</td>
      <td>0.740741</td>
    </tr>
    <tr>
      <th>B</th>
      <td>0.5</td>
      <td>0.014</td>
      <td>0.007</td>
      <td>0.259259</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</details>
</div>
<p><em>Think Bayes</em>, Second Edition</p>
<p>Copyright 2020 Allen B. Downey</p>
<p>License: <a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="chap01.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>Probability</p>
      </div>
    </a>
    <a class="right-next"
       href="chap03.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Distributions</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-cookie-problem">2.1. The Cookie Problem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diachronic-bayes">2.2. Diachronic Bayes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-tables">2.3. Bayes Tables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-dice-problem">2.4. The Dice Problem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-monty-hall-problem">2.5. The Monty Hall Problem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">2.6. Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">2.7. Exercises</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Allen B. Downey
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>