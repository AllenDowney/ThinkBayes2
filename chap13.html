
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Inference &#8212; Think Bayes</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Survival Analysis" href="chap14.html" />
    <link rel="prev" title="Classification" href="chap12.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  
  <h1 class="site-logo" id="site-title">Think Bayes</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="README.html">
   ThinkBayes2
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="chap01.html">
   Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap02.html">
   Bayes’s Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap03.html">
   Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap04.html">
   Estimating proportions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap05.html">
   Estimating counts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap06.html">
   Odds and Addends
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap07.html">
   Minimum, maximum, and mixture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap08.html">
   Poisson Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap09.html">
   Decision Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap10.html">
   Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap11.html">
   Comparison
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap12.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap14.html">
   Survival Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap15.html">
   Mark and Recapture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap16.html">
   Logistic regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap17.html">
   Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap18.html">
   Conjugate Priors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap19.html">
   MCMC
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chap13.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/AllenDowney/ThinkBayes2"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/AllenDowney/ThinkBayes2/master?urlpath=tree/chap13.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#improving-reading-ability">
   Improving Reading Ability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimating-parameters">
   Estimating parameters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#likelihood">
   Likelihood
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#posterior-marginal-distributions">
   Posterior marginal distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#distribution-of-differences">
   Distribution of Differences
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-summary-statistics">
   Using Summary Statistics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#update-with-summary-statistics">
   Update with summary statistics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#comparing-marginals">
   Comparing Marginals
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#proof-by-simulation">
   Proof By Simulation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checking-standard-deviation">
   Checking Standard Deviation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise">
   Exercise
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="inference">
<h1>Inference<a class="headerlink" href="#inference" title="Permalink to this headline">¶</a></h1>
<p>Whenever people compare Bayesian inference with conventional approaches, one of the questions that comes up most often is something like, “What about p-values?”
And one of the most common examples is the comparison of two groups to see if there is a difference in their means.</p>
<p>In classical statistical inference, the usual tool for this scenario is a <a class="reference external" href="https://en.wikipedia.org/wiki/Student%27s_t-test">Student’s <em>t</em>-test</a>, and the result is a <a class="reference external" href="https://en.wikipedia.org/wiki/P-value">p-value</a>.
This process is an example of <a class="reference external" href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">null hypothesis significance testing</a>.</p>
<p>A Bayesian alternative is to compute the posterior distribution of the difference between the groups.
Then we can use that distribution to answer whatever questions we are interested in, including the most likely size of the difference, a credible interval that’s likely to contain the true difference, the probability of superiority, or the probability that the difference exceeds some threshold.</p>
<p>To demonstrate this process, I’ll solve a problem borrowed from a statistical textbook: evaluating the effect of an educational “treatment” compared to a control.</p>
<div class="section" id="improving-reading-ability">
<h2>Improving Reading Ability<a class="headerlink" href="#improving-reading-ability" title="Permalink to this headline">¶</a></h2>
<p>We’ll use data from a <a class="reference external" href="https://docs.lib.purdue.edu/dissertations/AAI8807671/">Ph.D. dissertation in educational psychology</a> written in 1987, which was used as an example in a <a class="reference external" href="https://books.google.com/books/about/Introduction_to_the_practice_of_statisti.html?id=pGBNhajABlUC">statistics textbook</a> from 1989 and published on <a class="reference external" href="https://web.archive.org/web/20000603124754/http://lib.stat.cmu.edu/DASL/Datafiles/DRPScores.html">DASL</a>, a web page that collects data stories.</p>
<p>Here’s the description from DASL:</p>
<blockquote>
<div><p>An educator conducted an experiment to test whether new directed reading activities in the classroom will help elementary school pupils improve some aspects of their reading ability. She arranged for a third grade class of 21 students to follow these activities for an 8-week period. A control classroom of 23 third graders followed the same curriculum without the activities. At the end of the 8 weeks, all students took a Degree of Reading Power (DRP) test, which measures the aspects of reading ability that the treatment is designed to improve.</p>
</div></blockquote>
<p>The <a class="reference external" href="https://web.archive.org/web/20000603124754/http://lib.stat.cmu.edu/DASL/Datafiles/DRPScores.html">dataset is available here</a>.</p>
<p>I’ll use Pandas to load the data into a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;drp_scores.csv&#39;</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="mi">21</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Treatment</th>
      <th>Response</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Treated</td>
      <td>24</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Treated</td>
      <td>43</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Treated</td>
      <td>58</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Treated</td>
      <td>71</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Treated</td>
      <td>43</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>I’ll use <code class="docutils literal notranslate"><span class="pre">groupby</span></code> to separate the data for the <code class="docutils literal notranslate"><span class="pre">Treated</span></code> and <code class="docutils literal notranslate"><span class="pre">Control</span></code> groups:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grouped</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Treatment&#39;</span><span class="p">)</span>
<span class="n">responses</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">grouped</span><span class="p">:</span>
    <span class="n">responses</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;Response&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Here are CDFs of the scores for the two groups and summary statistics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">empiricaldist</span> <span class="kn">import</span> <span class="n">Cdf</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">decorate</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">responses</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="n">response</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">response</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
    <span class="n">cdf</span> <span class="o">=</span> <span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="n">cdf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    
<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Score&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;CDF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Control 23 41.52173913043478 17.148733229699484
Treated 21 51.476190476190474 11.00735684721381
</pre></div>
</div>
<img alt="_images/chap13_13_1.png" src="_images/chap13_13_1.png" />
</div>
</div>
<p>The distribution of scores is not exactly normal for either group, but it is close enough that the normal model is a reasonable choice.</p>
<p>So I’ll assume that in the entire population of students (not just the ones in the experiment), the distribution of scores is well modeled by a normal distribution with unknown mean and standard deviation.
I’ll use <code class="docutils literal notranslate"><span class="pre">mu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> to denote these unknown parameters.</p>
<p>And we’ll do a Bayesian update to estimate what they are.</p>
</div>
<div class="section" id="estimating-parameters">
<h2>Estimating parameters<a class="headerlink" href="#estimating-parameters" title="Permalink to this headline">¶</a></h2>
<p>As always, we need a prior distribution for the parameters.<br />
Since there are two parameters, it will be a joint distribution.<br />
I’ll construct it by choosing marginal distributions for each parameter and computing their outer product.</p>
<p>As a simple starting place, I’ll assume that the prior distributions for <code class="docutils literal notranslate"><span class="pre">mu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> are uniform.
I’ll use the following function to make <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> objects that represent the priors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">empiricaldist</span> <span class="kn">import</span> <span class="n">Pmf</span>

<span class="k">def</span> <span class="nf">make_uniform</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a Pmf that represents a uniform distribution.</span>
<span class="sd">    </span>
<span class="sd">    start: lower bound</span>
<span class="sd">    stop: upper bound</span>
<span class="sd">    num: number of points</span>
<span class="sd">    name: string name for the quantities</span>
<span class="sd">    options: passed to Pmf</span>
<span class="sd">    </span>
<span class="sd">    returns: Pmf</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">qs</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>
    <span class="n">pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">name</span><span class="p">:</span>
        <span class="n">pmf</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="k">return</span> <span class="n">pmf</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">make_uniform</span></code> takes the lower and upper bounds of the distribution and the number of points in the interval.
It also takes a string, <code class="docutils literal notranslate"><span class="pre">name</span></code>, which is assigned to the index so it appears when we display the <code class="docutils literal notranslate"><span class="pre">Pmf</span></code>.</p>
<p>Here’s the prior distribution for <code class="docutils literal notranslate"><span class="pre">mu</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior_mu</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>I chose the lower and upper bounds by trial and error.
I’ll explain how when we look at the posterior distribution.</p>
<p>Here’s the prior distribution for <code class="docutils literal notranslate"><span class="pre">sigma</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior_sigma</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;std&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can use <code class="docutils literal notranslate"><span class="pre">make_joint</span></code> to make the joint prior distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">make_joint</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">prior_mu</span><span class="p">,</span> <span class="n">prior_sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And we’ll start by working with the data from the control group.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">responses</span><span class="p">[</span><span class="s1">&#39;Control&#39;</span><span class="p">]</span>
<span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(23,)
</pre></div>
</div>
</div>
</div>
<p>In the next section we’ll compute the likelihood of this data for each pair of parameters in the prior distribution.</p>
</div>
<div class="section" id="likelihood">
<h2>Likelihood<a class="headerlink" href="#likelihood" title="Permalink to this headline">¶</a></h2>
<p>Now, we would like to know the probability of each score in the dataset for each hypothetical pair of values, <code class="docutils literal notranslate"><span class="pre">mu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code>.
I’ll do that by making a 3-dimensional grid with values of <code class="docutils literal notranslate"><span class="pre">mu</span></code> on the first axis, values of <code class="docutils literal notranslate"><span class="pre">sigma</span></code> on the second axis, and the scores from the dataset on the third axis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu_mesh</span><span class="p">,</span> <span class="n">sigma_mesh</span><span class="p">,</span> <span class="n">data_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
    <span class="n">prior</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">prior</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="n">mu_mesh</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101, 23)
</pre></div>
</div>
</div>
</div>
<p>Now we can use <code class="docutils literal notranslate"><span class="pre">norm.pdf</span></code> to compute the probability density of each score for each hypothetical pair of parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="n">densities</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">mu_mesh</span><span class="p">,</span> <span class="n">sigma_mesh</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data_mesh</span><span class="p">)</span>
<span class="n">densities</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101, 23)
</pre></div>
</div>
</div>
</div>
<p>The result is a 3-D array.  To compute likelihoods, I’ll compute the product of these densities along the third axis, that is <code class="docutils literal notranslate"><span class="pre">axis=2</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">densities</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">likelihood</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101)
</pre></div>
</div>
</div>
</div>
<p>The result is a 2-D array that contains the likelihood of the entire dataset for each hypothetical pair of parameters.</p>
<p>We can use this array to update the prior, like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">normalize</span>

<span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span>
<span class="n">normalize</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="n">posterior</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101)
</pre></div>
</div>
</div>
</div>
<p>The result is a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> that represents the joint posterior distribution.</p>
<p>The following function encapsulates these steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_norm</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update the prior based on data.</span>
<span class="sd">    </span>
<span class="sd">    prior: joint distribution of mu and sigma</span>
<span class="sd">    data: sequence of observations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mu_mesh</span><span class="p">,</span> <span class="n">sigma_mesh</span><span class="p">,</span> <span class="n">data_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
        <span class="n">prior</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">prior</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    
    <span class="n">densities</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">mu_mesh</span><span class="p">,</span> <span class="n">sigma_mesh</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data_mesh</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">densities</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span>
    <span class="n">normalize</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">posterior</span>
</pre></div>
</div>
</div>
</div>
<p>Here are the updates for the control and treatment groups:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">responses</span><span class="p">[</span><span class="s1">&#39;Control&#39;</span><span class="p">]</span>
<span class="n">posterior_control</span> <span class="o">=</span> <span class="n">update_norm</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">responses</span><span class="p">[</span><span class="s1">&#39;Treated&#39;</span><span class="p">]</span>
<span class="n">posterior_treated</span> <span class="o">=</span> <span class="n">update_norm</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And here’s what they look like:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">plot_contour</span>

<span class="n">plot_contour</span><span class="p">(</span><span class="n">posterior_control</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">49.5</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="s1">&#39;Control&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>

<span class="n">cs</span> <span class="o">=</span> <span class="n">plot_contour</span><span class="p">(</span><span class="n">posterior_treated</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Oranges&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">57</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="s1">&#39;Treated&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Mean&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Standard deviation&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_40_0.png" src="_images/chap13_40_0.png" />
</div>
</div>
<p>Along the <code class="docutils literal notranslate"><span class="pre">x</span></code> axis, it looks like the mean score for the treated group is higher.
Along the <code class="docutils literal notranslate"><span class="pre">y</span></code> axis, it looks like the standard deviation for the control group is higher.</p>
<p>If we think the treatment causes these differences, the data suggest that the treatment increases the mean of the scores and decreases their spread.
We can see these differences more clearly by looking at the marginal distributions for <code class="docutils literal notranslate"><span class="pre">mu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code>.</p>
</div>
<div class="section" id="posterior-marginal-distributions">
<h2>Posterior marginal distributions<a class="headerlink" href="#posterior-marginal-distributions" title="Permalink to this headline">¶</a></h2>
<p>I’ll use <code class="docutils literal notranslate"><span class="pre">marginal</span></code>, which we saw in Chapter 9, to extract the posterior marginal distributions for the population means.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">marginal</span>

<span class="n">pmf_mean_control</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">posterior_control</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">pmf_mean_treated</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">posterior_treated</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s what they look like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmf_mean_control</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Control&#39;</span><span class="p">)</span>
<span class="n">pmf_mean_treated</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Treated&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Population mean&#39;</span><span class="p">,</span> 
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span> 
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distributions of mu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_45_0.png" src="_images/chap13_45_0.png" />
</div>
</div>
<p>In both cases the posterior probabilities at the ends of the range are near zero, which means that the bounds we chose for the prior distribution are wide enough.</p>
<p>Comparing the marginal distributions for the two groups, it looks like the population mean in the treated group is higher.
We can use <code class="docutils literal notranslate"><span class="pre">prob_gt</span></code> to compute the probability of superiority:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pmf</span><span class="o">.</span><span class="n">prob_gt</span><span class="p">(</span><span class="n">pmf_mean_treated</span><span class="p">,</span> <span class="n">pmf_mean_control</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.980479025187326
</pre></div>
</div>
</div>
</div>
<p>There is a 98% chance that the mean in the treated group is higher.</p>
</div>
<div class="section" id="distribution-of-differences">
<h2>Distribution of Differences<a class="headerlink" href="#distribution-of-differences" title="Permalink to this headline">¶</a></h2>
<p>To quantify the magnitude of the difference between groups, we can use <code class="docutils literal notranslate"><span class="pre">sub_dist</span></code> to compute the distribution of the difference.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmf_diff</span> <span class="o">=</span> <span class="n">Pmf</span><span class="o">.</span><span class="n">sub_dist</span><span class="p">(</span><span class="n">pmf_mean_treated</span><span class="p">,</span> <span class="n">pmf_mean_control</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Two things to be careful about when you use methods like <code class="docutils literal notranslate"><span class="pre">sub_dist</span></code>:</p>
<p>The first is that the result usually contains more elements than the original <code class="docutils literal notranslate"><span class="pre">Pmf</span></code>.<br />
In this example, the original distributions have the same quantities, so the size increase is moderate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">pmf_mean_treated</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">pmf_mean_control</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">pmf_diff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101, 879)
</pre></div>
</div>
</div>
</div>
<p>In the worst case, the size of the result can be the product of the sizes of the originals.</p>
<p>The other thing to be aware of is that plotting a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> does not always work well.
In this example, if we plot the distribution of differences, the result is pretty noisy.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmf_diff</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Difference in population means&#39;</span><span class="p">,</span> 
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span> 
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distribution of difference in mu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_54_0.png" src="_images/chap13_54_0.png" />
</div>
</div>
<p>There are two ways to work around that limitation.  One is to plot the CDF, which smooths out the noise:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cdf_diff</span> <span class="o">=</span> <span class="n">pmf_diff</span><span class="o">.</span><span class="n">make_cdf</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cdf_diff</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Difference in population means&#39;</span><span class="p">,</span> 
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;CDF&#39;</span><span class="p">,</span> 
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distribution of difference in mu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_57_0.png" src="_images/chap13_57_0.png" />
</div>
</div>
<p>The other option is to use kernel density estimation (KDE) to make a smooth approximation of the PDF on an equally-spaced grid, which is what this function does:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">gaussian_kde</span>

<span class="k">def</span> <span class="nf">kde_from_pmf</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">101</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a kernel density estimate for a PMF.</span>
<span class="sd">    </span>
<span class="sd">    pmf: Pmf object</span>
<span class="sd">    n: number of points</span>
<span class="sd">    </span>
<span class="sd">    returns: Pmf object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kde</span> <span class="o">=</span> <span class="n">gaussian_kde</span><span class="p">(</span><span class="n">pmf</span><span class="o">.</span><span class="n">qs</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">pmf</span><span class="o">.</span><span class="n">ps</span><span class="p">)</span>
    <span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">pmf</span><span class="o">.</span><span class="n">qs</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">pmf</span><span class="o">.</span><span class="n">qs</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">kde</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">qs</span><span class="p">)</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">qs</span><span class="p">)</span>
    <span class="n">pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pmf</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">kde_from_pmf</span></code> takes as parameters a <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> and the number of places to evaluate the KDE.</p>
<p>It uses <code class="docutils literal notranslate"><span class="pre">gaussian_kde</span></code>, which we saw in Section xxx, passing the probabilities from the <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> as weights.
This makes the estimated densities higher where the probabilities in the <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> are higher.</p>
<p>Here’s what the kernel density estimate looks like for the <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> of differences between the groups.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kde_diff</span> <span class="o">=</span> <span class="n">kde_from_pmf</span><span class="p">(</span><span class="n">pmf_diff</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kde_diff</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Difference in means&#39;</span><span class="p">,</span> 
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span> 
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distribution of difference in mu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_62_0.png" src="_images/chap13_62_0.png" />
</div>
</div>
<p>The mean of this distribution is almost 10 points on a test where the mean is around 45, so the effect of the treatment seems to be substantial.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmf_diff</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>9.954413088940848
</pre></div>
</div>
</div>
</div>
<p>We can use <code class="docutils literal notranslate"><span class="pre">credible_interval</span></code> to compute a 90% credible interval.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmf_diff</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 2.4, 17.4])
</pre></div>
</div>
</div>
</div>
<p>Based on this interval, we are pretty sure the treatment improves test scores by 2 to 17 points.</p>
</div>
<div class="section" id="using-summary-statistics">
<h2>Using Summary Statistics<a class="headerlink" href="#using-summary-statistics" title="Permalink to this headline">¶</a></h2>
<p>In this example the dataset is not very big, so it doesn’t take too long to compute the probability of every score under every hypothesis.
But the result is a 3-D array; for larger datasets, it might be too big to compute practically.</p>
<p>Also, with larger datasets the likelihoods get very small, sometimes so small that we can’t compute them with floating-point arithmetic.
That’s because we are computing the probability of a particular dataset; the number of possible datasets is astronomically big, so the probability of any of them is very small.</p>
<p>An alternative is to compute a summary of the dataset and compute the likelihood of the summary.
For example, if we compute the mean and standard deviation of the data, we can compute the likelihood of those summary statistics under each hypothesis.</p>
<p>As an example, suppose we know that the actual mean of the population, <span class="math notranslate nohighlight">\(\mu\)</span>,  is 42 and the actual standard deviation, <span class="math notranslate nohighlight">\(\sigma\)</span>, is 17.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">17</span>
</pre></div>
</div>
</div>
</div>
<p>Now suppose we draw a sample from this distribution with sample size <code class="docutils literal notranslate"><span class="pre">n=20</span></code>, and compute the mean of the sample, which I’ll call <code class="docutils literal notranslate"><span class="pre">m</span></code>, and the standard deviation of the sample, which I’ll call <code class="docutils literal notranslate"><span class="pre">s</span></code>.</p>
<p>And suppose it turns out that:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">41</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">18</span>
</pre></div>
</div>
</div>
</div>
<p>The summary statistics, <code class="docutils literal notranslate"><span class="pre">m</span></code> and <code class="docutils literal notranslate"><span class="pre">s</span></code>, are not too far from the parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, so it seems like they are not too unlikely.</p>
<p>To compute their likelihood, we will take advantage of three results from mathematical statistics:</p>
<ul class="simple">
<li><p>Given <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, the distribution of <code class="docutils literal notranslate"><span class="pre">m</span></code> is normal with parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span>.</p></li>
<li><p>The distribution of <span class="math notranslate nohighlight">\(s\)</span> is more complicated, but if we compute the transform <span class="math notranslate nohighlight">\(t = n s^2 / \sigma^2\)</span>, the distribution of <span class="math notranslate nohighlight">\(t\)</span> is chi-squared with parameter <span class="math notranslate nohighlight">\(n-1\)</span>.</p></li>
<li><p>And, according to <a class="reference external" href="https://en.wikipedia.org/wiki/Basu%27s_theorem">Basu’s theorem</a>, <code class="docutils literal notranslate"><span class="pre">m</span></code> and <code class="docutils literal notranslate"><span class="pre">s</span></code> are independent.</p></li>
</ul>
<p>So let’s compute the likelihood of <code class="docutils literal notranslate"><span class="pre">m</span></code> and <code class="docutils literal notranslate"><span class="pre">s</span></code> given <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>First I’ll create a <code class="docutils literal notranslate"><span class="pre">norm</span></code> object that represents the distribution of <code class="docutils literal notranslate"><span class="pre">m</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_m</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>This is the “sampling distribution of the mean”.
We can use it to compute the likelihood of the observed value of <code class="docutils literal notranslate"><span class="pre">m</span></code>, which is 41.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">like1</span> <span class="o">=</span> <span class="n">dist_m</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">like1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.10137915138497372
</pre></div>
</div>
</div>
</div>
<p>The result is a probability density, which we will use to update the prior.</p>
<p>But first we have to compute the likelihood of the observed value of <code class="docutils literal notranslate"><span class="pre">s</span></code>, which is 18.</p>
<p>First, we compute the transformed value <code class="docutils literal notranslate"><span class="pre">t</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">s</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span>
<span class="n">t</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>22.422145328719722
</pre></div>
</div>
</div>
</div>
<p>Then we create a <code class="docutils literal notranslate"><span class="pre">chi2</span></code> object to represent the distribution of <code class="docutils literal notranslate"><span class="pre">t</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">chi2</span>

<span class="n">dist_s</span> <span class="o">=</span> <span class="n">chi2</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can compute the likelihood of <code class="docutils literal notranslate"><span class="pre">t</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">like2</span> <span class="o">=</span> <span class="n">dist_s</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="n">like2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.04736427909437004
</pre></div>
</div>
</div>
</div>
<p>Again, the result is a probability density.</p>
<p>Finally, because <code class="docutils literal notranslate"><span class="pre">m</span></code> and <code class="docutils literal notranslate"><span class="pre">s</span></code> are independent, their joint likelihood is the product of their likelihoods:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">like</span> <span class="o">=</span> <span class="n">like1</span> <span class="o">*</span> <span class="n">like2</span>
<span class="n">like</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.004801750420548287
</pre></div>
</div>
</div>
</div>
<p>By itself this number doesn’t mean very much, but now we can compute the likelihood of the data for any values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, which we’ll use in the next section to do the update.</p>
</div>
<div class="section" id="update-with-summary-statistics">
<h2>Update with summary statistics<a class="headerlink" href="#update-with-summary-statistics" title="Permalink to this headline">¶</a></h2>
<p>Now we’re ready to do an update.
I’ll compute summary statistics for the two groups.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">responses</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">summary</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="n">response</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">response</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    
<span class="n">summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;Control&#39;: (23, 41.52173913043478, 17.148733229699484),
 &#39;Treated&#39;: (21, 51.476190476190474, 11.00735684721381)}
</pre></div>
</div>
</div>
</div>
<p>The result is a dictionary that maps from group name to a tuple that contains the sample size, <code class="docutils literal notranslate"><span class="pre">n</span></code>, the sample mean, <code class="docutils literal notranslate"><span class="pre">m</span></code>, and the sample standard deviation <code class="docutils literal notranslate"><span class="pre">s</span></code>, for each group.</p>
<p>I’ll demonstrate the update with the summary statistics from the control group.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">summary</span><span class="p">[</span><span class="s1">&#39;Control&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>I’ll make a mesh with hypothetical values of <code class="docutils literal notranslate"><span class="pre">mu</span></code> on the <code class="docutils literal notranslate"><span class="pre">x</span></code> axis and values of <code class="docutils literal notranslate"><span class="pre">sigma</span></code> on the <code class="docutils literal notranslate"><span class="pre">y</span></code> axis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mus</span><span class="p">,</span> <span class="n">sigmas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">prior</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">mus</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101)
</pre></div>
</div>
</div>
</div>
<p>Now we can compute the likelihood of seeing the sample mean <code class="docutils literal notranslate"><span class="pre">m</span></code> for each pair of parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">like1</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">mus</span><span class="p">,</span> <span class="n">sigmas</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">like1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101)
</pre></div>
</div>
</div>
</div>
<p>The result is an array of probability densities.</p>
<p>Now we can compute the likelihood of the sample standard deviation, <code class="docutils literal notranslate"><span class="pre">s</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">s</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">sigmas</span><span class="o">**</span><span class="mi">2</span>
<span class="n">like2</span> <span class="o">=</span> <span class="n">chi2</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span>
<span class="n">like2</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 101)
</pre></div>
</div>
</div>
</div>
<p>The result is another array of probability densities.</p>
<p>Now we can do the update with both likelihoods:</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior_control2</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">like1</span> <span class="o">*</span> <span class="n">like2</span>
<span class="n">normalize</span><span class="p">(</span><span class="n">posterior_control2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And here’s what the joint posterior distribution looks like for the control group.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_contour</span><span class="p">(</span><span class="n">posterior_control2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">49.5</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="s1">&#39;Control&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Mean&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Standard deviation&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_100_0.png" src="_images/chap13_100_0.png" />
</div>
</div>
<p>To compute the posterior distribution for the treatment group, I’ll put the previous steps in a function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_norm_summary</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update a normal distribution based on summary statistics.</span>
<span class="sd">    </span>
<span class="sd">    prior: DataFrame, joint prior distribution</span>
<span class="sd">    data: tuple of sample size, sample mean, sample std</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">mu_mesh</span><span class="p">,</span> <span class="n">sigma_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">prior</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    
    <span class="n">like1</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">mu_mesh</span><span class="p">,</span> <span class="n">sigma_mesh</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">like2</span> <span class="o">=</span> <span class="n">chi2</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">s</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">sigma_mesh</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">like1</span> <span class="o">*</span> <span class="n">like2</span>
    <span class="n">normalize</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">posterior</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s the update for the treatment group:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">summary</span><span class="p">[</span><span class="s1">&#39;Treated&#39;</span><span class="p">]</span>
<span class="n">posterior_treated2</span> <span class="o">=</span> <span class="n">update_norm_summary</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And here are the results.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_contour</span><span class="p">(</span><span class="n">posterior_control2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">49.5</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="s1">&#39;Control&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>

<span class="n">cs</span> <span class="o">=</span> <span class="n">plot_contour</span><span class="p">(</span><span class="n">posterior_treated2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Oranges&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">57</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="s1">&#39;Treated&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_106_0.png" src="_images/chap13_106_0.png" />
</div>
</div>
<p>Visually, these posterior joint distributions are similar to the ones we computed using the entire dataset, not just the summary statistics.
But they are not exactly the same, as we can see by comparing the marginal distributions.</p>
</div>
<div class="section" id="comparing-marginals">
<h2>Comparing Marginals<a class="headerlink" href="#comparing-marginals" title="Permalink to this headline">¶</a></h2>
<p>Again, let’s extract the marginal posterior distributions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">marginal</span>

<span class="n">pmf_mean_control2</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">posterior_control2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">pmf_mean_treated2</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">posterior_treated2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And compare them to results we got using the entire dataset (shown in gray).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmf_mean_control</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">pmf_mean_control2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Control&#39;</span><span class="p">)</span>
<span class="n">pmf_mean_treated</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">pmf_mean_treated2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Treated&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Population mean&#39;</span><span class="p">,</span> 
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span> 
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distributions of mu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_111_0.png" src="_images/chap13_111_0.png" />
</div>
</div>
<p>The posterior distributions based on summary statistics are similar to the posteriors we computed using the entire dataset, but in both cases they are shorter and a little wider.</p>
<p>That’s because the update with summary statistics is based on the implicit assumption that the distribution of the data is actually normal.
But it’s not; as a result, when we replace the dataset with the summary statistics, we lose some information about the true distribution of the data.
With less information, we are less certain about the parameters.</p>
</div>
<div class="section" id="proof-by-simulation">
<h2>Proof By Simulation<a class="headerlink" href="#proof-by-simulation" title="Permalink to this headline">¶</a></h2>
<p>The update with summary statistics is based on theoretical distributions, and it seems to work, but I think it is useful to test theories like this, for a few reasons:</p>
<ul class="simple">
<li><p>It confirms that our understanding of the theory is correct,</p></li>
<li><p>It confirms that the conditions where we apply the theory are conditions where the theory holds,</p></li>
<li><p>It confirms that the implementation details are correct.  For many distributions, there is more than one way to specify the parameters.  If you use the wrong specification, this kind of testing will help you catch the error.</p></li>
</ul>
<p>In this section I’ll use simulations to show that the distribution of the sample mean and standard deviation is as I claimed.
But if you want to take my word for it, you can skip this section and the next.</p>
<p>Let’s suppose that we know the actual mean and standard deviation of the population:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">17</span>
</pre></div>
</div>
</div>
</div>
<p>I’ll create a <code class="docutils literal notranslate"><span class="pre">norm</span></code> object to represent this distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">norm</span></code> provides <code class="docutils literal notranslate"><span class="pre">rvs</span></code>, which generates random values from the distribution.
We can use it to simulate 1000 samples, each with sample size <code class="docutils literal notranslate"><span class="pre">n=20</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="n">samples</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000, 20)
</pre></div>
</div>
</div>
</div>
<p>The result is an array with 1000 rows, each containing a sample or 20 simulated test scores.</p>
<p>If we compute the mean of each row, the result is an array that contains 1000 sample means; that is, each value is the mean of a sample with <code class="docutils literal notranslate"><span class="pre">n=20</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_means</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sample_means</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000,)
</pre></div>
</div>
</div>
</div>
<p>Now, let’s compare the distribution of these means to <code class="docutils literal notranslate"><span class="pre">dist_m</span></code>.
I’ll use <code class="docutils literal notranslate"><span class="pre">pmf_from_dist</span></code> to make a discrete approximation of <code class="docutils literal notranslate"><span class="pre">dist_m</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pmf_from_dist</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a discrete approximation of a continuous distribution.</span>
<span class="sd">    </span>
<span class="sd">    dist: SciPy dist object</span>
<span class="sd">    low: low end of range</span>
<span class="sd">    high: high end of range</span>
<span class="sd">    </span>
<span class="sd">    returns: normalized Pmf</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">qs</span><span class="p">)</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">qs</span><span class="p">)</span>
    <span class="n">pmf</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pmf</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">pmf_from_dist</span></code> takes an object representing a continuous distribution, evaluates its probability density function at equally space points between <code class="docutils literal notranslate"><span class="pre">low</span></code> and <code class="docutils literal notranslate"><span class="pre">high</span></code>, and returns a normalized <code class="docutils literal notranslate"><span class="pre">Pmf</span></code> that approximates the distribution.</p>
<p>I’ll use it to evaluate <code class="docutils literal notranslate"><span class="pre">dist_m</span></code> over a range of six standard deviations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">low</span> <span class="o">=</span> <span class="n">dist_m</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">dist_m</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="mi">3</span>
<span class="n">high</span> <span class="o">=</span> <span class="n">dist_m</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">dist_m</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="mi">3</span>

<span class="n">pmf_m</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">dist_m</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s compare this theoretical distribution to the means of the samples.
I’ll use <code class="docutils literal notranslate"><span class="pre">kde_from_sample</span></code> to estimate their distribution and evaluate it in the same locations as <code class="docutils literal notranslate"><span class="pre">pmf_m</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">kde_from_sample</span>

<span class="n">qs</span> <span class="o">=</span> <span class="n">pmf_m</span><span class="o">.</span><span class="n">qs</span>
<span class="n">pmf_sample_means</span> <span class="o">=</span> <span class="n">kde_from_sample</span><span class="p">(</span><span class="n">sample_means</span><span class="p">,</span> <span class="n">qs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The following figure shows the two distributions.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmf_m</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theoretical distribution&#39;</span><span class="p">,</span>
           <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">pmf_sample_means</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;KDE of sample means&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Mean score&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_129_0.png" src="_images/chap13_129_0.png" />
</div>
</div>
<p>The theoretical distribution and the distribution of sample means are in accord.</p>
</div>
<div class="section" id="checking-standard-deviation">
<h2>Checking Standard Deviation<a class="headerlink" href="#checking-standard-deviation" title="Permalink to this headline">¶</a></h2>
<p>Let’s also check that the standard deviations follow the distribution we expect.
First I’ll compute the standard deviation for each of the 1000 samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_stds</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sample_stds</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000,)
</pre></div>
</div>
</div>
</div>
<p>Now we’ll compute the transformed values, <span class="math notranslate nohighlight">\(t = n s^2 / \sigma^2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transformed</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">sample_stds</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<p>We expect the transformed values to follow a chi-square distribution with parameter <span class="math notranslate nohighlight">\(n-1\)</span>.
SciPy provides <code class="docutils literal notranslate"><span class="pre">chi2</span></code>, which we can use to represent this distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">chi2</span>

<span class="n">dist_s</span> <span class="o">=</span> <span class="n">chi2</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can use <code class="docutils literal notranslate"><span class="pre">pmf_from_dist</span></code> again to make a discrete approximation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">low</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">high</span> <span class="o">=</span> <span class="n">dist_s</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">dist_s</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="mi">4</span>

<span class="n">pmf_s</span> <span class="o">=</span> <span class="n">pmf_from_dist</span><span class="p">(</span><span class="n">dist_s</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And we’ll use <code class="docutils literal notranslate"><span class="pre">kde_from_sample</span></code> to estimate the distribution of the sample standard deviations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="n">pmf_s</span><span class="o">.</span><span class="n">qs</span>
<span class="n">pmf_sample_stds</span> <span class="o">=</span> <span class="n">kde_from_sample</span><span class="p">(</span><span class="n">transformed</span><span class="p">,</span> <span class="n">qs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can compare the theoretical distribution to the distribution of the standard deviations.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pmf_s</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theoretical distribution&#39;</span><span class="p">,</span>
           <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">pmf_sample_stds</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;KDE of sample std&#39;</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Standard deviation of scores&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_142_0.png" src="_images/chap13_142_0.png" />
</div>
</div>
<p>The distribution of transformed standard deviations agrees with the theoretical distribution.</p>
<p>Finally, to confirm that the sample means and standard deviations are independent, I’ll compute their coefficient of correlation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">sample_means</span><span class="p">,</span> <span class="n">sample_stds</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.006929629021976252
</pre></div>
</div>
</div>
</div>
<p>Their correlation is near zero, which is consistent with their being independent.</p>
<p>So the simulations confirm the theoretical results we used to do the update with summary statistics.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this chapter we used a joint distribution to represent prior probabilities for the parameters of a normal distribution, <code class="docutils literal notranslate"><span class="pre">mu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code>.</p>
<p>And we updated that distribution two ways: first using the entire dataset and the normal PDF; then using summary statistics, the normal PDF, and the chi-square PDF.</p>
<p>Using summary statistics is computationally more efficient, but it loses some information in the process.</p>
<p>Normal distributions appear in many domains, so the methods in this chapter are broadly applicable.  The exercises at the end of the chapter will give you a chance to apply them.</p>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p><strong>Exercise:</strong> Looking again at the posterior joint distribution of <code class="docutils literal notranslate"><span class="pre">mu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code>, it seems like the standard deviation of the treated group might be lower; if so, that would suggest that the treatment is more effective for students with lower scores.</p>
<p>But before we speculate too much, we should estimate the size of the difference and see whether it might actually be 0.</p>
<p>Extract the marginal posterior distributions of <code class="docutils literal notranslate"><span class="pre">sigma</span></code> for the two groups.
What is the probability that the standard deviation is higher in the control group?</p>
<p>Compute the distribution of the difference in <code class="docutils literal notranslate"><span class="pre">sigma</span></code> between the two groups.  What is the mean of this difference?  What is the 90% credible interval?</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">pmf_std_control</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">posterior_control</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">pmf_std_treated</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">posterior_treated</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">pmf_std_control</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Control&#39;</span><span class="p">)</span>
<span class="n">pmf_std_treated</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Treated&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Population standard deviation&#39;</span><span class="p">,</span> 
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span> 
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distributions of sigma&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_153_0.png" src="_images/chap13_153_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">Pmf</span><span class="o">.</span><span class="n">prob_gt</span><span class="p">(</span><span class="n">pmf_std_control</span><span class="p">,</span> <span class="n">pmf_std_treated</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9685103375300469
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">pmf_diff2</span> <span class="o">=</span> <span class="n">Pmf</span><span class="o">.</span><span class="n">sub_dist</span><span class="p">(</span><span class="n">pmf_std_control</span><span class="p">,</span> <span class="n">pmf_std_treated</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">pmf_diff2</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>6.41717132817218
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">pmf_diff2</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 1. , 12.5])
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">kde_from_pmf</span><span class="p">(</span><span class="n">pmf_diff2</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Difference in population standard deviation&#39;</span><span class="p">,</span> 
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span> 
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distributions of difference in sigma&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_158_0.png" src="_images/chap13_158_0.png" />
</div>
</div>
</div>
<div class="section" id="exercise">
<h2>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">¶</a></h2>
<p>An “<a class="reference external" href="http://en.wikipedia.org/wiki/Effect_size">effect size</a>” is a statistic intended to quantify the magnitude of a phenomenon.
If the phenomenon is a difference in means between two groups, a common way to quantify it is Cohen’s effect size, denoted <span class="math notranslate nohighlight">\(d\)</span>.</p>
<p>If the parameters for Group 1 are <span class="math notranslate nohighlight">\((\mu_1, \sigma_1)\)</span>, and the
parameters for Group 2 are <span class="math notranslate nohighlight">\((\mu_2, \sigma_2)\)</span>, Cohen’s
effect size is</p>
<p><span class="math notranslate nohighlight">\( d = \frac{\mu_1 - \mu_2}{(\sigma_1 + \sigma_2)/2} \)</span></p>
<p>Use the joint posterior distributions for the two groups to compute the posterior distribution for Cohen’s effect size.</p>
<p>If we try enumerate all pairs from the two distributions, it takes too
long so we’ll use random sampling.</p>
<p>The following function takes a joint posterior distribution and returns a sample of pairs.
It uses some features we have not seen yet, but you can ignore the details for now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample_joint</span><span class="p">(</span><span class="n">joint</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Draw a sample from a joint distribution.</span>
<span class="sd">    </span>
<span class="sd">    joint: DataFrame representing a joint distribution</span>
<span class="sd">    size: sample size</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="n">joint</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">stack</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">pmf</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s how we can use it to sample pairs from the posterior distributions for the two groups.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_treated</span> <span class="o">=</span> <span class="n">sample_joint</span><span class="p">(</span><span class="n">posterior_treated</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">sample_treated</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_control</span> <span class="o">=</span> <span class="n">sample_joint</span><span class="p">(</span><span class="n">posterior_control</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">sample_control</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000,)
</pre></div>
</div>
</div>
</div>
<p>The result is an array of tuples, where each tuple contains a possible pair of values for <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>.
Now you can loop through the samples, compute the Cohen effect size for each, and estimate the distribution of effect sizes.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="k">def</span> <span class="nf">cohen_effect</span><span class="p">(</span><span class="n">pair1</span><span class="p">,</span> <span class="n">pair2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute Cohen&#39;s effect size for difference in means.</span>
<span class="sd">    </span>
<span class="sd">    pair1: tuple of (mu1, sigma1)</span>
<span class="sd">    pair2: tuple of (mu2, sigma2)</span>
<span class="sd">    </span>
<span class="sd">    return: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mu1</span><span class="p">,</span> <span class="n">sigma1</span> <span class="o">=</span> <span class="n">pair1</span> 
    <span class="n">mu2</span><span class="p">,</span> <span class="n">sigma2</span> <span class="o">=</span> <span class="n">pair2</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="p">(</span><span class="n">sigma1</span> <span class="o">+</span> <span class="n">sigma2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">mu1</span> <span class="o">-</span> <span class="n">mu2</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">cohen_effect</span><span class="p">(</span><span class="n">sample_treated</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sample_control</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7245283018867921
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">ds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">pair1</span><span class="p">,</span> <span class="n">pair2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sample_treated</span><span class="p">,</span> <span class="n">sample_control</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">cohen_effect</span><span class="p">(</span><span class="n">pair1</span><span class="p">,</span> <span class="n">pair2</span><span class="p">)</span>
    <span class="n">ds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">cdf</span> <span class="o">=</span> <span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
<span class="n">cdf</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Cohen effect size&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;CDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distributions of effect size&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_168_0.png" src="_images/chap13_168_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">cdf</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6814774216741235
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">cdf</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.12      , 1.22352941])
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise:</strong> This exercise is inspired by <a class="reference external" href="https://www.reddit.com/r/statistics/comments/hcvl2j/q_reverse_empirical_distribution_rule_question/">a question that appeared on Reddit</a>.</p>
<p>An instructor announces the results of an exam like this, “The average score on this exam was 81.  Out of 25 students, 5 got more than 90, and I am happy to report that no one failed (got less than 60).”</p>
<p>Based on this information, what do you think the standard deviation of scores was?</p>
<p>You can assume that the distribution of scores is approximately normal.  And let’s assume that the sample mean, 81, is actually the population mean, so we only have to estimate <code class="docutils literal notranslate"><span class="pre">sigma</span></code>.</p>
<p>Hint: To compute the probability of a score greater than 90, you can use <code class="docutils literal notranslate"><span class="pre">norm.sf</span></code>, which computes the survival function, also known as the complementary CDF, or <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">cdf(x)</span></code>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Based on trial and error, here&#39;s a range of</span>
<span class="c1"># values for the prior</span>

<span class="n">hypos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here are the probabilities of a score greater than 90</span>
<span class="c1"># for each hypothetical value of sigma.</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="n">pgt90</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="mi">81</span><span class="p">,</span> <span class="n">hypos</span><span class="p">)</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="mi">90</span><span class="p">)</span>
<span class="n">pgt90</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101,)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># And here&#39;s the chance that 5 out of 25 people</span>
<span class="c1"># get a score greater than 90</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>

<span class="n">likelihood1</span> <span class="o">=</span> <span class="n">binom</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">pgt90</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">likelihood1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101,)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here&#39;s the first update</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">hypos</span><span class="p">)</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood1</span>
<span class="n">posterior</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.299480018256251
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here&#39;s the first posterior.</span>

<span class="n">posterior</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Standard deviation&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PMF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_176_0.png" src="_images/chap13_176_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here&#39;s the probability of a score greater than 60</span>

<span class="n">pgt60s</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="mi">81</span><span class="p">,</span> <span class="n">hypos</span><span class="p">)</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># And here&#39;s the probability that all 25 students exceed 60</span>

<span class="n">likelihood2</span> <span class="o">=</span> <span class="n">pgt60s</span> <span class="o">**</span> <span class="mi">25</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hypos</span><span class="p">,</span> <span class="n">likelihood2</span><span class="p">)</span>
<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Standard deviation&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Likelihood&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_179_0.png" src="_images/chap13_179_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="c1"># Here&#39;s the posterior after both updates</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">Pmf</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">hypos</span><span class="p">)</span>
<span class="n">prior</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
<span class="n">posterior2</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood1</span> <span class="o">*</span> <span class="n">likelihood2</span>
<span class="n">posterior2</span><span class="o">.</span><span class="n">normalize</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.014254555311295629
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Posterior 1&#39;</span><span class="p">)</span>
<span class="n">posterior2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Posterior 2&#39;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Standard deviation&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PMF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_181_0.png" src="_images/chap13_181_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">posterior2</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(18.150261186811544, 10.189707962198526)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">posterior2</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 7., 15.])
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise:</strong> I have a soft spot for crank science, so this exercise is about the <a class="reference external" href="http://en.wikipedia.org/wiki/Variability_hypothesis">Variability Hypothesis</a>, which</p>
<blockquote>
<div><p>“originated in the early nineteenth century with Johann Meckel, who argued that males have a greater range of ability than females, especially in intelligence. In other words, he believed that most geniuses and most mentally retarded people are men. Because he considered males to be the ’superior animal,’ Meckel concluded that females’ lack of variation was a sign of inferiority.”</p>
</div></blockquote>
<p>I particularly like that last part because I suspect that if it turned out that women were <em>more</em> variable, Meckel would have taken that as a sign of inferiority, too.</p>
<p>Nevertheless, the Variability Hypothesis suggests an exercise we can use to practice the methods in this chapter.  Let’s look at the distribution of heights for men and women in the U.S. and see who is more variable.</p>
<p>I used 2018 data from the CDC’s <a class="reference external" href="https://www.cdc.gov/brfss/annual_data/annual_2018.html">Behavioral Risk Factor Surveillance System</a> (BRFSS), which includes self-reported heights from 154407 men and 254722 women.</p>
<p>Here’s what I found:</p>
<ul class="simple">
<li><p>The average height for men is 178 cm; the average height for women is 163 cm. So men are taller on average; no surprise there.</p></li>
<li><p>For men the standard deviation is 8.27 cm; for women it is 7.75 cm. So in absolute terms, men’s heights are more variable.</p></li>
</ul>
<p>But to compare variability between groups, it is more meaningful to use the <a class="reference external" href="https://en.wikipedia.org/wiki/Coefficient_of_variation">coefficient of variation</a> (CV), which is the standard deviation divided by the mean. It is a dimensionless measure of variability relative to scale.</p>
<p>For men CV is 0.0465; for women it is 0.0475.
The coefficient of variation is higher for women, so this dataset provides evidence against the Variability Hypothesis. But we can use Bayesian methods to make that conclusion more precise.</p>
<p>Use these summary statistics to compute the posterior distribution of <code class="docutils literal notranslate"><span class="pre">mu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> for the distributions of male and female height.
Use <code class="docutils literal notranslate"><span class="pre">Pmf.div_dist</span></code> to compute posterior distributions of CV.
Based on this dataset and the assumption that the distribution of height is normal, what is the probability that the coefficient of variation is higher for men?
What is the most likely ratio of the CVs and what is the 90% credible interval for that ratio?</p>
<p>Hint: Use different prior distributions for the two groups, and chose them so they cover all parameters with non-negligible probability.</p>
<p>Also, you might find this function helpful:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_posterior_cv</span><span class="p">(</span><span class="n">joint</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the posterior distribution of CV.</span>
<span class="sd">    </span>
<span class="sd">    joint: joint distribution of mu and sigma</span>
<span class="sd">    </span>
<span class="sd">    returns: Pmf representing the smoothed posterior distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pmf_mu</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">pmf_sigma</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">(</span><span class="n">joint</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pmf_cv</span> <span class="o">=</span> <span class="n">Pmf</span><span class="o">.</span><span class="n">div_dist</span><span class="p">(</span><span class="n">pmf_sigma</span><span class="p">,</span> <span class="n">pmf_mu</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">kde_from_pmf</span><span class="p">(</span><span class="n">pmf_cv</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">154407</span>
<span class="n">mean</span> <span class="o">=</span> <span class="mi">178</span>
<span class="n">std</span> <span class="o">=</span> <span class="mf">8.27</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">prior_mu</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">mean</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">mean</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

<span class="n">prior_sigma</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">std</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">std</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;std&#39;</span><span class="p">)</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">prior_mu</span><span class="p">,</span> <span class="n">prior_sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">n</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span>
<span class="n">posterior_male</span> <span class="o">=</span> <span class="n">update_norm_summary</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plot_contour</span><span class="p">(</span><span class="n">posterior_male</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Mean&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Standard deviation&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_190_0.png" src="_images/chap13_190_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">254722</span>
<span class="n">mean</span> <span class="o">=</span> <span class="mi">163</span>
<span class="n">std</span> <span class="o">=</span> <span class="mf">7.75</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">prior_mu</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">mean</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">mean</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

<span class="n">prior_sigma</span> <span class="o">=</span> <span class="n">make_uniform</span><span class="p">(</span><span class="n">std</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">std</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;std&#39;</span><span class="p">)</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">make_joint</span><span class="p">(</span><span class="n">prior_mu</span><span class="p">,</span> <span class="n">prior_sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">n</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span>
<span class="n">posterior_female</span> <span class="o">=</span> <span class="n">update_norm_summary</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plot_contour</span><span class="p">(</span><span class="n">posterior_female</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Oranges&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_193_0.png" src="_images/chap13_193_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">pmf_cv_male</span> <span class="o">=</span> <span class="n">get_posterior_cv</span><span class="p">(</span><span class="n">posterior_male</span><span class="p">)</span>
<span class="n">kde_from_pmf</span><span class="p">(</span><span class="n">pmf_cv_male</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>

<span class="n">pmf_cv_female</span> <span class="o">=</span> <span class="n">get_posterior_cv</span><span class="p">(</span><span class="n">posterior_female</span><span class="p">)</span>
<span class="n">kde_from_pmf</span><span class="p">(</span><span class="n">pmf_cv_female</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Coefficient of variation&#39;</span><span class="p">,</span>
         <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;PDF&#39;</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Posterior distributions of CV&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chap13_194_0.png" src="_images/chap13_194_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">ratio_cv</span> <span class="o">=</span> <span class="n">Pmf</span><span class="o">.</span><span class="n">div_dist</span><span class="p">(</span><span class="n">pmf_cv_female</span><span class="p">,</span> <span class="n">pmf_cv_male</span><span class="p">)</span>
<span class="n">ratio_cv</span><span class="o">.</span><span class="n">max_prob</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0233615721208176
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Solution</span>

<span class="n">ratio_cv</span><span class="o">.</span><span class="n">credible_interval</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.0193799 , 1.02734473])
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="chap12.html" title="previous page">Classification</a>
    <a class='right-next' id="next-link" href="chap14.html" title="next page">Survival Analysis</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Allen B. Downey<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>